# Discussion

This thesis explored the role of interaction in data visualization pipelines. More specifically, I investigated how interaction affects the four stages of data visualization pipelines - partitioning, aggregation, scaling, and rendering - and explored the inherent problems and challenges. The main thrust of my argument was that the popular model implied by the Grammar of Graphics [@wilkinson2012], which treats statistics and geometric objects as independent entities, is insufficient for describing the complex relationships between the components of interactive figures [see also @wu2024]. As an alternative, I proposed a simple category-theoretic model, conceptualizing the data visualization pipeline as a functor. 

The essence of the proposed model is the idea that, initially, all visualizations begin as a collection of data subsets. In almost all cases, this collection is not arbitrary, but instead has a special kind of structure: it is a hierarchy of data partitions ordered by set union. To maintain consistency during interactions like linked selection, the subsequent steps of the data visualization pipeline should preserve this structure. In plain words, the geometric objects in our plots and the underlying summary statistics should *behave like set union*. Formally, this means that the mappings from data subsets to summary statistics and from summary statistics to geometric objects should be functors. More specifically, using the properties of set union, we can identify the underlying algebraic structures as either groups or monoids: the operations in our plots should be associative and unital, and also potentially invertible, monotonic, and commutative. When these algebraic constraints are satisfied, the geometric objects in our plots will compose well under selection, meaning that their parts add up to a meaningful whole.     

To validate the proposed model, I developed `plotscaper`, an interactive data visualization R package. In fact, this implementation served as a crucial feedback loop, as many of the theoretical concepts emerged from practical challenges that I encountered during the design of the system. By translating theory into code, I was able to empirically test and refine assumptions about the structure and behavior of interactive data visualizations. 

However, `plotscaper` was also developed to provide a practical tool for data exploration, not just theory testing. As outlined in Section \@ref(background), within the R community, there is currently no shortage of interactive data visualization packages and frameworks; however, many of these offer only fairly limited, shallow kinds of interactivity. Implementing more complex kinds of interaction, such as linked selection, representation switching, and parametric interaction (see section \@ref(common-features)) often requires substantial programming expertise and time-investment, creating a barrier to entry for casual users and solo data analysts [see e.g. @batch2017]. Thus, one of the goals of the project was to try to address this perceived lack of simple and practical tools for interactive data exploration. This hypothesis seems to have been largely proven correct by the package's moderate success - despite its relatively experimental status in comparison to other, far larger and better-established interactive data visualization frameworks, `plotscaper` has been downloaded over `r cranlogs::cran_downloads("plotscaper", from = "2024-10-01", to = Sys.Date())$count |> sum()` times^[The number only includes downloads from the RStudio CRAN mirror.], in the `r as.numeric(Sys.Date() - as.Date("2024-10-19"))` days since its initial release.

However, despite all of these relative successes, both the theoretical model and its practical implementation in `plotscaper` have certain important limitations. These will be the subject of the next few sections.
 
## Limitations of the theoretical model

The first important thing to discuss are the limitations of the theoretical model described in Section \@ref(problems). This model conceptualizes the data visualization pipeline as a structure-preserving mapping - a functor - from the space of data subsets to the space of graphics. This relies on the key assumption that, if we start from a place of structure - a hierarchy of data subsets ordered by set inclusion/union - the subsequent steps of the data visualization pipeline should not discard this structure. Instead, the transformations of our data into summary statistics and aesthetic encodings should flow naturally around this structure. 

Of course, the first possible critique of the model is that not all plot types have to represent distinct data subsets. For example, as discussed in Section \@ref(comparison-disjointness), in certain visualizations of set-typed data, two geometric objects in the same layer may represent overlapping data subsets [see e.g. @alsallakh2013]. However, as I argued in that section, these types of visualizations are fairly specialized and rare, and, conversely, there is a number of arguments one can make for the "naturality" of typical, disjoint, part-whole object relationships which we encounter in most everyday plots.  

There are many useful visualization types which do not neatly fit into this model, and many of them may be reconciled with linked selection in some way. However, such reconciliation has to be, by definition, ad hoc.  

