# Discussion

This thesis explored the role of interaction in data visualization pipelines. More specifically, I investigated how interaction affects the four stages of data visualization pipelines - partitioning, aggregation, scaling, and rendering - and explored the inherent problems and challenges. The main thrust of my argument was that the popular model implied by the Grammar of Graphics [@wilkinson2012], which treats statistics and geometric objects as independent entities, is insufficient for describing the complex relationships between the components of interactive figures [see also @wu2024]. As an alternative, I proposed a simple category-theoretic model, conceptualizing the data visualization pipeline as a functor. 

The essence of the proposed model is the idea that, initially, all visualizations begin as a collection of data subsets. In almost all cases, this collection is not arbitrary, but instead has a special kind of structure: it is a hierarchy of data partitions ordered by set union. To maintain consistency during interactions like linked selection, the subsequent steps of the data visualization pipeline should preserve this structure. In plain words, the geometric objects in our plots and the underlying summary statistics should *behave like set union*. Formally, this means that the mappings from data subsets to summary statistics and from summary statistics to geometric objects should be functors. More specifically, using the properties of set union, we can identify the underlying algebraic structures as either groups or monoids: the operations in our plots should be associative and unital, and also potentially invertible, monotonic, and commutative. When these algebraic constraints are satisfied, the geometric objects in our plots will compose well under selection, meaning that their parts add up to a meaningful whole.     

To validate the proposed model, I developed `plotscaper`, an interactive data visualization R package. In fact, this implementation served as a crucial feedback loop, as many of the theoretical concepts emerged from practical challenges that I encountered during the design of the system. By translating theory into code, I was able to empirically test and refine assumptions about the structure and behavior of interactive data visualizations. 

However, `plotscaper` was also developed to provide a practical tool for data exploration, not just theory testing. As outlined in Section \@ref(background), within the R community, there is currently no shortage of interactive data visualization packages and frameworks; however, many of these offer only fairly limited, shallow kinds of interactivity. Implementing more complex kinds of interaction, such as linked selection, representation switching, and parametric interaction (see section \@ref(common-features)) often requires substantial programming expertise and time-investment, creating a barrier to entry for casual users and solo data analysts [see e.g. @batch2017]. Thus, one of the goals of the project was to try to address this perceived lack of simple and practical tools for interactive data exploration. This hypothesis seems to have been largely proven correct by the package's moderate success - despite its relatively experimental status in comparison to other, far larger and better-established interactive data visualization frameworks, `plotscaper` has been downloaded over `r cranlogs::cran_downloads("plotscaper", from = "2024-10-01", to = Sys.Date())$count |> sum()` times^[The number only includes downloads from the RStudio CRAN mirror.], in the `r as.numeric(Sys.Date() - as.Date("2024-10-19"))` days since its initial release.

However, despite all of these relative successes, both the theoretical model and its practical implementation in `plotscaper` have certain important limitations. These will be the subject of the next few sections.
 
## Limitations of the theoretical model

Firstly, it is important discuss the limitations of the theoretical model described in Section \@ref(problems). This model conceptualizes the data visualization pipeline as a structure-preserving mapping - a functor - from the space of ordered data subsets to the space of graphics. This relies on the key assumption that, if we start with a structured object - a hierarchy of data partitions made out of subsets ordered by set inclusion/union - the subsequent steps of the data visualization pipeline should not discard this structure arbitrarily. Instead, transformations of data into summary statistics and aesthetic encodings should preserve the inherent hierarchical relationships. This naturally leads us to groups and monoids.

One immediate critique is that the data partition hierarchy model does not describe all possible plot types. For instance, it precludes visualizations where geometric objects within the same graphical layer represent overlapping data subsets, as seen, for example, in certain visualizations of set-typed data [see Section \@ref(comparison-disjointness), also e.g. @alsallakh2014]. However, these types of visualizations are fairly rare. In the vast majority of standard plots - including barplots, histograms, density plots, scatterplots, lineplots, and parallel coordinate plots, among others - each geometric object represents a distinct subset of cases, independent from the rest, and the objects may combine together to form well-behaved, part-whole relationships. Further, as discussed in in Section \@ref(comparison-disjointness), this tendency towards disjoint representations does not seem to be a mere convention or accident, but instead likely stems from some fundamental mathematical and cognitive properties of disjointness and independence. Thus, while non-disjoint plots may be useful in certain specialized circumstances, disjointness seems to provide a good, general model.

Another potential point of contention are the limitations that the model imposes. Requiring that all graphics and the underlying summary statistics are (monotonic, commutative) monoids or groups excludes a non-trivial fraction of popular plot types. For instance, boxplots are entirely made out of non-monoidal summary statistics, nevertheless, they have been successfully implemented alongside linked selection in some interactive data visualization packages [see e.g. @theus2002; @urbanek2011]. However, the point of the model is not to say that certain kinds of visualizations can never be reconciled with linked selection, instead, it is to easily identify certain "natural" types of visualization where linked selection is inherently compatible. We are free to violate this naturality when we see fit, however, we should be aware of the fact that the reconciliation of these non-compliant visualizations may require some ad-hoc solutions. 

## Limitations of the software packages

During this project, I had time to think through and test out different implementations of the various features of the interactive data visualization system. While I succeeded in some areas, there were also areas which could still use some improvement. 

As discussed in Section \@ref(system), one shortcoming of my system is the absence of a simple declarative schema for specifying interactive graphics. While some parts of the internal codebase such as [REFERENCE WRANGLER] showed some promise, ultimately, plot were defined in a largely procedural way, and the package's user-facing API (`plotscaper`) used nominal plot-type functions. As I argued earlier, I believe this challenge is not unique to my system; many other, overtly declarative data visualization systems offer only partial solutions [see also @wu2024]. There are important reasons for why coming up with declarative schemas for interactive graphics is not easy, such as the lack of a direct correspondence between data variables and encodings (see Section [REFERENCE]) or the hierarchical nature of graphics itself (discussed e.g. in Section \@ref(hierarchy)), 

Further, 



