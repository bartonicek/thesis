# Introduction {#introduction}

> It’s written here: "In the Beginning was the Word!" <br>
> Here I stick already! Who can help me? It’s absurd, <br>
> [...] <br>
> The Spirit helps me! I have it now, intact. <br>
> And firmly write: "In the Beginning was the Act!"
>
> Faust, Part I, Johann Wolfgang von Goethe [-@goethe2015]

Humans are intensely visual creatures: roughly 20-30% of our brain is involved in visual processing [@van2003; @sheth2016]. This is reflected in a highly sophisticated and powerful visual processing system [see e.g. @goebel2004; @knudsen2020; for a brief review, see @ware2019], which enables us to perform some very advanced perceptual tasks. For instance, it is well-established that our brain can process certain highly salient visual stimuli in sub-20-millisecond times, outside of conscious attention [@ledoux2000; @ledoux2003], and that we can make extremely rapid, accurate, and parallel visual judgements, through phenomena known as subitizing and pre-attentive processing [@mandler1982; @treisman1985]. These features establish the visual cortex as our most potent information channel, both in terms of bandwidth and throughput.

Importantly, the visual cortex excels at processing not just concrete objects, but also abstract information, a fact that statisticians have been leveraging for a long time. Starting with early charts and maps, data visualization co-evolved alongside mathematical statistics, offering a complementary set of tools and methods [for a review, see @friendly2006 or Section \@ref(brief-history)]. Notably, while mathematical statistics was developed with the primary goal of confirming or disproving hypotheses, data visualization provided an alternative approach: instead of binary decisions, it facilitated unsupervised exploration, "forcing us to notice that which we would never expect to see" [@tukey1977]. This valuable role in revealing the unexpected eventually established data visualization as a respected part of the applied statistician's arsenal.

However, our interaction with the natural world extends beyond sight. When we try to understand some unknown object, we do not just look at it: if we can, we also touch, manipulate, and probe. Within our brain, action and perception are not independent, but are instead interconnected, mutually reinforcing processes [see e.g. @dijkerman2007; @lederman2009]; seeing is believing, but if you can't put your finger on it, how much is that belief really worth? Thus, it was only natural that, eventually, statisticians would start exploiting this relationship between visual perception and action as well. The development of computer graphics and interactive data visualization in the latter part of the twentieth century transformed the idea of "interrogating a chart" from a mere turn of phrase into tangible reality. All of a sudden, it became possible to directly manipulate the visual representation of the data in real time, getting new perspectives and insights at the stroke of a key or click of a button. 

These days, interactive data visualization has become a widely popular method of presenting data, but, a number of issues remain unresolved. Specifically, while interactive figures make frequent appearance in online news articles and commercial dashboards, and the data science ecosystem offers a plethora of tools and packages, there are still significant gaps in the utilization and understanding of interactive visualizations. Individual analysts rarely integrate interactive visualizations into their workflows [see e.g. @batch2017], and, despite the fact that many sophisticated interactive features have been developed over the years, their general availability is often fairly limited (see Section \@ref(background)). Finally, a core issue that is yet to be resolved is that of data pipelines: how do we go about transforming raw data into summary statistics that can be displayed by interactive graphics, in an efficient and consistent manner [@wickham2009; @vanderplas2020]?

In this thesis, I explore these gaps and try to identify the underlying issues which make developing interactive data visualization systems challenging. A key argument, echoing Leland Wilkinson's Grammar of Graphics (GoG) model [-@wilkinson2012], is that, although plots are composed of geometric objects, they are not mere pictures. Instead, they contain a large amount of structure, and this becomes particularly noticeable under interaction. I further contend that, while GoG offers a foundational framework for understanding the structure underlying graphics, to be able to fully integrate interaction, the model warrants refinement. To illustrate this point bluntly, I want to raise attention to the discrepancy between the following two quotes:

> "This system cannot produce a meaningless graphic, however. This is a strong claim, vulnerable to a single counter-example. It is a claim based on the formal rules of the system, however, not on the evaluation of specific graphics it may produce."
>
> "Some of the combinations of graphs and statistical methods may be degenerate or bizarre, but there is no moral reason to restrict them."
>
> @wilkinson2012, pp. 15 and 112^[See also the following quote: "I have tried to build the argument, except for the statistical methods in Chapter 7, from elementary definitions.", pp. 10 of the preface to the first edition.].

What makes some combinations of graphics and statistics meaningful, while others degenerate or bizarre? I believe that the answer to this question lies at the core of many of the problems with interactive data visualization. Specifically, I argue that, for plots to be well-behaved, there needs to be a special kind of congruence between data, summary statistics, and geometric objects. This is especially true under interaction; what we can *do* with a plot is fundamentally determined by what the plot *is*. To formally describe this congruence between data, statistics, and graphics, I propose a model leveraging some fundamental algebraic structures and concepts from category theory^[Which go beyond those described by @wilkinson2012.].

Finally, to validate and refine these theoretical concepts, I also develop an original open-source interactive data visualization library. Consequently, this thesis also details the design considerations, architecture, and components of this system, along with its application to real-world data. My goal is to demonstrate that many of the theoretical considerations have direct impact on the design characteristics of the system. Ultimately, I contend that, to build truly general and efficient interactive data visualization systems, we need to take both the theoretical and practical considerations into account. 

#### Thesis Overview

The thesis is organized as follows. Section \@ref(background) provides a review of the history of interactive data visualization, theoretical considerations regarding interactivity, common interactive features, and broader data visualization theory. Section \@ref(problems) identifies specific challenges in designing interactive data visualization pipelines and introduces the core algebraic theory. Section \@ref(goals), outlines general objectives and goals that guided the development of the interactive data visualization software system created as part of this project. Section \@ref(system) details more specific design considerations, architectural decisions, and key components of the developed software. Section \@ref(applied-example) presents a practical example of exploring a real-world data set using the developed system. Finally, Section \@ref(discussion), discusses lessons learned and potential future research directions.
