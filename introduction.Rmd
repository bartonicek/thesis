# Introduction {#introduction}

> It’s written here: "In the Beginning was the Word!" <br>
> Here I stick already! Who can help me? It’s absurd, <br>
> [...] <br>
> The Spirit helps me! I have it now, intact. <br>
> And firmly write: "In the Beginning was the Act!"
>
> Faust, Part I, Johann Wolfgang von Goethe [-@goethe2015]

Humans are intensely visual creatures. About 20-30% of our brain is involved in visual processing [@van2003; @sheth2016], providing support for a highly sophisticated and powerful visual system [see e.g. @goebel2004; @knudsen2020; for a brief review, see @ware2019], which in turn enables us to perform some remarkable perceptual feats. For instance, it is well-established that our brain can process certain highly salient visual stimuli in sub-20-millisecond times, outside of conscious attention [@ledoux2000; @ledoux2003], and that we can make extremely rapid, accurate, and parallel visual judgements, through phenomena known as subitizing and pre-attentive processing [@mandler1982; @treisman1985]. Features such as these establish the visual system as the most potent information channel at our disposal.

Crucially, while the visual cortex excels at processing data about the natural world, it is equally adept at processing abstract information. Statisticians have long capitalized on this fact. Emerging from early charts and maps, data visualization has co-evolved alongside mathematical statistics, providing a complementary set of tools and methods [for a review, see @friendly2006 or Section \@ref(brief-history)]. Specifically, while mathematical statistics was primarily developed with the goal of supporting or disproving scientific hypotheses, data visualization offered an alternative approach: unsupervised exploration. Rather than providing answers to binary decisions, it demonstrated its worth in "forcing us to notice that which we would never expect to see" [@tukey1977]. This invaluable role in revealing the unexpected eventually established data visualization as an indispensable part of the applied statistician's arsenal.

Our interaction with the natural world extends beyond sight, however. When we try to understand unknown objects, we do not just look; we also touch, manipulate, and probe. Consequently, within our brain, action and perception are not independent, but instead deeply interconnected, mutually reinforcing processes [see e.g. @dijkerman2007; @lederman2009]. As a consequence, the most effective learning strategies tend to involve "learning by doing"; passive observation is less effective [@hackathorn2011; @reese2011]. As the saying goes, seeing is believing, but how much is that belief really worth if you can't put your finger on it?

Naturally, statisticians would eventually come to exploit this connection between action and perception as well, just as they had done with visual perception alone. In the latter half of the twentieth century, the development of computer graphics, and interactive data visualization in particular, transformed the idea of "interrogating a chart" from a mere turn of phrase into tangible reality. Suddenly, users could directly manipulate the visual representation of the data in real time, uncovering new insights with a keystroke or a mouse click.

The power of interactive data visualization quickly established it as one of the most popular ways of presenting data. Today, interactive graphics make frequent appearance in online news articles, on government websites, and in commercial dashboards. Similarly, data science developer ecosystems are flush with software for creating interactive graphics. Thus, given its ubiquity, it may seem as though interactive data visualization is a "solved problem".

Yet, a number of issues surrounding the use and understanding of interactive visualizations remain. While interactive visualizations are indeed popular in large organizations, individual analysts rarely integrate them into their workflows [see e.g. @batch2017]. Further, despite years of research and development, only a small fraction of sophisticated interactive features have made it into the widely available software (see Section \@ref(background)). Finally, a core underlying issue that is yet to be resolved is that of data pipelines: how do we go about modeling the process of transforming raw data into something that can be interactively visualized, in a simple and efficient manner [see e.g. @wickham2009; @vanderplas2020]?

In this thesis, I explore the challenges that come up when developing interactive data visualization systems. A recurring theme will be that, although plots are visual entities composed of geometric objects, they are not mere pictures. Instead, they contain a significant amount of implicit, algebraic structure. This underlying structure dictates how plots can be manipulated, a fact that becomes particularly evident when interaction is introduced. 

By focusing on this underlying algebraic foundation, I build upon the work of Leland Wilkinson, and the Grammar of Graphics (GoG) model in particular [-@wilkinson2012]. However, I contend that while GoG offers a foundational framework, it may require certain refinements to fully encompass the scope of interactive graphics. To illustrate the point bluntly, consider the following two quotes:

> "This system cannot produce a meaningless graphic, however. This is a strong claim, vulnerable to a single counter-example. It is a claim based on the formal rules of the system, however, not on the evaluation of specific graphics it may produce."
>
> "Some of the combinations of graphs and statistical methods may be degenerate or bizarre, but there is no moral reason to restrict them."
>
> @wilkinson2012, pp. 15 and 112

What makes some combinations of graphics and statistics meaningful, while others degenerate or bizarre? I believe that answering this question is essential for building coherent data visualization systems, particularly ones involving interaction. Statistics may be a somewhat overlooked component of the GoG model^[See also the following quote: "I have tried to build the argument, except for the statistical methods in Chapter 7, from elementary definitions.", pp. 10 of the first-edition preface.]. Yet, I contend that, when developing interactive data visualizations, grappling with the properties of statistics underlying our plots is absolutely essential.

The main thrust of my argument is: what we can *do* with a graphic is fundamentally determined what the graphic *is*. Like geometric objects and scales, summary statistics are essential components of plots. When we consider all these together, distinct patterns emerge. Some types of plots exhibit a special kind of congruence between data, summary statistics, and visuals, which ensures predictable behavior under interaction. Other plots break this congruence, making certain interactive features brittle or difficult to implement. I explore this congruence and lack thereof throughout this thesis. Further, to describe it formally, I propose a simple model leveraging some fundamental algebraic concepts from category theory [see e.g. @fong2019]. My application of these concepts extends beyond the GoG [@wilkinson2012]. Specifically, in contrast to the GoG approach which treats data, statistics, and graphics as entirely independent, modular components, I propose an alternative, compositional model which focuses on preserving key mathematical properties.

Finally, since interactive data visualization is first and foremost an applied discipline, all this theoretical work would be meaningless if it did not lead to practical, actionable insights. Therefore, to validate and refine these theoretical findings, I also develop an original open-source interactive data visualization library, `plotscaper` (https://github.com/bartonicek/plotscaper). Consequently, parts of this thesis are dedicated to the design and architecture of this system, as well as its application to real-world data. Throughout these sections, I repeatedly explore and elaborate on the links between the underlying mathematics and the practical concerns that arise when building interactive data visualization systems. 

Ultimately, I contend that, to build truly general and efficient interactive data visualization systems, we need to take the algebraic relationships underlying plots into account. Only by precisely describing what a plot *is* can we begin to reason about what we can *do* with it.

#### Structure of the thesis

The thesis is organized as follows:

- **Section \@ref(background)** provides a brief overview of the history of interactive data visualization, theoretical considerations regarding interactive graphics as well as common interactive features, and several broader, important topics in data visualization. 
- **Section \@ref(problems)** identifies key challenges in designing interactive data visualization pipelines and introduces some core algebraic theory. 
- **Section \@ref(goals)** outlines the general objectives and goals that guided the development of the interactive data visualization software system (`plotscaper`).
- **Section \@ref(system)** overviews key design and architectural decisions, and discusses key components of the delivered software. 
- **Section \@ref(applied-example)** presents a practical example of applying `plotscaper` to explore a real-world data set. 
- **Section \@ref(discussion)** discusses lessons learned and potential future research directions, covering both the theoretical model and the applied work.
- **Section \@ref(conclusion)** provides some concluding remarks and closing thoughts.
