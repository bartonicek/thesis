# Introduction {#introduction}

> It’s written here: "In the Beginning was the Word!" <br>
> Here I stick already! Who can help me? It’s absurd, <br>
> [...] <br>
> The Spirit helps me! I have it now, intact. <br>
> And firmly write: "In the Beginning was the Act!"
>
> Faust, Part I, Johann Wolfgang von Goethe [-@goethe2015]

Humans are intensely visual creatures. About 20-30% of our brain is involved in visual processing [@van2003; @sheth2016], supporting a highly sophisticated and powerful visual system [see e.g. @goebel2004; @knudsen2020; for a brief review, see @ware2019]. This in turn enables us to perform some remarkable perceptual feats. For instance, it is well-established that our brain can process certain highly salient visual stimuli in sub-20-millisecond times, outside of conscious attention [@ledoux2000; @ledoux2003], and that we can make extremely rapid, accurate, and parallel visual judgements, through phenomena known as subitizing and pre-attentive processing [@mandler1982; @treisman1985]. Features such as these establish the visual system as the most potent information channel we have at our disposal.

Importantly, while the visual cortex excels at processing information about the natural world, it is also remarkably adept at handling abstract data as well - a fact statisticians have long capitalized on. Emerging from early charts and maps, data visualization has co-evolved alongside mathematical statistics, providing a complementary set of tools and methods [for a review, see @friendly2006 or Section \@ref(brief-history)]. Specifically, while mathematical statistics was primarily developed with the goal of supporting or disproving existing scientific hypotheses, data visualization offered an alternative: unsupervised exploration. Instead of providing binary answers, it demonstrated its worth in "forcing us to notice that which we would never expect to see" [@tukey1977]. This invaluable role in revealing the unexpected eventually established data visualization as an indispensable part of the applied statistician's arsenal.

Yet, despite the primacy of vision, our interaction with the natural world extends beyond sight. When we try to understand unknown objects, we do not just look; we also touch, manipulate, and probe. Consequently, within our brain, action and perception are deeply connected, mutually reinforcing processes [see e.g. @dijkerman2007; @lederman2009], and, as a consequence, effective learning strategies usually involve "learning by doing"; passive observation is less effective [@hackathorn2011; @reese2011]. As the saying goes, seeing is believing, but how much is that belief really worth if you can't put your finger on it?

Naturally, statisticians would eventually come to exploit this connection between action and perception as well. In the latter half of the twentieth century, the development of computer graphics and interactive data visualization transformed the idea of "interrogating a chart" from a mere turn of phrase into tangible reality. Suddenly, users could directly manipulate the visual representation of the data in real time, uncovering new insights with a keystroke or a mouse click.

The power of interactive data visualization quickly established it as one of the most popular ways of presenting data. Today, interactive graphics make frequent appearance in online news articles, on government websites, and in commercial dashboards, and data-science-adjacent developer ecosystems are flush with software for building and deploying interactive visualizations. Thus, given its ubiquity, it may seem as though interactive data visualization is a "solved problem".

Yet, a number of issues surrounding the use and understanding of interactive visualizations remain. While interactive visualizations are indeed popular in large organizations, individual analysts rarely integrate them into their workflows [see e.g. @batch2017]. Further, despite years of research and development, only a small fraction of the more sophisticated interactive features make it into the widely available software (see Section \@ref(background)). Finally, a core underlying issue that is yet to be resolved is that of data pipelines: how do we go about modeling the process of transforming raw data into something that can be interactively visualized, in a simple and efficient manner [see e.g. @wickham2009; @vanderplas2020]?

In this thesis, I explore the challenges that come up when developing interactive data visualization systems. A recurring theme will be that plots, despite being visual entities composed of geometric objects, are more than just pictures. Instead, they possess a significant amount of implicit, algebraic structure which dictates how they can be created and manipulated. This underlying structure becomes particularly critical when interaction is introduced.

By focusing on this underlying algebraic foundation, I build upon the work of Leland Wilkinson, and the Grammar of Graphics (GoG) model in particular [-@wilkinson2012]. However, I contend that GoG, while a foundational model, contains certain gaps that complicate reasoning about graphics, especially under interaction. To illustrate the point rather bluntly, consider the following two quotes:

> "This system cannot produce a meaningless graphic, however. This is a strong claim, vulnerable to a single counter-example. It is a claim based on the formal rules of the system, however, not on the evaluation of specific graphics it may produce."
>
> "Some of the combinations of graphs and statistical methods may be degenerate or bizarre, but there is no moral reason to restrict them."
>
> @wilkinson2012, pp. 15 and 112

What makes some combinations of graphics and statistics meaningful, while others degenerate or bizarre? I believe that answering this question is essential for building coherent data visualization systems, particularly ones involving interaction. Arguably, statistics may be a somewhat overlooked component of the GoG model^[See also the following quote: "I have tried to build the argument, except for the statistical methods in Chapter 7, from elementary definitions.", pp. 10 of the first-edition preface.]. Yet, I contend that, when developing interactive data visualizations, grappling with the properties of statistics underlying our plots is just as essential as understanding any other component.

The main thrust of my argument is this: what we can *do* with a graphic is fundamentally determined what the graphic *is*. Like geometric objects and scales, summary statistics are essential components of plots. When we consider all these together, distinct patterns emerge. Some types of plots exhibit a special congruence between data, summary statistics, and visuals, which ensures predictable behavior under interaction. Other plots break this congruence, making certain interactive features brittle or difficult to implement. I explore this congruence and lack thereof throughout this thesis. Further, to describe it formally, I propose a simple model leveraging some fundamental algebraic concepts from category theory [see e.g. @fong2019]. My application of these concepts extends beyond the GoG [@wilkinson2012]. Specifically, in contrast to the GoG approach which treats data, statistics, and graphics as entirely independent, modular components, I propose an alternative, compositional model which focuses on preserving key mathematical properties.

Finally, since interactive data visualization is first and foremost an applied discipline, all this theoretical work would be meaningless if it did not lead to practical, actionable insights. Therefore, to validate and refine these theoretical findings, I also develop an original open-source interactive data visualization library, `plotscaper` (https://github.com/bartonicek/plotscaper). Consequently, parts of this thesis are dedicated to the design and architecture of this system, as well as its application to real-world data. Throughout these sections, I repeatedly explore and elaborate on the links between the underlying mathematics and the practical concerns that arise when building interactive data visualization systems. 

Ultimately, I contend that, to build truly general and efficient interactive data visualization systems, we need to take the algebraic relationships underlying plots into account. Only by precisely describing what a plot *is* can we begin to reason about what we can *do* with it.

#### Structure of the thesis

The thesis is organized as follows:

- **Section \@ref(background)** provides a brief overview of the history of interactive data visualization, theoretical considerations regarding interactive graphics as well as common interactive features, and several broader, important topics in data visualization. 
- **Section \@ref(problems)** identifies key challenges in designing interactive data visualization pipelines and introduces some core algebraic theory. 
- **Section \@ref(goals)** outlines the general objectives and goals that guided the development of the interactive data visualization software system (`plotscaper`).
- **Section \@ref(system)** overviews key design and architectural decisions, and discusses key components of the delivered software. 
- **Section \@ref(applied-example)** presents a practical example of applying `plotscaper` to explore a real-world data set. 
- **Section \@ref(discussion)** discusses lessons learned and potential future research directions, covering both the theoretical model and the applied work.
- **Section \@ref(conclusion)** provides some concluding remarks and closing thoughts.
