# Introduction {#introduction}

> It’s written here: ‘In the Beginning was the Word!’ <br>
> Here I stick already! Who can help me? It’s absurd, <br>
> [...] <br>
> The Spirit helps me! I have it now, intact. <br>
> And firmly write: ‘In the Beginning was the Act!
>
> Faust, Part I, Johann Wolfgang von Goethe [-@goethe2015]

Humans are intensely visual creatures: roughly 20-30% of our brain is involved in visual processing [@van2003; @sheth2016]. This results in a highly sophisticated and powerful visual processing system [see e.g. @goebel2004; @knudsen2020; for a brief review, see @ware2019], allowing the brain to perform highly advanced perceptual tasks. For instance, it is well-established that certain highly salient visual stimuli can be processed in sub-20-millisecond times, outside of conscious attention [@ledoux2000; @ledoux2003], and that people can make accurate, parallel, and extremely rapid visual judgements, in phenomena known as subitizing and pre-attentive processing [@mandler1982; @treisman1985]. These features make the visual cortex the most powerful information channel we have, both in terms of bandwidth and throughput.

Importantly, the visual cortex excels at processing not just concrete objects, but also abstract information. Statisticians have long capitalized on this capability. Starting with early charts and maps, data visualization co-evolved alongside mathematical statistics, offering a complementary set of tools and methods [for a review, see @friendly2006 or Section \@ref(brief-history)]. Specifically, while mathematical statistics was primarily developed to confirm or disprove hypotheses, data visualization offered something else: instead of binary decisions, it allowed for unsupervised exploration, "forcing us to notice that which we would never expect to see" [@tukey1977]. This valuable role in revealing the unexpected eventually established data visualization as a respected part of the applied statistician's arsenal.

However, our interaction with the natural world extends beyond sight. When we try to understand some unknown object, we do not just look at it: if we can, we also touch, manipulate, and probe. This is due to the fact that, within the human brain, action and perception are not independent, but are instead interconnected, mutually reinforcing processes [see e.g. @dijkerman2007; @lederman2009]. Seeing is believing, but if you can't put your finger on it, how much is that belief really worth?

Therefore, it is only natural that, eventually, that statisticians would eventually exploit this relationship between visual and tactile perception as well. The development of computer graphics and interactive data visualization in the latter part of the twentieth century transformed the idea of "interrogating a chart" from a mere turn of phrase into tangible reality. All of a sudden, it became possible to work with the visual representation of data in a tactile way, getting new perspectives and insights at the stroke of a key or click of a button. 

These days, interactive data visualization has become wildly popular method of presenting data. However, a number of unresolved issues remain. While interactive figures make frequent appearance in online news articles and commercial dashboards, and the data science ecosystem offers a plethora of tools and packages, there are still significant gaps in the utilization and understanding of interactive visualizations. Specifically, individual analysts rarely integrate interactive visualizations into their workflows [see e.g. @batch2017]. Additionally, despite the fact that many sophisticated interactive features have been developed over the years, their general availability is fairly limited (see Section \@ref(background)). Finally, a core issue that is yet to be resolved is that of data pipelines: how do we go about transforming raw data into summary statistics that can be displayed by interactive graphics, in an efficient and consistent manner [@wickham2009; @vanderplas2020]?

In this thesis, I explore these gaps and try to identify the underlying issues which make developing interactive data visualization systems challenging. A key argument I will keep coming back to again and again is that, although plots are composed of geometric objects, they are not merely pictures. Instead, they contain a significant amount of structure, which can be described algebraically. In this way, I follow the tradition of the Grammar of Graphics (GoG) model developed by Leland Wilkinson [-@wilkinson2012]. However, I believe there are some parts of the GoG model which are fundamentally lacking or incomplete. Specifically, I want to raise attention to the discrepancy between the following two quotes:

> "This system cannot produce a meaningless graphic, however. This is a strong claim, vulnerable to a single counter-example. It is a claim based on the formal rules of the system, however, not on the evaluation of specific graphics it may produce."
>
> "Some of the combinations of graphs and statistical methods may be degenerate or bizarre, but there is no moral reason to restrict them."
>
> @wilkinson2012, pp. 15 and 112.

What makes some combinations of graphics and statistics valid, while others degenerate or bizarre? I believe that this question lies at the core of many of the problems with interactive data visualization. Specifically, for plots to be well-behaved, particularly under interaction, there needs to be a fundamental congruence between data, summary statistics, and geometric objects. I contend that this congruence can be formally described using some fundamental algebraic structures and concepts from category theory. I also argue that interactivity places some additional constraints on these structures, and as a result, cannot be simply an afterthought.

Finally, to test and refine these ideas, I also developed an interactive data visualization system as an open-source library. Therefore, I also discuss the considerations that went into the development of this system, its various parts and components, and an application on real-world data. Further, my goal is also to demonstrate that many theoretical considerations directly impact concrete design characteristics. I content that, to build truly general and efficient interactive data visualization systems, we need to take both the theory and practice into consideration. 

#### Thesis Overview

The thesis is organized as follows. Section \@ref(background) reviews the history of interactive data visualization and discusses general trends and issues in the field. Section \@ref(problems), focuses on specific problems encountered when designing an interactive data visualization pipeline. Section \@ref(goals), outlines the the goals and aims that guided the development of the interactive data visualization library. Section \@ref(system) details the system's components and design considerations. Section \@ref(applied-example), presents an applied example of exploring a real-world data set using the developed library. Finally, Section \@ref(discussion), discusses lessons learned and potential future research directions.
