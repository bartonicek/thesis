# Introduction {#introduction}

> It’s written here: "In the Beginning was the Word!" <br>
> Here I stick already! Who can help me? It’s absurd, <br>
> [...] <br>
> The Spirit helps me! I have it now, intact. <br>
> And firmly write: "In the Beginning was the Act!"
>
> Faust, Part I, Johann Wolfgang von Goethe [-@goethe2015]

Humans are intensely visual creatures. About 20-30% of our brain is involved in visual processing [@van2003; @sheth2016], providing support for a highly sophisticated and powerful visual system [see e.g. @goebel2004; @knudsen2020; for a brief review, see @ware2019]. This enables us to perform some remarkable perceptual feats. For instance, it is well-established that our brain can process certain highly salient visual stimuli in sub-20-millisecond times, outside of conscious attention [@ledoux2000; @ledoux2003], and that we can make extremely rapid, accurate, and parallel visual judgements, through phenomena known as subitizing and pre-attentive processing [@mandler1982; @treisman1985]. Features such as these establish the visual system as the most potent information channel at our disposal.

Crucially, while the visual cortex excels at processing data about the natural world, it is equally adept at processing abstract information. Statisticians have long capitalized on this fact. Emerging from early charts and maps, data visualization has evolved alongside mathematical statistics, providing a complementary set of tools and methods [for a review, see @friendly2006 or Section \@ref(brief-history)]. While mathematical statistics was primarily developed with the goal of supporting or disproving scientific hypotheses, data visualization offered an alternative approach: unsupervised exploration. Rather than providing answers to binary decisions, it demonstrated its worth in "forcing us to notice that which we would never expect to see" [@tukey1977]. This invaluable role in revealing the unexpected eventually established data visualization as an indispensable part of the applied statistician's arsenal.

Now, while vision is one of the primary ways we gather information, our interaction with the natural world extends beyond sight. When trying to understand unknown objects, we do not just look; we also touch, manipulate, and probe. Consequently, within our brain, action and perception are not independent, but instead deeply interconnected, mutually reinforcing processes [see e.g. @dijkerman2007; @lederman2009]. We learn most effectively by action and observing the resulting changes; passive observation is less effective. As the saying goes, seeing is believing, but how much is that belief really worth if you can't put your finger on it?

Naturally, statisticians would eventually come to exploit this connection between perception and action as well, just as they had done with visual perception alone. In the latter half of the twentieth century, the development of computer graphics and interactive data visualization transformed the idea of "interrogating a chart" from a mere turn of phrase into tangible reality. Suddenly, it became possible to directly manipulate the visual representation of the data in real time, such that new visual insights could be obtained at the stroke of a key or click of a button.

The power of interactive data visualization quickly established it as one of the most popular ways of presenting data. Today, interactive graphics make frequent appearance in online news articles, on government websites, and in commercial dashboards. Similarly, data science developer ecosystems abound with software packages and tools for creating interactive graphics. As such, given its ubiquity, it may seem as though interactive data visualization is a "solved problem".

Yet, a number of unresolved issues surrounding the use and understanding interactive figures remain. Although large organizations favor interactive data visualizations, individual analysts seldom integrate them into their workflows [see e.g. @batch2017]. Moreover, despite the development of a wide array of sophisticated interactive features over the years, only a small fraction of them make it into widely available software (see Section \@ref(background)). Finally, a core underlying issue is that of data pipelines: how do we go about transforming raw data into something that can be visualized interactively, in a simple yet efficient manner [@wickham2009; @vanderplas2020]?

In this thesis, I explore these gaps and try to identify the underlying issues which make the development of interactive data visualization systems challenging. A recurring theme will be that, although plots are visual entities composed of geometric objects, they are not mere pictures. Instead, they contain a significant amount of implicit, algebraic structure, which becomes particularly apparent when interaction enters the scene. By focusing on the algebraic structure underlying plots, I build upon the work of Leland Wilkinson, and the Grammar of Graphics (GoG) model in particular [-@wilkinson2012]. However, I contend that, while offering a foundational framework, to fully encompass the scope of interactive graphics, the GoG model warrants certain refinements. To make the point rather bluntly, I want to draw attention to the following two quotes:

> "This system cannot produce a meaningless graphic, however. This is a strong claim, vulnerable to a single counter-example. It is a claim based on the formal rules of the system, however, not on the evaluation of specific graphics it may produce."
>
> "Some of the combinations of graphs and statistical methods may be degenerate or bizarre, but there is no moral reason to restrict them."
>
> @wilkinson2012, pp. 15 and 112

What makes some combinations of graphics and statistics meaningful, while others degenerate or bizarre? I believe that answering this question is essential for building coherent interactive data visualization systems. Arguably, summary statistics and their properties are a somewhat overlooked part of the GoG model^[See also the following quote: "I have tried to build the argument, except for the statistical methods in Chapter 7, from elementary definitions.", pp. 10 of the first-edition preface.]; however, I contend that, when developing interactive data visualizations, grappling with them is essential.

Specifically, I argue that what we can *do* with a graphic is fundamentally determined what the graphics *is*, and summary statistics are an unavoidable part of that. Certain types of plots exhibit a special kind of congruence between data, summary statistics, and visuals, which ensures predictable behavior under interaction. Other types of plots break this congruence, making implementing certain interactive features challenging. However, what is this congruence? To describe it formally, I propose a model leveraging some fundamental algebraic concepts from category theory [see e.g. @fong2019]. These concepts, and my application of them, extends beyond the model developed by @wilkinson2012. Specifically, unlike GoG, which treats data, statistics, and graphics as entirely independent, modular components, I propose a compositional model which focuses on preserving key mathematical properties.

Finally, developing theory is all well and good, but it would be for naught if it did not lead to practical, actionable insights. The end-goal of this work was to provide answers to applied problems that arise when developing interactive data visualization systems. Therefore, to validate and refine the theoretical findings, I also develop an original open-source interactive data visualization library, `plotscaper` (https://github.com/bartonicek/plotscaper). Consequently, parts of this thesis are dedicated to the design and architecture of this system, as well as its application to real-world data. Throughout these sections, I repeatedly explore and elaborate on the connections between the theory and its practical application. 

Ultimately, I contend that, to build truly general and efficient interactive data visualization systems, we need to take both the theory and practice into account. To reiterate the key point, what we can *do* with a visualization is predicated on what the visualization *is*, and algebraic concepts provide a uniquely powerful tool for describing this.  

#### Structure of the thesis

The thesis is organized as follows:

- **Section \@ref(background)** provides a brief overview of the history of interactive data visualization, theoretical considerations regarding interactive graphics as well as common interactive features, and several broader, important topics in data visualization. 
- **Section \@ref(problems)** identifies key challenges in designing interactive data visualization pipelines and introduces some core algebraic theory. 
- **Section \@ref(goals)** outlines the general objectives and goals that guided the development of the interactive data visualization software system (`plotscaper`).
- **Section \@ref(system)** overviews key design and architectural decisions, and discusses key components of the delivered software. 
- **Section \@ref(applied-example)** presents a practical example of applying `plotscaper` to explore a real-world data set. 
- **Section \@ref(discussion)** discusses lessons learned and potential future research directions, covering both the theoretical model and the applied work.
- **Section \@ref(conclusion)** provides some concluding remarks and closing thoughts.
