---
title: "The Algebra of Graphics, Statistics, and Interaction"
subtitle: "Towards Fluent Data Visualization Pipelines"
author: "Adam Bartonicek"
site: bookdown::bookdown_site
documentclass: book
always_allow_html: true
output:
  bookdown::gitbook:
    css: styles.css
  bookdown::pdf_document2:
    latex_engine: xelatex
  bookdown::pdf_book:
    latex_engine: xelatex
bibliography: [references.bib]
biblio-style: "apalike"
link-citations: true
editor_options: 
  chunk_output_type: console
header-includes:
  - \usepackage{tikz-cd}
---

# Abstract 

Placeholder



<!--chapter:end:index.Rmd-->

# Introduction {#introduction}

> It’s written here: ‘In the Beginning was the Word!’ <br>
> Here I stick already! Who can help me? It’s absurd, <br>
> [...] <br>
> The Spirit helps me! I have it now, intact. <br>
> And firmly write: ‘In the Beginning was the Act!
>
> Faust, Part I, Johann Wolfgang von Goethe [-@goethe2015]

Humans are intensely visual creatures. About 20-30% of our brain is involved in visual processing [@van2003; @sheth2016], utilizing a highly sophisticated and powerful visual processing pipeline [see e.g. @goebel2004; @knudsen2020; for a brief review, see @ware2019]. It is well-established the brain can process certain salient visual stimuli in sub-20-millisecond times, outside of conscious attention [@ledoux2000; @ledoux2003], and that people can make accurate, parallel, and extremely rapid visual judgements, in phenomena known as subitizing and pre-attentive processing [@mandler1982; @treisman1985]. These features make the visual cortex the most powerful information channel that humans possess, both in terms of bandwidth and throughput.

Statisticians have known about this power of visual presentation for a long time. Starting with early charts and maps, data visualization co-evolved alongside mathematical statistics, offering an alternative and complementary perspective [for a review, see @friendly2006 or Section \@ref(brief-history)]. While mathematical statistics tended to focus on confirmatory hypothesis testing, data visualization provided avenues for unsupervised exploration, "forcing us to notice that which we would never expect to see" [@tukey1977]. Eventually, this valuable role of forcing us to see the unexpected established data visualization as a respected tool within the applied statistician's toolkit.

Seeing an object from a distance is one thing, but being able to also touch, manipulate, and probe it is another. Within the human brain, action and perception are not independent, but are instead intricately linked, mutually reinforcing processes [see e.g. @dijkerman2007; @lederman2009]. Beginning in the 1970's, statisticians acquired a new set of tools for exploiting this connection. The advent of computer graphics and interactive data visualization transformed the idea of "interrogating a chart" from a mere turn of phrase into tangible reality. All of a sudden, it became possible to work with the visual representation of data in a tactile way, getting new perspectives and insights at the stroke of a key or click of a button. 

This compelling union of the visual and the tactile has made interactive data visualization a popular method of presenting data. Nowadays, there are many packages and libraries for building interactive data visualizations across all the major data analytic languages. Interactive figures make frequent appearance in online news articles and commercial dashboards. However, despite this apparent popularity, significant gaps remain in the use and understanding of interactive visualizations. Individual analysts rarely utilize interactive data visualization in their workflow [see e.g. @batch2017], the availability of certain more sophisticated features is fairly limited (see Section \@ref(background)), and researchers still point to a lack of a general interactive data visualization pipeline [@wickham2009; @vanderplas2020]. 

This thesis explores these interactive data visualization paradoxes and the inherent challenges surrounding interactive data visualization pipelines more specifically. I argue that, contrary to some prevailing views, interactivity is not simply an add-on to static graphics. Instead, interactive visualizations must be designed with interactivity as a primary consideration. Furthermore, I contend that certain interactive features fundamentally influence the types of visualizations that can be effectively presented. My claim is that popular types of interactive visualizations exhibit a particular kind congruence between graphics, statistics, and interaction, and that the absence of this congruence results in suboptimal visualizations. I formalize this congruence using the framework of category theory. Finally, I validate these theoretical concepts by developing an open-source interactive data visualization library and demonstrate its application to real-world data.

#### Thesis Overview

The thesis is organized as follows. Section \@ref(background) reviews the history of interactive data visualization and discusses general trends and issues in the field. Section \@ref(problems), focuses on specific problems encountered when designing an interactive data visualization pipeline. Section \@ref(goals), outlines the the goals and aims that guided the development of the interactive data visualization library. Section \@ref(system) details the system's components and design considerations. Section \@ref(applied-example), presents an applied example of exploring a real-world data set using the developed library. Finally, Section \@ref(discussion), discusses lessons learned and potential future research directions.

<!--chapter:end:introduction.Rmd-->


# Background {#background}

Placeholder


## Brief history of interactive data visualization {#brief-history}
### Static data visualization: From ancient times to the space age
### Early interactive data visualization: By statisticians for statisticians {#early-interactive}
#### Open-source Statistical Computing
#### Common features and limitations of early interactive systems
### Interactive data visualization and the internet: Web-based interactivity {#web-based}
#### D3
#### Plotly and Highcharts
#### Vega and Vega-Lite
#### Common features and limitations of web-based interactive systems
## What even is interactive data visualization? {#what-is-interactive-visualization}
### Interactive vs. interacting with {#interactive-interacting}
### Interactive *enough*?
### Complexity of interactive features {#complexity-of-features}
### Working definition
### Common interactive features {#common-features}
#### Changing size and opacity
#### Zooming and panning
#### Querying
#### Sorting and reordering
#### Parametric interaction
#### Animation and projection
#### Representation switching {#representation-switching}
#### Linked selection {#linked-selection}
## General data visualization theory
### Visualization goals {#visualization-goals}
### Visual perception {#visual-perception}
### Scales and measurement {#scales-measurement}
### Graphics formats {#graphics-formats}
#### Raster graphics
#### Vector graphics

<!--chapter:end:litreview.Rmd-->


# Challenges {#problems}

Placeholder


## The structure of this chapter: Data visualization pipeline
## Partitioning
### Showing the full data {#show-all-data}
### Comparison and disjointness {#comparison-disjointness}
#### The primarcy of disjointness
#### Disjoint visualizations: Real-world example
#### Disjointness and interaction {#disjointness-interaction}
### Plots as partitions
#### Bijection on cases vs. bijection on subsets
#### Products of partitions
#### Limits of flat product partitions
### Partitions, hierarchy, and preorders {#hierarchy}
#### Plots as preorders {#plots-as-preorders}
#### The graph behind the graph
## Aggregation
### The relationship between graphics and statistics
#### Independence: The grammar-based model
#### Motivating example: Limits of independence {#stacking-not-graphical}
#### Some statistics are stackable but others are not
#### Advantages of stacking: Part-whole relations {#stacking-part-whole}
### Stackable summaries: A brief journey into Category Theory
#### Generalizing preorders: Categories {#preorders-categories}
#### Structure preserving maps: Functors
#### Aggregation: A functor from the preorder of data subsets to the preorder of summary statistics {#aggregation-functor}
#### Functorial summaries and set union
#### Whole equal to the sum of its parts: Monoids
#### Programming with monoids
#### Groups and inverses
#### Other properties: monotonicity and commutativity
##### Monotonicity
##### Commutativity
#### Transforming summaries: Stacking, normalizing, and shifting
##### Stacking
##### Normalizing
##### Shifting
## Scaling and encoding {#scaling}
#### Scales as functions
#### Limits of modeling scales with simple functions {#simple-scale-limits}
#### Solution: Scales as function composition {#scales-composition}
##### Reusability and discrete scales
##### The intermediate interval
##### Implementing scale features via the intermediate interval
###### Margins
###### Panning
###### Zooming
##### Inverses
##### Scale transformations
#### Comparison to past implementations of scales
## Rendering
### Frames
### Graphical elements

<!--chapter:end:problems.Rmd-->


# Goals {#goals}

Placeholder


## User profile
## Programming interface
## User interface
## Interactive features

<!--chapter:end:goals.Rmd-->


# High-level design

Placeholder


### User profile
## Programming paradigm
### Imperative programming
### Functional programming
### Object oriented programming
#### Abstraction
#### Encapsulation
#### Polymorphism
#### Inheritance
#### Domain-driven design
#### Criticism of OOP
### Data oriented programming
#### Data first
#### The data
#### The code
##### Encapsulation
##### Inheritance
## Reactivity
## Data representation
#### Row-based vs. column-based
#### Performance
## Rendering engine

<!--chapter:end:design.Rmd-->


# System description {#system}

Placeholder


## Core requirements
## Application Programming Interface (`plotscaper`)
### Basic example
### The scene and the schema {#scene-and-schema}
### HTML document embedding
## Interactive figure platform (`plotscape`)
### Indexable {#Indexable}
### Getter {#Getter}
### Dataframe
### Reactive
### Factors
#### Bijection factors
#### Constant factors
#### String factors
#### Binned factors
#### Product factors
##### Computing product indices
### Reducers
#### Motivation
### Scales {#scales}
#### Overview
#### Limits of modeling scales as simple functions {#simple-scale-limits}
#### Solution: Two-component scales {#two-component-scales}
##### Beyond linear maps
##### Inverses 
##### Some other remarks about the two-component scale system
#### Past implementations of scales
#### Proposed model of scales
##### Zero and one
##### Direction
##### Multipliers
##### The Full Monty
### Expanses
#### Continuous expanses
#### Point expanses
#### Band expanses

<!--chapter:end:system.Rmd-->


# Applied example

Placeholder


### About the data set
### Interactive exploration
#### The relationship between cases and days
#### Number of cases over time
#### Age and child and adolescent mental health
#### Prevalence of diagnoses
#### Prevalence of diagnoses over time
#### Characteristics of patient cohorts over time
## Summary

<!--chapter:end:example.Rmd-->

# Discussion

This thesis explored the role of interaction in data visualization pipelines. More specifically, I investigated how interaction affects the four stages of data visualization pipelines - partitioning, aggregation, scaling, and rendering - and explored the inherent problems and challenges. The main thrust of my argument was that the popular model implied by the Grammar of Graphics [@wilkinson2012], which treats statistics and geometric objects as independent entities, is insufficient for describing the complex relationships between the components of interactive figures [see also @wu2024]. As an alternative, I proposed a simple category-theoretic model, conceptualizing the data visualization pipeline as a functor. 

The essence of the proposed model is the idea that, initially, all visualizations begin as a collection of data subsets. In almost all cases, this collection is not arbitrary, but instead has a special kind of structure: it is a hierarchy of data partitions ordered by set union. To maintain consistency during interactions like linked selection, the subsequent steps of the data visualization pipeline should preserve this structure. In plain words, the geometric objects in our plots and the underlying summary statistics should *behave like set union*. Formally, this means that the mappings from data subsets to summary statistics and from summary statistics to geometric objects should be functors. More specifically, using the properties of set union, we can identify the underlying algebraic structures as either groups or monoids: the operations in our plots should be associative and unital, and also potentially invertible, monotonic, and commutative. When these algebraic constraints are satisfied, the geometric objects in our plots will compose well under selection, meaning that their parts add up to a meaningful whole.     

To validate the proposed model, I developed `plotscaper`, an interactive data visualization R package. In fact, this implementation served as a crucial feedback loop, as many of the theoretical concepts emerged from practical challenges that I encountered during the design of the system. By translating theory into code, I was able to empirically test and refine assumptions about the structure and behavior of interactive data visualizations. 

However, `plotscaper` was also developed to provide a practical tool for data exploration, not just theory testing. As outlined in Section \@ref(background), within the R community, there is currently no shortage of interactive data visualization packages and frameworks; however, many of these offer only fairly limited, shallow kinds of interactivity. Implementing more complex kinds of interaction, such as linked selection, representation switching, and parametric interaction (see section \@ref(common-features)) often requires substantial programming expertise and time-investment, creating a barrier to entry for casual users and solo data analysts [see e.g. @batch2017]. Thus, one of the goals of the project was to try to address this perceived lack of simple and practical tools for interactive data exploration. This hypothesis seems to have been largely proven correct by the package's moderate success - despite its relatively experimental status in comparison to other, far larger and better-established interactive data visualization frameworks, `plotscaper` has been downloaded over `r cranlogs::cran_downloads("plotscaper", from = "2024-10-01", to = Sys.Date())$count |> sum()` times^[The number only includes downloads from the RStudio CRAN mirror.], in the `r as.numeric(Sys.Date() - as.Date("2024-10-19"))` days since its initial release.

However, despite all of these relative successes, both the theoretical model and its practical implementation in `plotscaper` have certain important limitations. These will be the subject of the next few sections.
 
## Limitations of the theoretical model

The first important thing to discuss are the limitations of the theoretical model described in Section \@ref(problems). This model conceptualizes the data visualization pipeline as a structure-preserving mapping - a functor - from the space of data subsets to the space of graphics. This relies on the key assumption that, if we start from a place of structure - a hierarchy of data subsets ordered by set inclusion/union - the subsequent steps of the data visualization pipeline should not discard this structure. Instead, the transformations of our data into summary statistics and aesthetic encodings should flow naturally around this structure. 

Of course, the first possible critique of the model is that not all plot types have to represent distinct data subsets. For example, as discussed in Section \@ref(comparison-disjointness), in certain visualizations of set-typed data, two geometric objects like bars may represent overlapping data subsets [see e.g. @alsallakh2013]. However, as I argued in that section, these types of visualizations are fairly specialized and rare, and, conversely, there is a number of arguments one can make for the "naturality" of typical, disjoint, part-whole objects which we encounter in most everyday plots.  

There are many useful visualization types which do not neatly fit into this model, and many of them may be reconciled with linked selection in some way. However, such reconciliation has to be, by definition, ad hoc.  


<!--chapter:end:discussion.Rmd-->


# Glossary

Placeholder


#### API {#API}
#### Array of Structs (AoS) vs. Struct of Arrays (SoA) {#SoA}
#### JSON {#JSON}
#### IDE
#### SVG

<!--chapter:end:glossary.Rmd-->


# Appendix

Placeholder


#### Encapsulation in DOP {#dop-encapsulation}
## Gauss method and the russian peasant algorithm for monoids {#gauss-russian-monoids}

<!--chapter:end:appendix.Rmd-->


# Mathematical theory

Placeholder


#### Note on past applications of abstract algebra and category theory to data visualization
### Relations {#relations}
### Functions {#functions}
#### More on bijections {#bijections}
#### Composition
#### The image and the pre-image
### Partitions {#partitions}
### Preorders {#preorders}
#### Specializing preorders
#### Structure preserving maps: Monotone maps
### Monoids
#### Simple examples of monoids
#### Beyond numbers
#### Specializing monoids
#### Structure preserving maps: Monoid homomorphisms {#monoid-homomorphism}
### Groups
#### Simple examples of groups
#### Structure preserving maps: Group homomorphisms {#group-homomorphism}
### Categories {#categories}
#### Isomorphisms within categories {#isomorphism}
#### Algebraic structures as categories {#algebraic-as-categories}
### Functors {#functors}

<!--chapter:end:math.Rmd-->

# References


<!--chapter:end:references.Rmd-->

