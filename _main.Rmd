---
title: "The Algebra of Graphics, Statistics, and Interaction"
subtitle: "Towards Fluent Data Visualization Pipelines"
author: "Adam Bartonicek"
site: bookdown::bookdown_site
documentclass: book
always_allow_html: true
output:
  bookdown::gitbook:
    css: styles.css
  bookdown::pdf_document2:
    latex_engine: xelatex
  bookdown::pdf_book:
    latex_engine: xelatex
bibliography: [references.bib]
biblio-style: "apalike"
link-citations: true
editor_options: 
  chunk_output_type: console
header-includes:
  - \usepackage{tikz-cd}
---

# Abstract 

Placeholder



<!--chapter:end:index.Rmd-->

# Introduction {#introduction}

> It’s written here: ‘In the Beginning was the Word!’ <br>
> Here I stick already! Who can help me? It’s absurd, <br>
> [...] <br>
> The Spirit helps me! I have it now, intact. <br>
> And firmly write: ‘In the Beginning was the Act!
>
> Faust, Part I, Johann Wolfgang von Goethe [-@goethe2015]

Humans are intensely visual creatures. About 20-30% of our brain is involved in visual processing [@van2003; @sheth2016], utilizing a highly sophisticated and powerful visual processing pipeline [see e.g. @goebel2004; @knudsen2020; for a brief review, see @ware2019]. It is well-established the brain can process certain salient visual stimuli in sub-20-millisecond times, outside of conscious attention [@ledoux2000; @ledoux2003], and that people can make accurate, parallel, and extremely rapid visual judgements, in phenomena known as subitizing and pre-attentive processing [@mandler1982; @treisman1985]. These features make the visual cortex the most powerful information channel that humans possess, both in terms of bandwidth and throughput.

Statisticians have known about this power of visual presentation for a long time. Starting with early charts and maps, data visualization co-evolved alongside mathematical statistics, offering an alternative and complementary perspective [for a review, see @friendly2006 or Section \@ref(brief-history)]. While mathematical statistics tended to focus on confirmatory hypothesis testing, data visualization provided avenues for unsupervised exploration, "forcing us to notice that which we would never expect to see" [@tukey1977]. Eventually, this valuable role of forcing us to see the unexpected established data visualization as a respected tool within the applied statistician's toolkit.

Seeing an object from a distance is one thing, but being able to also touch, manipulate, and probe it is another. Within the human brain, action and perception are not independent, but are instead intricately linked, mutually reinforcing processes [see e.g. @dijkerman2007; @lederman2009]. Beginning in the 1970's, statisticians acquired a new set of tools for exploiting this connection. The advent of computer graphics and interactive data visualization transformed the idea of "interrogating a chart" from a mere turn of phrase into tangible reality. All of a sudden, it became possible to work with the visual representation of data in a tactile way, getting new perspectives and insights at the stroke of a key or click of a button. 

This compelling union of the visual and the tactile has made interactive data visualization a popular method of presenting data. Nowadays, there are many packages and libraries for building interactive data visualizations across all the major data analytic languages. Interactive figures make frequent appearance in online news articles and commercial dashboards. However, despite this apparent popularity, significant gaps remain in the use and understanding of interactive visualizations. Individual analysts rarely utilize interactive data visualization in their workflow [see e.g. @batch2017], the availability of certain more sophisticated features is fairly limited (see Section \@ref(background)), and researchers still point to a lack of a general interactive data visualization pipeline [@wickham2009; @vanderplas2020]. 

This thesis explores these interactive data visualization paradoxes and the inherent challenges surrounding interactive data visualization pipelines more specifically. I argue that, contrary to some prevailing views, interactivity is not simply an add-on to static graphics. Instead, interactive visualizations must be designed with interactivity as a primary consideration. Furthermore, I contend that certain interactive features fundamentally influence the types of visualizations that can be effectively presented. My claim is that popular types of interactive visualizations exhibit a particular kind congruence between graphics, statistics, and interaction, and that the absence of this congruence results in suboptimal visualizations. I formalize this congruence using the framework of category theory. Finally, I validate these theoretical concepts by developing an open-source interactive data visualization library and demonstrate its application to real-world data.

#### Thesis Overview

The thesis is organized as follows. Section \@ref(background) reviews the history of interactive data visualization and discusses general trends and issues in the field. Section \@ref(problems), focuses on specific problems encountered when designing an interactive data visualization pipeline. Section \@ref(goals), outlines the the goals and aims that guided the development of the interactive data visualization library. Section \@ref(system) details the system's components and design considerations. Section \@ref(applied-example), presents an applied example of exploring a real-world data set using the developed library. Finally, Section \@ref(discussion), discusses lessons learned and potential future research directions.

<!--chapter:end:introduction.Rmd-->


# Background {#background}

Placeholder


## Brief history of interactive data visualization {#brief-history}
### Static data visualization: From ancient times to the space age
### Early interactive data visualization: By statisticians for statisticians {#early-interactive}
#### Open-source Statistical Computing
#### Common features and limitations of early interactive systems
### Interactive data visualization and the internet: Web-based interactivity {#web-based}
#### D3
#### Plotly and Highcharts
#### Vega and Vega-Lite
#### Common features and limitations of web-based interactive systems
## What even is interactive data visualization? {#what-is-interactive-visualization}
### Interactive vs. interacting with {#interactive-interacting}
### Interactive *enough*? {#interactive-enough}
### Complexity of interactive features {#complexity-of-features}
### Working definition
### Common interactive features {#common-features}
#### Changing size and opacity
#### Zooming and panning
#### Querying
#### Sorting and reordering
#### Parametric interaction
#### Animation and projection
#### Representation switching {#representation-switching}
#### Linked selection {#linked-selection}
## General data visualization theory
### Visualization goals {#visualization-goals}
### Visual perception {#visual-perception}
### Scales and measurement {#scales-measurement}
### Graphics formats {#graphics-formats}
#### Raster graphics
#### Vector graphics
## Summary

<!--chapter:end:litreview.Rmd-->


# Challenges {#problems}

Placeholder


## The structure of this chapter: Data visualization pipeline
## Partitioning {#partitioning}
### Showing the full data {#show-all-data}
### Comparison and disjointness {#comparison-disjointness}
#### Naturality of disjointness
#### Disjointness and bijections
#### Disjointness in visualizations: Real-world example
#### Disjointness and interaction {#disjointness-interaction}
### Plots as partitions
#### Bijection on cases vs. bijection on subsets
#### Products of partitions {#products-of-partitions}
#### Limits of flat product partitions
### Partitions, hierarchy, and preorders {#hierarchy}
#### Plots as preorders {#plots-as-preorders}
#### The graph behind the graph
## Aggregation
### The relationship between graphics and statistics
#### Independence: The grammar-based model
#### Motivating example: Limits of independence {#stacking-not-graphical}
#### Some statistics are stackable but others are not {#stackable-or-not}
#### Advantages of stacking: Part-whole relations {#stacking-part-whole}
### Stackable summaries: A brief journey into Category Theory {#aggregation-category-theory}
#### Past applications of category theory to data visualization {#visualization-category-theory}
#### Generalizing preorders: Categories {#preorders-categories}
#### Structure preserving maps: Functors
#### Aggregation: A functor from the preorder of data subsets to the preorder of summary statistics {#aggregation-functor}
#### Functorial summaries and set union
#### Whole equal to the sum of its parts: Monoids {#monoids}
#### Programming with monoids {#programming-with-monoids}
#### Groups and inverses {#groups-inverses}
#### Other properties: monotonicity and commutativity
##### Monotonicity
##### Commutativity
#### Transforming summaries: Stacking, normalizing, and shifting {#transforming-summaries}
##### Stacking
##### Normalizing
##### Shifting
## Scaling and encoding {#scaling}
#### Scales as functions {#scales-as-functions}
#### Limits of modeling scales with simple functions {#simple-scale-limits}
#### Solution: Scales as function composition {#scales-composition}
##### Reusability and discrete scales
##### The intermediate interval {#scaling-intermediate}
##### Implementing scale features via the intermediate interval
###### Margins
###### Panning
###### Zooming
##### Inverses {#scaling-inverses}
##### Scale transformations
#### Comparison to past implementations of scales {#scales-comparison}
## Rendering
### Frames {#frames}
### Graphical elements

<!--chapter:end:problems.Rmd-->

---
output: html_document
editor_options: 
  chunk_output_type: console
---

```{r}
#| echo: false
knitr::opts_chunk$set(
  out.width = "100%",
  out.height = "100%"
)

include_figure <- function(path) {
  if (knitr::is_html_output()) knitr::include_url(path)
  else knitr::include_graphics(gsub(".html", ".png", path))
}

if (knitr::is_html_output()) {
  knitr::opts_chunk$set(
    out.extra = 'style="border: none;"' # Get rid of iframe borders
  )
}
```

# Goals {#goals}

Beyond developing the theory described in Section \@ref(problems), another key objective of this doctoral project was to develop a compatible interactive data visualization system. This was realized through the creation and publication of the R package `plotscaper` (available on [CRAN](https://cran.r-project.org/web/packages/plotscaper/index.html)) and the underlying JavaScript package `plotscape` (available on [NPM](https://www.npmjs.com/package/@abartonicek/plotscape)). This section outlines some general considerations that informed the more specific design choices which will be discussed later on (Section \@ref(system)).

## User profile

A key first step in designing any kind of system is understanding the target audience. This is especially the case in interactive data visualization systems, which cater to a diverse range of users. As was discussed in Section \@ref(background), users of interactive data visualization systems can differ in their goals, experience, and motivation. These user requirements inform the design of interactive visualization systems. At one end of the spectrum, some interactive data visualization systems are designed with fairly minimal expectations of the user's level of experience or motivation. Conversely, other systems assume a highly motivated "expert" users with a sufficient level of domain expertise [@dimara2019] or the ability to contend with low-level execution details such as rendering or reactive event graph [@satyanarayan2015; @satyanarayan2016]. 

My goal was to design a package which would be accessible to a wide range of R users. Specifically, I wanted to empower novice users to quickly and easily create interactive figures for data exploration. Simultaneously, I wanted to provide more advanced users with the flexibility to leverage the full range of features and engage in deeper customization. Balancing these user requirements required some careful consideration. Overall, I generally opted for a simple design, abstracting away many low-level implementation details. Further, I prioritized several key features: a simple API with sensible defaults, a clean and intuitive user interface, and a robust set of built-in interactive capabilities.

## Programming interface

A key concern was designing a simple and intuitive application programming interface ([API]). Specifically, I wanted to make it easy for the average user to learn the package quickly and produce fairly complete and useful interactive figures with only a few lines of R code. The goal was to empower even users with limited programming experience to take advantage of interactive graphics.

Achieving this level of accessibility required several design choices. First, the API had to be relatively familiar. I tried to accomplish this by drawing inspiration from established packages. Specifically, the main inspirations for the `plotscaper` API were the popular `ggplot2` package [@wickham2016], as well as the `iplots` package [@urbanek2003; @urbanek2011]. However, `plotscaper`'s design goals also necessitated some deviations from these packages' APIs, see Section \@ref(system). Second, to further streamline the user experience, many of the components such as scales were given sensible defaults. Conversely, this also meant that extensive graphical customizability was not a primary concern: the goal was to empower the users to start exploring their data quickly, rather than spend time making fine-grained adjustments to the design of their figures. Third, to broaden its appeal, the package had to integrate seamlessly with existing tools within the R ecosystem. These included the popular RStudio [IDE] [@rstudio2024] and the RMarkdown document-authoring system [@xie2018].    

## User interface

While ease of writing user code was a key consideration, equally important was the ease of interpreting and interacting with the resulting visualizations. The visual design of the figures needed to facilitate acquisition of statistical insights, and the figures' behavior had to be clear and intuitive. As was discussed in Section \@ref(background), effective visual design is crucial, as poor design can make figures less legible or even misleading [see e.g. @tufte2001; @cairo2014; @cairo2019; @franconeri2021]. Similarly, the design of interactions can either enhance or hinder the acquisition of insights.

```{r plotscaper-design}
#| echo: false
#| fig-cap: "A simple example of a default `plotscaper` figure. Note the clean design: I opted for no axis ticks or grid lines, and generally muted auxiliary graphical elements to emphasize the data."
include_figure("figures/plotscaper_example1.html")
```

A general rule I applied to the design of the user interface `plotscaper` was "less is more". Specifically, following Tufte's [-@tufte2001] example, I aimed to design figures that would prioritize showing the data above all else, see Figure \@ref(fig:plotscaper-design). Visually, this was achieved by minimizing auxiliary graphical elements such as axis ticks, labels, and grid lines. I also tried to strive for a minimalist "pen and paper" look and feel, as if the figures were drawn in a notebook. For color, I decided to use muted colors for non-data elements and an established color palette for representing the data. Finally, when it came to interactive features, I tried to approach those with similar degree of minimalism. I tried to avoid distracting interactive features, such as having query tool-tips always appear on hover by default, and in general tried to design the user interactions in a way that would complement but not overwhelm the visual experience.

## Interactive features

The next important question was which interactive features to support. As was discussed in Section \@ref(background), there are many interactive data visualization features, and some are more useful than others (for data exploration, anyway). Furthermore, the amount of time and effort required to implement these features also varies considerably. Therefore, choosing the right set of features to prioritize was a key design consideration.

As was hinted at throughout Section \@ref(background), the core feature to implement was generalized linked selection or brushing. Specifically, every plot in `plotscaper` needed to support both dispatching and displaying selection events. This feature is highly desirable because it allows users to quickly explore trends across dynamically-generated subsets of their data, making it one of the most useful tools in the interactive data visualization arsenal [@buja1996; @heer2012; @wilhelm2003; @wilhelm2008; @wills2008; @ware2019; @ward2015]. However, it also requires a significant amount of careful planning and programming effort. Simply adding this functionality on top of an existing static data visualization system does not work. Naive solutions, like replacing the entire plot upon selection, produce unsatisfactory behavior, see for example the following quote by Adalbert Wilhelm from chapter II.9 of the Data Visualization Handbook:

> "[Replacing the entire plot] only works ﬁne when we have individual plot symbols for each observation, as in scatterplots for example, where some attributes are changed by the user interaction. But even when replacing plot parameters the user loses the possibility to compare the current plot with previous versions. The
user can only compare the current image with a mental copy of the previous image and hence the comparison might get distorted."
>
> [@wilhelm2008, pp. 210]

Thus, linked selection had to be directly integrated into the data visualization pipeline, or rather, the data visualization pipeline had to be built around this feature. This was a significant programming challenge. Crucially also, I aimed for a consistent linked selection behavior across *all* implemented plot types. This necessitated careful consideration of the issues discussed in Section \@ref(problems).

Other important features which also had to be directly integrated into the data visualization pipeline were parameter manipulation and representation switching. These features give the user the ability to quickly see alternative views of their data and discover trends that they may otherwise miss (see Sections \@ref(representation-switching)). This makes them highly desirable. 

Another interesting challenge was querying. Upon seeing an interesting visual trend in their data, users may often be interested in the precise data values that produced that visual impression. Thus, being able to interactively query geometric objects is very useful. This feature is arguably simpler to implement than the previously mentioned features, however, it should be noted that what complicates its implementation is that, often, the user does not directly care about the visual attributes of the queried geometric objects, but the instead the statistics underlying those visual attributes. For instance, when querying a stacked barplot, we do not care about the stacked values, but instead about the values corresponding to individual segments. Thus, querying provided an intermediate level of challenge. 

Other interesting feature was bi-directional communication. The ability to call functions in an interactive session and have the figure respond directly can be invaluable in data exploration. However, compared to a static data visualization, this requires a specialized setup, such as having live server respond to messages from the client. Thus, developing a system for communicating between the R client and the JavaScript "backend" (the figure) was necessary.

Finally, there were some useful features which were relatively simple to implement. These included changing size and alpha, zooming, and panning. These features could be implemented by manipulating scales and/or the visual attributes of geometric objects, without modifying earlier stages of the data visualization pipeline. Nevertheless, desppite their simplicity, these features could still be highly useful. For example, zooming and panning can help to reveal trends within narrow data ranges, while adjustments to size and alpha can mitigate overplotting. Therefore, implementing these features was an easy choice.

Some features I did not choose to implement were complex logical selection, semantic zooming, and [LIST OTHERS]. Logical selection refers to the ability of being able to use logical operators such as AND, OR, and XOR with selection events to create more complex selections [see e.g. @theus2008]. While this feature can be undeniably a powerful tool in the hands of more advanced users, its utility for novices is debatable. @wills2000 argued that selection systems should be simple, powerful, and forgiving, and as such, I did not choose to prioritize complex selection operators, opting instead for simple transient/persistent selection. More sophisticated selection operators could also always be implemented later. As for semantic zooming, I did not choose to prioritize this feature since, while also undeniably useful in certain situations, it is fairly complex and applies only to a limited set of plot types such as maps. Generally, I focused on features that could apply across many different plot types, and this gave features like semantic zooming lower priority.

<!--chapter:end:goals.Rmd-->


# High-level design

Placeholder


### User profile
## Programming paradigm
### Imperative programming
### Functional programming
### Object oriented programming
#### Abstraction
#### Encapsulation
#### Polymorphism
#### Inheritance
#### Domain-driven design
#### Criticism of OOP
### Data oriented programming
#### Data first
#### The data
#### The code
##### Encapsulation
##### Inheritance
## Reactivity
## Data representation
#### Row-based vs. column-based
#### Performance
## Rendering engine

<!--chapter:end:design.Rmd-->


# System description {#system}

Placeholder


## Core requirements
## High-level API (`plotscaper`) {#high-level-api}
### API design {#api-design}
### Basic example {#basic-example}
#### Figure vs. plot and selectors {#figure-plot}
#### Variable names
#### Variables and encodings {#variables-encodings}
### The scene and the schema {#scene-and-schema}
### Client-server communication {#communication}
### HTML embedding
## Low-level implementation (`plotscape`) {#low-level-implementation}
### Reactivity
#### Observer pattern {#observer}
#### Streams
#### Virtual DOM
#### Signals {#signals}
#### Reactivity in `plotscape` and final thoughts {#reactivity-solution}
### System components
#### Indexable {#Indexable}
#### Getter {#Getter}
#### Dataframe
#### Factors
##### Bijection and constant factors
##### Discrete factors
##### Binned factors
##### Product factors
#### Marker
##### Transient vs. persistent selection {#transient-persistent}
##### Group assignment indices {#group-indices}
##### Updating group assignment indices
#### Aggregation: Reducers, reduceds, and summaries {#aggregation-summaries}
##### Reducers {#reducers}
##### Reduced
##### Summaries {#summaries}
#### Scales {#scales}
##### Scale properties
#### Expanses
#### Continuous expanses
#### Point expanses
#### Band expanses
##### Compound and split expanses
#### Plot {#plot}
##### Data {#plot-data}
##### Scales {#plot-scales}
##### Rendering {#plot-rendering}
#### Events and interactive features
##### Activation and deactivation
##### Growing/shrinking objects
##### Mouse-move interaction: selection, panning, and zooming {#plot-mousemove}
####### Selection
####### Panning
####### Querying
#### Zooming
#### Scene {#scene}
##### Plots
##### Marker
##### WebSockets client
##### Events and Keybindings

<!--chapter:end:system.Rmd-->


# Applied example {#applied-example}

Placeholder


### About the data set
### Interactive exploration
#### The relationship between cases and days
#### Number of cases over time
#### Age and child and adolescent mental health
#### Prevalence of diagnoses
#### Prevalence of diagnoses over time
#### Characteristics of patient cohorts over time
## Summary

<!--chapter:end:example.Rmd-->


# Discussion

Placeholder


## Limitations of the theoretical model
### Why the model is necessary
### Disjointness
### Associativity and unitality
### Model constraints
## Limitations of the software
### Scope and features
### Declarative schemas {#declarative-schemas}
### Performance {#performance}

<!--chapter:end:discussion.Rmd-->


# Glossary

Placeholder


#### API {#API}
#### Array of Structs (AoS) vs. Struct of Arrays (SoA) {#SoA}
#### JSON {#JSON}
#### IDE
#### SVG

<!--chapter:end:glossary.Rmd-->


# Appendix

Placeholder


#### Encapsulation in DOP {#dop-encapsulation}
## Gauss method and the russian peasant algorithm for monoids {#gauss-russian-monoids}

<!--chapter:end:appendix.Rmd-->


# Mathematical theory

Placeholder


### Relations {#relations}
### Functions {#functions}
#### More on bijections {#bijections}
#### Composition
#### The image and the pre-image
### Partitions {#partitions}
### Preorders {#preorders}
#### Specializing preorders
#### Structure preserving maps: Monotone maps
### Monoids
#### Simple examples of monoids
#### Beyond numbers
#### Specializing monoids
#### Structure preserving maps: Monoid homomorphisms {#monoid-homomorphism}
### Groups
#### Simple examples of groups
#### Structure preserving maps: Group homomorphisms {#group-homomorphism}
### Categories {#categories}
#### Isomorphisms within categories {#isomorphism}
#### Algebraic structures as categories {#algebraic-as-categories}
### Functors {#functors}

<!--chapter:end:math.Rmd-->

# References


<!--chapter:end:references.Rmd-->

