---
output: html_document
editor_options: 
  chunk_output_type: console
---

# Goals {#goals}

The primary aim of this doctoral project was to develop an original interactive data visualization system, while attempting to provide solutions to the problems described in Section \@ref(problems). This was realized through the creation and publication of the R package `plotscaper` (available on [CRAN](https://cran.r-project.org/web/packages/plotscaper/index.html)) and the underlying JavaScript package `plotscape` (available on [NPM](https://www.npmjs.com/package/@abartonicek/plotscape)). This section outlines some general concerns that informed the more specific design decisions that will be discussed in Section \@ref(system).

## User profile

A key first step in designing any kind of system is understanding the target audience. This is especially the case in interactive data visualization systems, which cater to a diverse range of users. As was discussed in Section \@ref(litreview), users of interactive data visualization systems can differ in their analysis goals, experience, and motivation. At one end of the spectrum, some interactive data visualization systems are designed with fairly minimal expectations of the user's level of experience or motivation. Conversely, other systems assume a highly motivated "expert" users with a sufficient level of domain expertise [@dimara2019] or the ability to contend with low-level execution details such as rendering or reactive event graph [@satyanarayan2015; @satyanarayan2016]. 

The goal was to design a package for interactive data exploration that would be accessible to a wide range of R users. Specifically, I wanted to enable even the novice users to quickly create comprehensive interactive figures they could use to explore their data, while, at the same time, allowing more advanced users to take advantage of the full range of features and engage in deeper customization.  This necessitated a generally simple design, with low-level implementation details abstracted away. Consequently, the design prioritized several key features: a simple API with sensible defaults, a clean and intuitive user interface, and a robust set of built-in interactive capabilities.

## Programming interface

To make the package accessible to a wide range of R users, a key concern was designing a simple and intuitive application programming interface ([API]). Specifically, I wanted to make it easy for the average user to learn the package and produce fairly complete and useful interactive figures, with only few lines of R code. Ideally, the package should empower even users with limited programming experience to take advantage of interactive graphics.

Achieving this level of accessibility required several design choices. First, the API had to be easy to learn. I tried to accomplish this by drawing inspiration from established packages. Specifically, the main inspirations for the `plotscaper` API were the popular `ggplot2` package [@wickham2016], as well as the `iplots` package [@urbanek2003; @urbanek2011]. However, `plotscaper`'s design goals also necessitated some deviations from these packages' APIs, see Section \@ref(system). Second, to further simplify the API, many of the components such as scales had to be given sensible defaults. Conversely, this also meant that extensive customizability was not a primary concern: the goal was to empower the users to start exploring their data quickly, rather than spend time making fine-grained adjustments to their figures. Third, to broaden its appeal, the package had to integrate seamlessly with existing tools within the R ecosystem. These included the popular RStudio [IDE] [@rstudio2024] and the RMarkdown document-authoring system [@xie2018].    

## User interface

While ease of writing user code was a key consideration, equally important was the ease of interpreting and interacting with the resulting visualizations. The visual design of the figures needed to promote acquisition of statistical insights, and the figures' interactive behavior had to be clear and intuitive. As was discussed in Section \@ref(litreview), effective visual design is of key impoertance, as poor design can make figures less legible or even misleading [see e.g. @tufte2001; @cairo2014; @cairo2019; @franconeri2021]. Similarly, the design of interactions can either enhance or hinder the acquisition of insights.

A general rule I applied to the design of the user interface `plotscaper` was "less is more". Specifically, following Tufte's [-@tufte2001] example, I aimed to design figures that would prioritize showing the data above all else. Visually, this was achieved by minimizing auxiliary graphical elements such as axis ticks, labels, and grid lines. I also tried to strive for a minimalist "pen and paper" look and feel, as if the figures were drawn in a notebook. For color, I decided to use muted colors for non-data elements and an established color palette for representing the data. Finally, when it came to interactive features, I tried to approach those with similar degree of minimalism. I tried to avoid distracting interactive features, such as having query tool-tips always appear on hover by default, and in general tried to design the user interactions in a way that would complement but not overwhelm the visual experience.

## Interactive features

The next important question was which interactive features to support. As was discussed in Section \@ref(litreview), there are many interactive data visualization features, and some are more useful than others (for data exploration, anyway). Furthermore, the amount of time and effort required to implement these features also varies considerably. Therefore, choosing the right set of features to prioritize was a key design consideration.

As was hinted at throughout Section \@ref(litreview), the core feature to implement was generalized linked selection or brushing. Specifically, every plot in `plotscaper` needed to support both dispatching and displaying selection events. This feature is highly desirable because it allows users to quickly explore trends across dynamically-generated subsets of their data, making it one of the most useful tools in the interactive data visualization arsenal [@buja1996; @heer2012; @wilhelm2003; @wilhelm2008; @wills2008; @ware2019; @ward2015]. However, it also requires a significant amount of careful planning and programming effort. Simply adding this functionality on top of an existing static data visualization system does not work. Naive solutions, like replacing the entire plot upon selection, produce unsatisfactory behavior, see for example the following quote by Adalbert Wilhelm from chapter II.9 of the Data Visualization Handbook:

> "[Replacing the entire plot] only works ï¬ne when we have individual plot symbols for each observation, as in scatterplots for example, where some attributes are changed by the user interaction. But even when replacing plot parameters the user loses the possibility to compare the current plot with previous versions. The
user can only compare the current image with a mental copy of the previous image and hence the comparison might get distorted."
>
> [@wilhelm2008, pp. 210]

Thus, linked selection had to be directly integrated into the data visualization pipeline, or rather, the data visualization pipeline had to be built around this feature. This was a significant programming challenge. Crucially also, I aimed for a consistent linked selection behavior across *all* implemented plot types. This necessitated careful consideration of the issues discussed in Section \@ref(problems).

Other important features which also had to be directly integrated into the data visualization pipeline were parameter manipulation and representation switching. These features give the user the ability to quickly see alternative views of their data and discover trends that they may otherwise miss (see Sections \@ref(changing-representation)). This makes them highly desirable. 

Another interesting challenge was querying. Upon seeing an interesting visual trend in their data, users may often be interested in the precise data values that produced that visual impression. Thus, being able to interactively query geometric objects is very useful. This feature is arguably simpler to implement than the previously mentioned features, however, it should be noted that what complicates its implementation is that, often, the user does not directly care about the visual attributes of the queried geometric objects, but the instead the statistics underlying those visual attributes. For instance, when querying a stacked barplot, we do not care about the stacked values, but instead about the values corresponding to individual segments. Thus, querying provided an intermediate level of challenge. 

Other interesting feature was bi-directional communication. The ability to call functions in an interactive session and have the figure respond directly can be invaluable in data exploration. However, compared to a static data visualization, this requires a specialized setup, such as having live server respond to messages from the client. Thus, developing a system for communicating between the R client and the JavaScript "backend" (the figure) was necessary.

Finally, there were some useful features which were relatively simple to implement. These included changing size and alpha, zooming, and panning. These features could be implemented by manipulating scales and/or the visual attributes of geometric objects, without modifying earlier stages of the data visualization pipeline. Nevertheless, desppite their simplicity, these features could still be highly useful. For example, zooming and panning can help to reveal trends within narrow data ranges, while adjustments to size and alpha can mitigate overplotting. Therefore, implementing these features was an easy choice.

Some features I did not choose to implement were complex logical selection, semantic zooming, and [LIST OTHERS]. Logical selection refers to the ability of being able to use logical operators such as AND, OR, and XOR with selection events to create more complex selections [see e.g. @theus2008]. While this feature can be undeniably a powerful tool in the hands of more advanced users, its utility for novices is debatable. @wills2000 argued that selection systems should be simple, powerful, and forgiving, and as such, I did not choose to prioritize complex selection operators, opting instead for simple transient/persistent selection. More sophisticated selection operators could also always be implemented later. As for semantic zooming, I did not choose to prioritize this feature since, while also undeniably useful in certain situations, it is fairly complex and applies only to a limited set of plot types such as maps. Generally, I focused on features that could apply across many different plot types, and this gave features like semantic zooming lower priority.

```{r}
#| echo: false
#| out-extra: 'style="border: none;"'
knitr::include_url("./figures/example-cases-days.html")
```
