[["litreview.html", "3 Background 3.1 Brief history of interactive data visualization 3.2 What even is interactive data visualization? 3.3 General data visualization theory", " 3 Background 3.1 Brief history of interactive data visualization Data visualization has a rich and intricate history, and a comprehensive treatment is beyond the scope of the present thesis. Nevertheless, in this section, I will provide a brief overview, with a particular focus on the later developments related to interactive visualization. For a more detailed historical account, readers should refer to Beniger and Robyn (1978), Dix and Ellis (1998), Friendly (2006), Friendly and Wainer (2021), or Young, Valero-Mora, and Friendly (2011). 3.1.1 Static data visualization: From ancient times to the space age The idea of graphically representing abstract information is very old. As one concrete example, a clay tablet recording a land survey during the Old Babylonian period (approximately 1900-1600 BCE) has recently been identified as the earliest visual depiction of the Pythagorean theorem (Mansfield 2020). Other examples of early abstract visualizations include maps of geographic regions and the night sky, and these were also the first to introduce the idea of coordinate systems (Beniger and Robyn 1978; Friendly and Wainer 2021). Figure 3.1: Photos of the tablet Si. 427 which has recently been identified as the earliest depiction of the Pythagorean theorem (Mansfield 2020). Left: the obverse of the tablet depicts a diagram of a field, inscribed with areas. Right: the reverse of the tablet contains a table of numbers, corresponding to the calculation of the areas. Source: Wikimedia Commons (Mansfield 2018). For a long time, coordinate systems remained tied to geography and maps. However, with the arrival of the early modern age, this was about to change. In the 16-17th century, the works of the 9th century algebraist Al-Khwarizmi percolated into Europe, and with them the idea of representing unknown quantities by variables (Kvasz 2006). This idea culminated with Descartes, who introduced the concept of visualizing algebraic relationships as objects in a 2D plane, forging a powerful link between Euclidean geometry and algebra (Friendly and Wainer 2021). Coordinate systems were thus freed of their connection to geography, and the x- and y-axes could now be used to represent an arbitrary “space” spanned by two variables. Descartes’ invention of drawing abstract relationships as objects in a 2D plane was initially only used to plot mathematical functions. However, it would not be long until people realized that observations of the real world could be visualized as well. A true pioneer in this arena was William Playfair, who popularized visualization as a way of presenting socioeconomic data and invented many types of plots still in use today, such as the barplot, lineplot, and pie chart (Friendly and Wainer 2021). Further, with the emergence of modern nation states in the 19th century, the collection of data and statistics (“things of the state,” Online Etymology Dictionary 2024) became widespread, leading to a “golden age” of statistical graphics (Beniger and Robyn 1978; Friendly and Wainer 2021; Young, Valero-Mora, and Friendly 2011). This period saw the emergence of other graphical lumnaries, such as Étienne-Jules Marey and Charles Joseph Minard (Friendly and Wainer 2021), as well as some ingenious examples of the use of statistical graphics to solve real-world problems, including John Snow’s investigation into the London cholera outbreak (Freedman 1999; Friendly and Wainer 2021) and Florence Nightingale’s reporting on the unsanitary treatment of wounded British soldiers during the Crimean War (Brasseur 2005), both of which lead to a great reduction of preventable deaths. Simultaneously, the field of mathematical statistics was also experiencing significant developments. Building upon the foundation laid by mathematical prodigies such as Jakob Bernoulli, Abraham de Moivre, Pierre Simon Laplace, and Carl Friedrich Gauss, early 19th century pioneers such as Adolph Quetelet and Francis Galton began developing statistical techniques for uncovering hidden trends in the newly unearthed treasure trove of socioeconomic data (Fienberg 1992; Freedman 1999). In the late 19th and early 20th century, these initial efforts were greatly advanced by the theoretical work of figures such as Karl Pearson, Ronald A. Fisher, Jerzy Neyman, and Harold Jeffreys, who established statistics as a discipline in its own right and facilitated its dissemination throughout many scientific fields (Fienberg 1992). As mathematical statistics gained prominence in the early 20th century, data visualization declined. Perceived as less rigorous than “serious” statistical analysis, it got relegated to an auxiliary position, ushering in “dark age” of statistical graphics (Friendly 2006; Young, Valero-Mora, and Friendly 2011). This development may have been partly driven by the early frequentist statisticians’ aspiration to establish statistics as a foundation for determining objective truths about the world and society, motivated by personal socio-political goals (see Clayton 2021). Be it as it may, while statistical graphics also did get popularized and entered the mainstream during this time, only a few interesting developments took place (Friendly and Wainer 2021). However, beginning in the late 1950’s, a series of developments took place which would restore the prominence of data visualization and make it more accessible than ever. Firstly, on the theoretical front, the work of certain academic heavy-weights greatly elevated data visualization and its prestige. Particularly, John Tukey (1962; 1977) fervently championed exploratory data analysis and placed data visualization in its centre. Around the same time, Jacques Bertin published his famous Sémiologie graphique (1967), which was one of the first works to attempt to lay out a comprehensive system of visual encodings and scales. Secondly, at the more applied level, the development of personal computers (see e.g. Abbate 1999) and high-level programming languages such as FORTRAN in 1954 (Backus 1978), made the process of rendering production-grade figures easier and more accessible than ever before. Combined, these developments fueled a surge in the use and dissemination of data visualizations. As the millennium drew to a close, several other important developments solidified the foundation of static data visualization. First, William Cleveland made significant contributions to the field, laying out many important principles for scientific data visualization (Cleveland 1985, 1993). Of note, his seminal study on the impact of the choice of visual encodings on statistical judgements remains widely cited today (Cleveland and McGill 1984). Similarly, Edward Tufte introduced essential principles for designing effective graphics, coining terms such as chartjunk and data-to-ink ratio (Tufte 2001). Finally, Leland Wilkinson’s groundbreaking Grammar of Graphics (2012) introduced a comprehensive system for designing charts based on simple algebraic rules, influencing nearly every subsequent software package and research endeavor in the field of visualization. 3.1.2 Early interactive data visualization: By statisticians for statisticians Compared to static data visualization, interactive data visualization is much more of a recent development. Consequently, less has been written about its history, owing to the shorter timeline, as well as the rapid evolution of software in the time since its inception and the proprietary nature of some systems. Nevertheless, the brief history of interactive data visualization is still rather compelling. Following the boom of static data visualization in the 1950’s, interactive data visualization would not be left far behind. It started with tools designed for niche, specialized tasks. For example, Fowlkes (1969) designed a system which allowed the users to view probability plots under different configurations of parameters and transformations, whereas Kruskal (1965) created a tool for visualizing multidimensional scaling. Figure 3.2: John Tukey showcasing the PRIM-9 system (left), with an example of a projected scatterplot (right, Fisherkeller, Friedman, and Tukey 1974). Screenshots were taken from a video available at: ASA Statistical Graphics Video Library) However, researchers soon recognized the potential of interactive data visualization as a general-purpose tool for exploring data. The first such general-purpose system was PRIM-9 (Fisherkeller, Friedman, and Tukey 1974). PRIM-9 allowed for exploration of multivariate data via interactive features such as projection, rotation, masking, and filtering. Following PRIM-9, the late 1980’s saw the emergence of a new generation of systems which provided an even wider range of capabilities. Tools like MacSpin (Donoho, Donoho, and Gasko 1988), Data Desk (Velleman and Paul 1989), XLISP-Stat (Tierney 1990), and XGobi (Swayne, Cook, and Buja 1998) introduced features such as interactive scaling, rotation, linked views, and grand tours (for a glimpse into these systems, excellent video-documentaries are available at ASA Statistical Graphics Video Library). 3.1.2.1 Open-source Statistical Computing The proliferation of open-source, general-purpose statistical computing software such as S and R further democratized the access to interactive data visualization tools. Building on XGobi’s foundation, GGobi (Swayne et al. 2003), expanded upon on XGobi and provided an integration layer for R. Other tools like MANET (Unwin et al. 1996) and Mondrian (Theus 2002) introduced sophisticated linking techniques, with features such as selection sequences, allowing the users to combine a series of selections via logical operators (see also Unwin et al. 2006). Additionally, iPlots (Urbanek and Theus 2003) implemented a general framework for interactive plotting in R, allowing not only for one-shot rendering interactive figures from R but also for direct programmatic manipulation. This package was later expanded expanded for big data capabilities in iPlots eXtreme (Urbanek 2011). Figure 3.3: Examples of interactive features in Mondrian (Theus 2002): selection operators (left) and mosaic plot with querying (right). Other interactive data visualization packages developed for R tended to focus on specific methods and techniques. For instance, KLIMT was developed for interactive visualization of classification and regression trees (Urbanek and Unwin 2001; Urbanek 2002). Similarly, packages like tourr (Wickham 2011) and liminal (Lee 2021; Lee, Laa, and Cook 2022) provided functionalities for exploring large multivariate data sets via grand tour projections (see Cook et al. 1995). Overall, over time, within the R community, there seems to have been a trend towards more of these specialized tools, and the development of general-purpose interactive data visualization frameworks seems to have become less prevalent (although there are some notable exceptions, such as the loon package, Waddell and Oldford 2023). Currently, it seems that R users typically encounter interactive visualizations as part of Shiny (Chang et al. 2024) dashboards, or through R wrappers of interactive data visualization packages from the JavaScript ecosystem (see Section 3.1.3). 3.1.2.2 Common features and limitations of early interactive systems A common thread among these interactive data visualization systems is that they were designed by statisticians with primary focus on data exploration. High-level analytic features such as linked views, rotation/projection, and interactive manipulation of model parameters made frequent appearance. While these features were powerful, they also contributed to a steeper learning curve, potentially limiting adoption by users without a strong data analytic background. Furthermore, these early tools were typically standalone applications, with only later packages like GGobi and iplots offering integration with other data analysis software and languages. Finally, they often offerered only limited customization options and this made them less suitable for data presentation. 3.1.3 Interactive data visualization and the internet: Web-based interactivity The end of the millennium marked the arrival of a new class of technologies which impacted interactive data visualization just as much as almost every other field of human endeavor. The rise of the internet in the mid 1990’s made it possible to create interactive applications that could be accessed by anyone, from anywhere. This was aided by the dissemination of robust and standardized web browsers, as well as the development of JavaScript as a high-level programming language for the web (for a tour of the language’s history, see e.g. Wirfs-Brock and Eich 2020). Soon, interactive visualizations became just one of many emerging technologies within the burgeoning web ecosystem. Early web-based interactive data visualization systems tended to rely on external plugins. Examples of these include Prefuse (Heer, Card, and Landay 2005) and Flare (developed around 2008, Blokt 2020), which leveraged the Java runtime and Adobe Flash Player, respectively. However, as browser technologies advanced, particularly as JavaScript’s performance improved thanks to advances in just-in-time compilation (JIT, see e.g. Clark 2017; Dao 2020), it became possible to create complex interactive experiences directly in the browser. This led to the emergence of several popular web-native interactive data visualization systems in the early 2010s, many of which remain widely used today. 3.1.3.1 D3 D3.js (Bostock 2022) is one of the earliest and most influential web-based visualization systems. As a general, low-level framework for visualizing data, D3 provides of a suite of specialized JavaScript modules for various aspects of the data visualization workflow, including data parsing, transformation, scaling, and DOM interaction. For instance, here’s how to create a basic scatterplot in D3: import * as d3 from &quot;d3&quot;; const plot = document.querySelector&lt;HTMLDivElement&gt;(&quot;#d3-plot&quot;)!; const data = [ { x: 1, y: 0.41 }, { x: 2, y: 4.62 }, { x: 3, y: 7.62 }, { x: 4, y: 6.54 }, { x: 5, y: 9.61 }, ]; const margin = { top: 10, right: 30, bottom: 30, left: 60 }; const width = parseFloat(plot.style.width); const height = parseFloat(plot.style.height); // Create a SVG element, resize it, and append it to #d3-plot const svg = d3 .select(&quot;#d3-plot&quot;) .append(&quot;svg&quot;) .attr(&quot;width&quot;, width + margin.left + margin.right) .attr(&quot;height&quot;, height + margin.top + margin.bottom) .append(&quot;g&quot;) .attr(&quot;transform&quot;, &quot;translate(&quot; + margin.left + &quot;,&quot; + margin.top + &quot;)&quot;); // Create x and y scales and append them to const scaleX = d3.scaleLinear().domain([0, 6]).range([0, width]); const scaleY = d3.scaleLinear().domain([10, 0]).range([0, height]); svg .append(&quot;g&quot;) .attr(&quot;transform&quot;, &quot;translate(0,&quot; + height + &quot;)&quot;) .call(d3.axisBottom(scaleX)); svg.append(&quot;g&quot;).call(d3.axisLeft(scaleY)); // Add points svg .append(&quot;g&quot;) .selectAll(&quot;dot&quot;) .data(data) .enter() .append(&quot;circle&quot;) .attr(&quot;cx&quot;, (d) =&gt; scaleX(d.x)) .attr(&quot;cy&quot;, (d) =&gt; scaleY(d.y)) .attr(&quot;r&quot;, 2); Figure 3.4: Example of a scatterplot in D3.js. The code was taken from D3 Graph Gallery (Holtz 2022b) and adjusted to use ES6 syntax and slightly more informative variable names/comments. As you can see from Figure 3.4 and the corresponding code, D3 is a fairly low-level framework. Compared to typical high-level plotting functionalities such as those provided by base R or ggplot2 (R Core Team 2024; Wickham 2016), the user has to handle many low-level details such as scaling and appending of primitives explicitly. This is also the case with interaction. While D3 does provide methods for handling interactive DOM events, it does not itself provide a system for dispatching and coordinating these events - it instead delegates this responsibility to the user and encourages the use of reactive Web frameworks such as React (Meta 2024), Vue (Evan You and the Vue Core Team 2024), or Svelte (Rich Harris and the Svelte Core Team 2024). Finally, D3.js visualizations are rendered as Scalable Vector Graphics (SVG) by default. This ensures lossless scaling but may impact rendering performance at high data volumes. While various unofficial alternative rendering engines based on the HTML 5 Canvas element or WebGL, do exist, there are no such official libraries as of this date. 3.1.3.2 Plotly and Highcharts Building upon the low-level infrastructure that D3 provides, many packages such as Plotly.js (Plotly Inc. 2022) and Highcharts (Highsoft 2024) provide high-level abstractions which make the process of building interactive figures easier for the average user. Unlike D3 which provides low-level utilities such as data transformations, scales, and geometric objects, these packages provide a simple declarative framework for rendering entire plots using a static JSON schema. Here’s how to render the same scatterplot in Plotly: const data = [{ x: [1, 2, 3, 4, 5, 6], y: [0.41, 4.62, 7.62, 6.54, 9.61], mode: &#39;markers&#39;, type: &#39;scatter&#39; }]; Plotly.newPlot(&#39;app&#39;, data); Figure 3.5: Example of a scatterplot in Plotly.js. The code was taken from the official Plotly documentation (Plotly Inc. 2024b) and slightly simplified. Clearly, compared with the D3 code used to create Figure 3.4, the code for creating Figure 3.5 is much terser. Many details, such as the axis limits and margins, point size and colour, gridlines, and widgets, are handled implicitly, via default values and automatic inference. Also, note that the figure provides some interactive features by default, such as zooming, panning, and tooltip on hover. Reactivity is handled automatically using systems built on the native DOM Event Target interface (MDN 2024). Highcharts provides a similar JSON-based interface for specifying plots. While perhaps slightly more flexible than Plotly, it also requires more verbose specifications. Because of the similarity, I will not provide a separate example here (interested reader should look up the library website, Highsoft 2024). Finally, like D3, both plotly.js and Highcharts also render the graphics in SVG by default. However, unlike D3, they both also provide alternative rendering engines based on WebGL (Highsoft 2022; Plotly Inc. 2024a). This makes them more ergonomic for use with large data sets. 3.1.3.3 Vega and Vega-Lite Vega (Satyanarayan et al. 2015; Vega Project 2024d) is another popular interactive data visualization package. Like Plotly and Highcharts, Vega is also partially built upon the foundation of D3 and uses JSON schema for plot specification. However, Vega is more low-level and implements a lot of custom functionality. This allows it to offer more fine-grained customization of graphics and interactive behavior, leading to greater flexibility. However, this added flexibility does come at a cost. Compared to the high-level frameworks like Plotly and Highcharts, Vega is significantly more verbose. For instance, creating a scatterplot matrix with linked selection in Vega requires over 300 lines of JSON specification, not including the data and using default formatting (Vega Project 2024b). Vega-Lite (Satyanarayan et al. 2015) attempts to remedy this complexity by providing a high-level interface to Vega. Here’s how we can define a scatterplot with zooming, panning, and tooltip on hover in Vega-Lite: const spec = { $schema: &quot;https://vega.github.io/schema/vega-lite/v5.json&quot;, width: 500, height: 500, data: { values: [ { x: 1, y: 0.41 }, { x: 2, y: 4.62 }, { x: 3, y: 7.62 }, { x: 4, y: 6.54 }, { x: 5, y: 9.61 }] }, mark: {&quot;type&quot;: &quot;point&quot;, &quot;tooltip&quot;: true}, encoding: { x: { field: &quot;x&quot;, type: &quot;quantitative&quot; }, y: { field: &quot;y&quot;, type: &quot;quantitative&quot; } }, params: [{ name: &quot;grid&quot;, select: &quot;interval&quot;, bind: &quot;scales&quot; }] }; vegaEmbed(&quot;#vegalite-plot&quot;, spec); Note that the zooming and panning capability is provided by the params property, which declaratively specifies a list of plot parameters that can be modified by interaction (see Vega Project 2024c). In the case above, the specification creates a two-way binding between plot scales and mouse selection events (Vega Project 2024a). 3.1.3.4 Common features and limitations of web-based interactive systems In general, these contemporary web-based interactive data visualization systems offer a great deal of flexibility, making them well-suited to modern data presentation. However, all of this expressiveness does seem to come at a cost. Compared to the earlier statistical graphics systems, described in Section 3.1.2, many of the more advanced features that used to be common are either missing or require a significant effort to implement, such that they are only accessible to expert users. This is evidenced by their infrequent appearance in documentation and example gallery pages. For instance, the R Graph Gallery entry on Interactive Charts (Holtz 2022a) features multiple interactive figures implemented in the JavaScript libraries described above. However, all of these examples show only surface-level, single-plot interactive features such zooming, panning, hovering, 3D rotation, and node repositioning. The Plotly Dash documentation page on Interactive Visualizations (Plotly Inc. 2022) does feature two examples of simple linked cross-filtering, however, the vast majority of visualizations in the Plotly R Open Source Graphing Library documentation page (Plotly Inc. 2022) show examples only surface-level interactivity. Similarly, VegaLite Gallery pages on Interactive Charts (Vega Project 2022) feature many examples, however, only a limited number of examples show linked or parametric interactivity (see e.g. Interactive Multiview Displays). Finally, the Highcharter Showcase Page (Kunst 2022) does not feature any examples of linking. Even when advanced features such as linking and parametric manipulation are supported, they are often limited in some way. For example, the following is a quote from the website of Crosstalk, a package designed to enable linking in R, using web-based interactive widgets created with the htmlwidgets package (Vaidyanathan et al. 2021) or R Shiny (Chang et al. 2024): “Crosstalk currently only works for linked brushing and filtering of views that show individual data points, not aggregate or summary views (where “observations” is defined as a single row in a data frame). For example, histograms are not supported since each bar represents multiple data points; but scatter plot points each represent a single data point, so they are supported.” Posit (formerly RStudio Inc.) (2025) Of course, with enough effort, these web-based visualization systems can still be used to create rich figures with advanced interactive features such as linked views and parametric interaction. However, implementing these features often requires stepping down a level of abstraction and dealing with low-level language primitives. This defeats the purpose of using a high-level libraries and creates a barrier to entry for casual users (Keller, Manz, and Gehlenborg 2024). It also may explain why interactive visualizations are nowadays mainly used for data presentation, not data exploration (Batch and Elmqvist 2017). With the high upfront cost of learning these package’s APIs, creating rich interactive figures may be a task best suited for dedicated developers working inside large organizations, rather than individual researchers/analysts. 3.2 What even is interactive data visualization? If it looks like a duck, swims like a duck, and quacks like a duck, then it probably is a duck. […] The irony is that while the phrase is often cited as proof of abductive reasoning, it is not proof, as the mechanical duck is still not a living duck Duck Test entry, (Wikipedia 2022) In the previous section (Section 3.1), I provided an overview of the history and present state of interactive data visualization, discussing a number of features and systems. However, while doing so, I avoided one crucial question: what constitutes an interactive data visualization? Surprisingly, despite the widespread popularity of interactive visualizations, there is no universally agreed-upon definition of interactivity. Within the data visualization literature, the terms “interactive” and “interaction” are rarely explicitly defined. And even when they are, the definitions are often incongruent or even contradictory (see e.g. Dimara and Perin 2019; Elmqvist et al. 2011; Pike et al. 2009). Finally, similar conceptual ambiguity extends to other terms commonly used in the field, such as a “dashboard” (Sarikaya et al. 2018). This lack of a clear consensus makes the task of discussing interactive data visualization difficult. Ignoring the issue could lead to confusion, while a truly comprehensive dive into the terminology surrounding interactive data visualization could become excessively verbose, as evidenced by the existence of research papers dedicated to the topic (see e.g. Dimara and Perin 2019; Elmqvist et al. 2011). To address this issue, this section aims to provide a concise overview of how interactivity has been conceptualized in the literature. The goal is to establish a clear framework for understanding “interactive” and “interaction” within the context of this thesis. 3.2.1 Interactive vs. interacting with First, the word “visualization” in “interactive data visualization” can be interpreted in two different ways: As a noun: a concrete chart or figure As a nominalized verb: the process of interacting with a figure In data visualization literature, both interpretations are frequently used, leading to significant ambiguity (Dimara and Perin 2019; Pike et al. 2009; see also Yi et al. 2007). On one hand, some researchers focus on the mathematical and computational aspects of visualization, discussing specific systems and implementations (see e.g. Buja, Cook, and Swayne 1996; Kelleher and Levkowitz 2015; Leman et al. 2013; G. Wills 2008). Others prioritize the more cognitive or human-computer interaction (HCI) aspects of interactive data visualization, exploring what impact different kinds of visualization techniques have on the user’s ability to derive insights from the data (see e.g. Brehmer and Munzner 2013; Dimara and Perin 2019; Dix and Ellis 1998; Pike et al. 2009; Quadri and Rosen 2021; Yi et al. 2007). Of course, many interactive data visualization papers discuss both implementation and user experience. However, the dual interpretation of the term “interactive data visualization” does complicate literature search. It also highlights the interdisciplinary nature of the field, showing its connections to statistics, computer science, applied mathematics, business analytics, HCI, and cognitive psychology (see Brehmer and Munzner 2013; Dimara and Perin 2019). While this interdisciplinary nature of interactive data visualization is certainly a strength, it can also lead to confusion. As such I think it is necessary to clearly define key terms. To ensure clarity throughout thesis, the term “interactive data visualization” will primarily refer to concrete charts or figures. When referring to the practice of interactive data visualization, I will attempt to use more active phrasing such as “interacting with a visualization” or “user’s interaction with a visualization”, to indicate that what is being referred to is the activity or process of visualization, rather than any concrete figure or chart. 3.2.2 Interactive enough? Even when we use the term “interactive data visualization” to refer to concrete charts or figures, the meaning still remains fairly ambiguous. What is the bar for calling a figure “interactive”? What features should interactive figures have? Surprisingly, it is hard to find consensus on these topics among data visualization researchers, and the criteria tend to vary a lot, such that the same figure may be considered interactive by some but not by others. Some researchers adopt a broad definition of interactive data visualization, considering almost any figure combined with an interactive graphical user interface (GUI) as interactive, as long as it allows for some level of user manipulation (Brodbeck, Mazza, and Lalanne 2009). For others, the speed of the computer’s responses to user input is important, with faster updates translating to greater interactivity (Becker and Cleveland 1987; Buja, Cook, and Swayne 1996). Some also differentiate between “interactive” and “dynamic” manipulation, such that interactive manipulation involves discrete actions such as pressing a button or selecting an item from a drop-down menu, whereas dynamic manipulation involves continuous actions, like moving a slider or clicking-and-dragging to highlight a rectangular area (Rheingans 2002; Jankun-Kelly, Ma, and Gertz 2007; see also Dimara and Perin 2019). However, many other researchers ascribe to a much narrower view of interactive data visualization, which hinges on high-level analytic features that allow efficient exploration of the data. These features include the ability to generate different views of the data (by e.g. zooming, panning, sorting, and filtering), and the reactive propagation of changes between connected or “linked” parts of a figure (Kehrer et al. 2012; Buja, Cook, and Swayne 1996; Keim 2002; Unwin 1999; Chen, Härdle, and Unwin 2008). An often cited guideline is the visual information seeking mantra: overview first, zoom and filter, then details-on-demand (Shneiderman 2003). Similarly, in visual analytics research, a distinction is made between “surface-level” (or “low-level”) and “parametric” (or “high-level”) interactions, where surface-level interactions manipulate attributes of the visual domain only (e.g. zooming and panning), whereas parametric interactions manipulate attributes of mathematical models or algorithms underlying the visualization (Leman et al. 2013; Pike et al. 2009). Table 3.1 provides a concise summary of the several perspectives on interactivity discussed above. It meant to serve as a reference point for future discussions within the text, though it is important to note that this is not an exhaustive list. For a more comprehensive taxonomy of interactive visualization systems and features, see e.g. Dimara and Perin (2019), Yi et al. (2007). Table 3.1: Summary of the perspectives on interactivity Name Details Selected references User interaction The user can interactively manipulate the figure in some way Brodbeck, Mazza, and Lalanne (2009) Real-time updates The user’s interactions propagate into the visualization with little to no lag Becker and Cleveland (1987), Buja, Cook, and Swayne (1996), Jankun-Kelly, Ma, and Gertz (2007), and Rheingans (2002) Plot- and data-space manipulation The user can interactively explore different parts of the data set by doing actions which effectively amount to “subsetting” rows of the data (e.g. zooming, panning, and filtering) Buja, Cook, and Swayne (1996), Keim (2002), Shneiderman (2003), and Unwin (1999) Linked views The user’s interactions propagate across multiple plots (e.g. linked highlighting) Buja, Cook, and Swayne (1996), Keim (2002), Kehrer et al. (2012), Unwin (1999), Theus (2008), Wilhelm (2008), G. Wills (2008) Parametric updates The user can manipulate the parameters of some underlying mathematical model or algorithm (e.g. histogram bins, grand tour projections, etc…) Leman et al. (2013), Pike et al. (2009) 3.2.3 Complexity of interactive features The way we define interactivity is not just a matter of taste or preference: it has a significant impact on the complexity and feasibility of our systems. As we will see in Section 3.2.5, some simple features are fairly easy to implement, requiring just a thin interactive layer over a static data visualization system, whereas others come with a significant overhead, requiring an entirely different framework than static visualization. To make the point with a particularly blunt example, many programming languages support a read-evaluate-print loop (REPL). This allows interactive code execution from the command line: the user inputs code, the interpreter evaluates it, outputs results, and waits for more input. If the language supports plotting, running code to generate plots could be considered an “interactive data visualization system.” User interaction with the REPL modifies the visual output, and with fast-enough input, updates could appear almost instantly (thus satisfying the user interaction and real-time update definitions of interactivity, see table). This would make almost every programming language an “interactive data visualization system”, requiring no additional effort. However, I would argue that, today, this view stretches the concept of interactivity. It is true that, historically, the command line was considered a highly interactive user interface (see e.g. Foley 1990; Howard and MacEachren 1995). However, with advancements in processor speeds and the widespread adoption of graphical user interfaces (GUIs), user expectations have evolved. Nowadays, we typically associate interactivity with direct manipulation of visual elements and immediate feedback (Dimara and Perin 2019; Urbanek 2011). Thus, we can see that what’s considered “interactive” evolves over time. But even with figures that are manipulated directly, there still are considerable differences in what different features imply for implementation requirements. Some features, like changing color or opacity of points in a scatterplot affect only the visual attributes of the plot and not the underlying data representation. This makes them simple to implement as they do not require any specialized data structures or complex computations, and the primary cost lies in re-rendering the visualization. In contrast, some interactive features require a lot more infrastructure. For instance, filtering, linked highlighting, or parametric interaction require specialized data structures and algorithms beyond those that would be required in static plots. This is because, each time the user engages in an interaction, entirely new summaries of the underlying data may need to be computed. To give a concrete example, when a user selects several points in a linked scatterplot (see Section 3.2.5.8), we first have to find the ids of all the selected cases, recompute the statistics underlying all other linked plots (such as counts/sums in barplots or histograms), train all of the relevant scales, and only then can we re-render the figure. Likewise, when interactively manipulating a histogram’s binwidth, we need to recompute the number of cases in each bin whenever the binwidth changes. To maintain the illusion of smooth, “continuous” interaction (Dimara and Perin 2019), these computations need to happen fast, and as such, computational efficiency becomes imperative at high data volumes. 3.2.4 Working definition As discussed in previous sections, the definition “interactive data visualization” varies across fields and researchers. Moreover, when building interactive data visualization systems, different definitions imply varying levels of implementation complexity. Thus, we need to establish clear criteria for our specific definition. Data visualization can be broadly categorized into two primary modes: presentation and exploration. While both modes share a bulk of common techniques, each comes with a different set of goals and challenges (Kosara 2016). Data presentation starts from the assumption that we have derived most of the important insights from our data already, and the goal is now to communicate these insights clearly and make an impactful and lasting impression (Kosara 2016). In contrast, data exploration begins from a position of incomplete knowledge - we accept that there are facts about our data we might not be aware of. Thus, when we explore data with visualizations, the goal is to help us see what we might otherwise miss or might not even think to look for (Tukey et al. 1977; Unwin 2018). However, it is not always the case that more complex visuals necessarily translate to better statistical insights. In static visualization, it is a well-established that plots can include seemingly sophisticated features which do not promote the acquisition of statistical insights in any way (Cairo 2014, 2019; Gelman and Unwin 2013; Tufte 2001). Similarly, adding interactivity to a visualization does not always improve its statistical legibility (see e.g. Abukhodair et al. 2013; Franconeri et al. 2021). I propose to treat interactive features the same way we treat visual features in static visualization. Specifically, I propose the following working definition: When building interactive data visualization systems, we should prioritize interactive features which promote statistical understanding. If we accept this proposition, then several important consequences follow. First, we must favor high-level, data-dependent, parametric interactions over the purely graphical ones. That is not to say that purely graphical interactive features cannot useful. For instance, in the case of overplotting, changing the size or alpha of points in a scatterplot can help us see features that would otherwise remain hidden. Nevertheless, I argue that the ability to see entirely new representations of the data is what makes some interactive data visualizations systems particularly powerful. The interactive features that enable this, such as linked highlighting and parameter manipulation, go beyond aesthetics, and empower the users to explore the data in a much more dynamic way, compared to static graphics. 3.2.5 Common interactive features This section describes several common types of interactive features that tend to frequently appear in general interactive data visualization systems. It is only meant as an overview (for more comprehensive taxonomies of interactive features, see Dimara and Perin 2019; Unwin et al. 2006; Yi et al. 2007). For each feature, I highlight its core properties, common use cases, and implementation requirements. 3.2.5.1 Changing size and opacity One of the simplest and most widely-implemented interactive features is the ability to adjust the size and opacity of geometric objects. This feature gives the user the ability to dynamically shrink or grow objects and make semi-transparent, fully transparent, or opaque. The ability to shrink objects or make them semi-transparent can be particularly useful at high data volumes, since this can reveal trends that may be otherwise hidden due to overplotting. For example, in scatterplots, shrinking points and making them semi-transparent makes it possible to identify high-density regions and can in fact provide an approximation to a 2D kernel density plot (see e.g. Dang, Wilkinson, and Anand 2010). The same applies to all other types of plots where the where objects or glyphs may be plotted on top of each other at high densities, such as parallel coordinate plots (Theus 2008). This feature usually fairly easy to implement, since it involves manipulating visual attributes only. Specifically, in many interactive systems, size and alpha multipliers are independent parameters of the visual representation, which do not depend on the underlying data in any way. In other words, when we manipulate size or opacity of geometric objects in our plots, we do not need to worry about what data these objects represent. Compared to other interactive features, this makes it relatively simple to add this functionality to an existing static visualization system (see Braşoveanu et al. 2017). 3.2.5.2 Zooming and panning Another two significantly related interactive features are zooming and panning. They are often used in tandem, and both involve interactive manipulation of scale limits. For this reason, I discuss them here simultaneously, in a single subsection. Zooming, depicted in Figure 3.6, allows the user to magnify into a specific region of a plot. A common approach involves creating a rectangular selection and the axis scales are then automatically adjusted to match this region, however, other techniques do exist, for instance a symmetric zoom centered on a point using a mouse wheel. Zooming is useful because it allows the user to get a better sense of the trend within the magnified region, and discover patterns that may be otherwise obscured due to overplotting or improper aspect ratio (see e.g. Buja, Cook, and Swayne 1996; Dix and Ellis 1998; Unwin 1999; Theus 2008; Yi et al. 2007). Figure 3.6: Zooming involves shrinking the axis limits to obtain a more detailed view of the data. Typically, the user selects a rectangular region of the plot (left) and the plot scales are then adjusted so that the region fills up the entire plot area (right). Notice the change in the axis limits. After zooming, it is useful to retain the ability to navigate the wider plot region while preserving the current zoom level and aspect ratio. Panning addresses this need. By performing some action, typically right-click and drag, the user can move the center of the zoomed-in region around, exploring different areas of the plot. Figure 3.7: Panning involves moving the axis limits while retaining the same zoom level and axis ratio. After zooming into a rectangular region (top row), the user can around the plot region, usually by clicking and dragging (bottom row). Zooming and panning can be implemented by manipulating scales only, and this also makes them generally fairly straightforward to implement, similar to changing size and opacity. However, there are a few issues to consider. First, whereas continuous axes can be be zoomed and/or panned by simply modifying the axis limits, zooming discrete axes requires a bit more nuance (see e.g. Wilkinson 2012). Second, it is often desirable to give the user the ability to zoom-in multiple levels deep, and this makes maintaining a reversible history of previous zoom-states essential (Unwin 1999). Third, at times, it can be useful to link scale updates across multiple plots, such that, for example, zooming or panning a plot in a scatterplot matrix produces the same actions in other plots with the same variable on one of the axes. Finally, an advanced feature that can be also quite useful is semantic or logical zooming (Keim 2002; Unwin 1999; Yi et al. 2007). This technique goes beyond magnifying objects; it also increases the level of detail the objects display as the user zooms in. Semantic zooming can be particularly powerful when combined with hierarchical data such as geographic information, however, it also introduces additional complexity, since the effects of the zoom action propagate beyond x- and y-axis scales. 3.2.5.3 Querying Querying is another popular interactive feature that is usually fairly straightforward to implement. As shown in Figure 3.8, the way querying is typically implemented is that when a user mouses over a particular geometric object, a tooltip or a small table is displayed, showing values corresponding to the underlying data point(s) (Urbanek and Theus 2003). This makes it possible to look up precise values that would otherwise be available only approximately via the visual representation. Figure 3.8: Querying involves hovering over an object to display its associated data values in a table or pop-up. Notice that this can include both plotted values (weight, mileage) as well as values that are not directly represented in the plot (car name, cylinders). Querying is useful because combines the best features of graphics and tables. Specifically, it allows the user to overcome Tukey’s famous prescriptions: “graphics are for the qualitative/descriptive […] never for the carefully quantitative (tables do that better)”, and: “graphics are for comparison […] not for access to individual amounts” (Tukey 1993). Providing the option to query individual objects gives the user the ability to seamlessly transition between the high-level analytic overview of the graphic and low-level quantitative detail of a table. This allows users to perform tasks requiring higher precision, such as identifying specific outliers or calculating exact magnitudes of differences (Unwin et al. 2006). Additionally, querying also allow us to show more information than is displayed via the visual encodings alone (see again Figure 3.8). Specifically, whereas most plots can encode only two or three variables, we can assign an arbitrary number of key-value pairs to the rows of the query table/pop-up. However, it is crucial to balance the level of detail against visual clutter. Too many rows may overtax the attention of the user and also can lead to clipping/overplotting issues, if the query table cannot fit inside the plotting area. Further, there are better methods for retrieving very detailed information from interactive visualizations. Finally, while querying is also one of the more straightforward features, its implementation does present certain challenges. First, a naive implementation might simply display derived data values in the state just before they are mapped to visual attributes via scales, however, these are not always the most informative. For instance, in a stacked barplot, returning the original (unstacked) values is more useful than the stacked ones. Second, aggregate plots such as barplots or histograms do generally present some design decisions (see Unwin et al. 2006). In the case of one-to-one plots such as scatterplots, query data for an object (point) can be obtained by simply retrieving the corresponding row. However, in aggregate plots like barplots and histograms, a single object may correspond to multiple rows. This necessitates summarizing the underlying data, and often there may be no single “correct” summary. For instance, when querying a bar in a barplot, should we return the sum of the underlying continuous variable, some other numeric summary such as the mean or maximum, the set of all unique values, multiple of these summaries, or perhaps something else entirely? Similar ambiguities arise when querying objects which are partially selected or highlighted (see Section 3.2.5.8): should the query return summaries corresponding to the entire object, the highlighted parts, or both? 3.2.5.4 Sorting and reordering With plots of discrete (unordered) data, a highly useful feature can be to sort or reorder objects based on some criterion (see Unwin 2000; Unwin et al. 2006). For example, with barplots, in the absence of other ordering rules, bars are typically ordered by the lexographical order of the x-axis variable. However, sometimes, we can glean interesting patterns by sorting the bars in some other order, for example by their height, see Figure 3.9. Figure 3.9: Sorting or reordering can highlight interesting trends. For instance, sorting lexicographically ordered bars (left) by bar height (right) in the figure above immediately reveals a significant gap between the five tallest bars and the rest (gray dashed line). There are more sophisticated ways to sort objects in a plot than just sorting bars by height, however. For instance, in plots which show multiple summary statistics, any may serve as the basis for the sorting rule; for instance a boxplot may be sorted by the median, upper and lower quartile, the maximum, and the minimum (Unwin et al. 2006). Likewise, in the presence of selection/highlighting, objects may be sorted by the summary statistic on the highlighted parts. Alternatively, some systems allow users to permute the order of discrete scales manually by swapping the position of categories pairwise, a feature which can be particularly useful in parallel coordinate plots (Unwin et al. 2006; Urbanek 2011). Finally, in the presence of many categories, sorting may also be usefully combined with lumping categories below a certain threshold together (Unwin 2000). Like zooming and panning, basic sorting typically involves the manipulation of axis scales only, making it also a fairly straightforward feature to implement. However, the more sophisticated sorting features can pose non-trivial implementation challenges (Unwin et al. 2006). For instance, sorting by custom summary statistics or manually permuting discrete scale order may require specialized system components and behavior. 3.2.5.5 Parameter manipulation As discussed in Section 3.2.3, another valuable class of interactive features are those which affect the computation of the summary statistics underlying the graphic (also called “parametric interaction,” Leman et al. 2013; Pike et al. 2009). These features extend beyond simple manipulation of visual attributes, requiring that user interaction penetrates much deeper inside the data visualization pipeline. Fundamentally, these features involve the manipulation of the parameters of some underlying mathematical model. A basic and common example of parameter manipulation is dynamically changing histogram binwidth or anchor. Assuming a fixed binwidth \\(w\\) and an anchor \\(a\\), we can describe a histogram via a function \\(h\\) that, for each observation of a continuous variable \\(x_i\\) returns an index \\(j\\) of the corresponding bin, such that, for an ordered list of bins breaks \\(b_j\\), we have \\(x_i \\in [b_{j}, b_{j + 1})\\)1: \\[h(x; a, w) = \\lfloor (x_i - a) / w \\rfloor + 1\\] Thus, a histogram really is a kind of a mathematical model, and can in fact be seen as a crude form of density estimation (see also e.g. Bishop and Nasrabadi 2006, 4:120–22). Manipulating histogram bins amounts to manipulating the parameters of the function \\(h\\). Importantly, unlike zooming, panning, and changing or and opacity, which involve visual attributes of the plot only, changing binwidth and anchor requires that the summary statistics underlying the plot get recomputed each time interaction happens, and these changes can have significant downstream effects. For instance, if changing the binwidth leads to the count of cases within the tallest histogram bar increasing, we may need to update the upper y-axis limit, if we want to prevent the bars from overflowing the plotting region. 3.2.5.6 Animation and projection 3.2.5.7 Changing representation The same data can often by visualized in multiple ways, by representing it via different sets of visual encodings (Wilkinson 2012). However, some encodings may work better for answering certain questions than others. By enabling the users to switch the visual representation, we empower them to explore their data with grater flexibility (Yi et al. 2007). A typical example is switching between a barplot and a spineplot, see Figure 3.10. Barplots are an effective representation for comparing absolute quantities. Specifically, by encoding a categorical variable as the x-axis position and a continuous variable as the y-axis position/bar length, we can easily compare the y-axis quantities across the levels of the x-axis variable. Often, we further split the bars into segments and encode a second categorical variable as the segment colour, to be able to compare quantities within subgroups. Figure 3.10: Switching representations can be an effective way to derive new insights from the data. A barplot (left) represents the same underlying data as a spineplot (right), however, the former is better for comparing absolute counts whereas the latter is better for comparing proportions. Note that in the spineplot, it is much easier to see that the proportion of the red cases is the same in categories B and C. However, since the heights of the bars are different, barplots are not very effective for comparing proportions, especially when the bar heights vary significantly. Spineplots, on the other hand, present a way of visualizing the same sort of data as a barplot while making it much easier to compare proportions. Specifically, in a spineplot, the heights of the bars are all normalized to 1, such that the segments show a proportion of the total, and the absolute values are instead encoded as the bar width. The fixed height of bars makes it easy to compare the proportions the segments represent. Other examples of switching of representations include the spinogram (a normalized version of the histogram). 3.2.5.8 Linked selection Linked selection, also known as linked brushing, linked highlighting, or linked views, is often considered one of the most versatile and powerful interactive data visualization features (see e.g. Becker and Cleveland 1987; Buja, Cook, and Swayne 1996; Wilhelm 2003; Heer and Shneiderman 2012; Ward, Grinstein, and Keim 2015; Ware 2019). Fundamentally, it involves creating a figure with multiple “linked” plots. The user can then click or click-and-drag over objects in one plot, and the corresponding cases are highlighted across all the other plots, see Figure 3.11. This makes it possible to quickly quickly explore trends across different dynamically-generated subsets of the data (Dix and Ellis 1998). The ability to quickly materialize alternative views of the data makes this a particularly effective tool for data exploration (Wilhelm 2008; G. Wills 2008). Figure 3.11: Linked selection involves highlighting the same cases across all plots. The user can select some objects in one plot, such as points in a scatterplot (top left), and the corresponding cases are higlighted in all the other plots. Source of the underlying data is the mtcars dataset (Henderson and Velleman 1981). Despite the fact that the user experience of linked selection is usually fairly intuitive, there are many subtle considerations that go into implementing the feature (for a good overview, see Wilhelm 2008). First, there is the issue of how the user makes the selection. Typically, clicking selects a single objects and clicking-and-dragging selects multiple objects in a rectangular region (similar to how selecting files and folders works on desktop GUIs of most operating systems). In some systems, the users may also drag the selection region around (“brushing”), form a continuous “lasso” selection, select lines in a particular angular range, or points at a particular distance from a centroid (see e.g. Hauser, Ledermann, and Doleisch 2002; Splechtna et al. 2018; G. Wills 2008). Further, when one variables is continuous and the other is derived (such as the x- and y-axes in a histogram), the interaction may also be simplified by restricting selection/brushing to the primary axis (Satyanarayan et al. 2016). Finally, the selections can be combined by various operators such as OR, AND, NOT, and XOR, to form unions, intersections, and other types of logical subsets (Theus 2002; Urbanek and Theus 2003; G. J. Wills 2000; G. Wills 2008). Second, there is the issue of who should dispatch and respond to selection events. In presentation-focused interactive data visualization and dashboarding systems, this responsibility is kept flexible, such that some plots may only dispatch, only respond, do both, or neither (Satyanarayan et al. 2015, 2016). However, in systems focused on data exploration, the convention is typically for all plots to both dispatch and respond to selection events, such that they may be interacted with in the same way. (Theus 2002; Urbanek and Theus 2003; Urbanek 2011). Third, there is the issue of what to link. In the case of data represented by a two-dimensional table or data frame, the most common method is to link cases taken on the same observational level (identity linking), such that each row gets assigned a value representing the selection status (Urbanek and Theus 2003; Wilhelm 2008; G. Wills 2008). However, in the case of more complex data, more advanced linking schemes are also available, such as hierarchical and distance-based linking (Wilhelm 2008; Urbanek 2011). Third, there is the issue of displaying selection. This issue will be touched upon in more detail later, in Section 4. Briefly, Wilhelm (2008) identifies three methods for displaying linked selection: replacement, overlaying, and repetition. Replacement involves replacing the entire plot with a new graphic; overlaying involves superimposing the objects representing the selected subsets on top of the original objects; and repetition involves displaying the selected objects alongside the original ones. Wilhelm identifies issues with all three techniques, although he does seem to generally come down in favor of repetition (however, see my argument in Section 4.3.1.4). A fourth and final issue in linked selection, and arguably one of the core concerns of the present thesis, is consistency. This topic will be coming up again and again, particularly in Section 4. Consistent and predictable features are a cornerstone of good user interface design (see e.g. Ruiz, Serral, and Snoeck 2021). However, as discussed above, the design an interactive data visualization system supporting linked selection presents many design decisions, each with its own set of implementation constraints. Achieving a consistent user interface through the right combination of these decisions is a known challenge (Urbanek 2011; Pike et al. 2009). For example, while the approach of allowing objects to independently dispatch and display selection events offers great flexibility, it can also lead to a less intuitive user experience. Put simply, when users select objects in one linked plot by clicking them, they might reasonably expect the same functionality in other plots. If that is not the case (if, for instance, other plots support only displaying but not dispatching selection events), their expectation will be violated. Thus, it might be reasonable to require that all objects can both dispatch and display selection events. However, this places some fundamental constraints on these objects. For instance, how do we draw a lineplot line where only some of the underlying cases are selected? Do we draw a sequence of differently-coloured line segments, leading to a striped “candy cane” pattern (see Figure 3.12)? Do we draw two separate lines? If so, how do we then dispatch selection events on these lines which are already conditional on selection? Like turning over a rock and disturbing a host of creepy-crawlies, linked selection reveals a complex web of visualization design challenges that defy a satisfying, generic solution. Figure 3.12: Displaying selection is not always trivial. A good example is a lineplot (right). Whereas a point in a scatterplot displays a single case (row) and a bar in a barplot displays a simple subset of cases, a line segment in a lineplot connects two data points. As such, it is not clear whether to highlight the segment starting at the selected point, ending at the selected point, or, e.g., half a segment on each side of the point. Further, since the geometry of a segmented line is not commutative (row order matters), we end up with a striped ‘candy cane’ pattern that is not easily interpretable. 3.3 General data visualization theory The following sections briefly explore several key theoretical topics in data visualization: the goals and purpose of visualizations, the mechanisms of visual perception, and the theory of scales and measurement. While mainly discussed in the context of static visualization, these topics are equally relevant to interactive visualization and present some unique challenges. My goal is not to give an exhaustive review - each of these topics is substantial enough to serve as a thesis topic in its own right. Instead, I just want to give a brief overview of these topics, highlight some key points, and discuss how they may relate to my own work. 3.3.1 Visualization goals An important fact about data visualization is that, fundamentally, a chart can be used by many different people for many different things (for a review, see e.g. Brehmer and Munzner 2013; Franconeri et al. 2021; Sarikaya et al. 2018). For example, applied researchers may create figures as part of their workflow, aiming to better understand the data they had collected, spot errors and anomalies, and come up with new ideas and hypotheses (Brehmer and Munzner 2013; see also Kandel et al. 2012). Conversely, data scientists and data analysts in the public and private sector may visualize already familiar data sets to communicate important information, drive decisions, or convince or persuade stakeholders (Sarikaya et al. 2018). Finally, some figures may be created out of a sense of curiosity or for pure aesthetic enjoyment (Brehmer and Munzner 2013; Tufte 2001). Depending on the end-goals of the user and the desired target audience, certain visualization techniques, methods, or styles may become more useful than others. As mentioned in Section 3.2.1, much has been written about the goals and experiences a user might have while creating data visualizations. For instance, Brehmer and Munzner (2013) formalized a typology of abstract visualization tasks, based around three adverbs: why is a task is performed, how it is performed, and what does it pertain to. In the why part of their typology, they list the following reasons for why a user may engage in the process of visualizing data: to consume (present, discover, or enjoy), produce, search (lookup, browse, locate, and explore), and query (identify, compare, summarize). As another example, Pike et al. (2009) list the following high-level goals a user might have when interacting with a visualization: explore, analyze, browse, assimilate, triage, asses, understand, compare. And there are many other typologies and taxonomies of data visualization tasks and goals in the literature. Personally, when it comes to classifying interactive data visualization goals, I prefer the following short list provided by Ward, Grinstein, and Keim (2015): Exploration: The user wants to examine a data set Confirmation: The user wants to verify a fact or a hypothesis Presentation: The user wants to use the visualization to convince or inspire an audience Interactive presentation: The user wants to take the audience on a guided tour of key insights I believe this list maps fairly well onto interactive data visualization systems found in the wild, such as the ones discussed in Section 3.1. Specifically, as mentioned before, in the history of interactive data visualization, the earlier statistical systems seemed to primarily focus on exploration and confirmation, whereas the newer web-based systems seem to prioritize presentation. The interactive presentation category is interesting, since, I would argue, it is far more specific and less common than the other categories, however, by singling it out, Ward et al. make an interesting point. By incorporating time and intentionality, sequential interactive presentations, such as those found in the Graphics section of the New York Times (The New York Times Company 2025), really are quite unique. 3.3.2 Visual perception Another important research topic in data visualization is visual perception. Specifically, given that we use visual attributes such as position, color, length, or area to encode various aspects of our data, researchers have tried to answer the question of how to use these attributes in a way that best leverages the human visual system. Fortunately, this research has been quite fruitful, yielding precise and actionable guidelines (for a review, see Franconeri et al. 2021; Quadri and Rosen 2021). A landmark work in this area has been that of Cleveland and McGill (1984). In this study, the authors conducted a series of empirical experiments in which they investigated people’s ability to accurately judge quantities based on different visual encodings. They found that judgments based on position along a common scale were the most accurate, followed by length-based comparisons, and then angle-based comparisons. The findings were later corroborated by other authors. Heer and Bostock (2010) replicated the Cleveland and McGill (1984) study, and included judgements of circular and rectangular areas which were found to be less accurate than position, length, or angle. Other authors have extended these experiments to other visual encodings, such as color or density (e.g. Demiralp, Bernstein, and Heer 2014; Saket et al. 2017; Reda, Nalawade, and Ansah-Koi 2018). Together, these findings have been used to create rankings of visual encodings, with researchers generally agreeing on the following ordered list: position, length, area, angle, and intensity (from most effective to least, Mackinlay 1986; Franconeri et al. 2021; Quadri and Rosen 2021). 3.3.3 Scales and measurement Visualizing data involves mapping values to graphical attributes. As discussed in the previous section, certain visual attributes are better for visualizing particular types of data, and vice versa. However, even when we pick an appropriate visual attribute to represent our data with, there are still many choices in how to perform the mapping. For instance, suppose we have some variable \\(x\\) with values \\(\\{ 1, 2, 3 \\}\\). Should these be treated as magnitudes, a simple ordering, or even just category labels that may be permuted at will? In most data visualization systems, this metadata encoding of values into visual attributes is handled specialized components called scales or coordinate systems, and I will discuss their implementation in detail later, in Section 4.4.0.3. However, it is first necessary to discuss some theoretical issues involving scales. A particular challenge when discussing scales in data visualization is that the topic unavoidably intersects with a research area that has a particularly long and contentious history: theory of measurement (see e.g. Hand 1996; Michell 1986; Tal 2025). Theory of measurement (not to be confused with measure theory, with which it nevertheless shares some overlap) is the research area which tries to answer the deceptively simple question: what does it mean to measure something? This seemingly trivial problem has inspired long and fiery debates within the fields of mathematics, philosophy, and social science. Particularly, in psychology, where assigning numerical values non-physical phenomena such as moods and mental states is a central concern, the topic has garnered a significant amount of attention, creating a dense body of research (see e.g. Humphry 2013; Michell 2021). Arguably, the most influential work in this field has been that of Stevens (1946). In his fairly concise paper, Stevens defined a scale as method of assigning numbers to values, and introduced a four-fold classification classification, namely: nominal, ordinal, interval, and ratio scales (see Table 3.2). Table 3.2: Types of scales identified by Stevens (1946) Scale Structure Comparison Valid transformations Nominal Isomorphism Are \\(x\\) and \\(y\\) the same? \\(x&#39; = f(x)\\), where \\(f\\) is a bijection Ordinal Monotone map Is \\(x\\) is greater than \\(y\\)? \\(x&#39; = f(x)\\), where \\(f\\) is a monotone bijection Interval Affine transformation How far is \\(x\\) from \\(y\\)? \\(x&#39; = ax + b\\), for \\(a, b \\in \\mathbb{R}\\) Ratio Linear map How many times is \\(x\\) greater than \\(y\\)? \\(x&#39; = ax\\), for \\(a \\in \\mathbb{R}\\) The Steven’s (1946) typology is based on invariance under transformation. Specifically, for each class of scales, we define a set of transformations that preserve valid comparisons. The set of valid transformations shrinks as we move from one class of scales to another. For nominal scales, any kind of bijective transformation is valid. Intuitively, we can think of the scale as assigning labels to values, and any kind re-labeling is valid, as long as it preserves equality of the underlying values. For instance, given a nominal scale with three values, we can assign the labels \\(\\{ \\text{red}, \\text{green}, \\text{blue} \\}\\) or \\(\\{ \\text{monday}, \\text{tuesday}, \\text{wednesday} \\}\\) in any way we like, as long as each value maps to a unique label. This identifies the underlying mathematical structure as an isomorphism. Ordinal scales are more restrictive, since, on top of preserving equality, transformations also need to preserve order. For example, if we want to assign the labels \\(\\{ \\text{monday}, \\text{tuesday}, \\text{wednesday} \\}\\) to an ordinal scale with three values, there is only one way to do it that preserves the underlying order: assign the least values to \\(\\text{monday}\\), the middle value to \\(\\text{tuesday}\\), and the greatest value to \\(\\text{wednesday}\\) (assuming we order the labels/days in the usual day-of-week order). However, there is no notion of distance between the labels: we could just as well assign the values labels in \\(\\mathbb{N}\\) such as \\(\\{ 10, 20, 30 \\}\\), \\(\\{1, 2, 9999 \\}\\), and so on. Thus, the fundamental mathematical structure is that of a monotone map. Interval scales need to additionally preserve equality of intervals. This means that, for any three values \\(a, b,\\) and \\(c\\), if the distances between \\(a\\) and \\(b\\) and \\(b\\) and \\(c\\) are equal, \\(d(a, b) = d(b, c)\\), then so should be the distances between the scaled labels, \\(d^*(f(a), f(b)) = d^*(f(b), f(c)\\). For most real applications, this limits interval scales to the class of affine transformations of the form \\(f(x) = ax + b\\). A canonical example of an interval scale is the conversion formula of degrees Celsius to Fahrenheit: \\(f(c) = 9/5 \\cdot c + 32\\) (Stevens 1946). This example also highlights an important property of interval scales: the zero point can be arbitrary and ratios are not meaningful. Specifically, since the zero points of both Celsius and Fahrenheit scales were chosen based on arbitrary metrics (freezing temperatures of water and brine, respectively), it does not make sense to say that, e.g. 20°C is “twice as hot” as 10°C, in the same way that it does not make sense to say that 2000 CE is “twice as late” as 1000 CE. Finally, ratio scales also need to preserve the equality of ratios. Specifically, if \\(a/b = b/c\\) then \\(f(a)/f(b) = f(b) / f(c)\\). As a consequence, this also means that the scale must have a well-defined zero-point. Examples of ratio scales include physical magnitudes such as height and weight, which have a well-defined zero point (Stevens 1946). Steven’s (1946) typology sparked a considerable debate, on multiple fronts. First, since the original publication, many authors have sought to either expand upon or criticize Steven’s typology. However, despite some monumental efforts towards a unified theory, such as that of Krantz et al. (1971), measurement has remained a hotly debated topic to this day (see e.g. Michell 2021; Tal 2025). Second, more relevant to statistics, some authors such as Stevens (1951) and Luce (1959) used the theory to define come up with prescriptive rules for statistical transformations, suggesting that, for example, taking the mean of an ordinal variable is wrong since the meaning of the average operator is not preserved under monotone transformations. However, this issue was hotly contested by statisticians such as Lord (1953), Tukey (1986), and Velleman and Wilkinson (1993), who argued that many well-established statistical practices, such as rank-based tests and coefficients of variations, rely on such “impermissible” statistics but can nevertheless yield valuable insights. More broadly, these authors also argued that data is not really meaningful on its own, but instead derives its meaning from the statistical questions it is used to answer (see also Wilkinson 2012). At this point, the discussion around measurement has arguably become far too dense and theoretical, and most data visualization researchers seem to avoid delving into it too deeply (see e.g. Wilkinson 2012). Nevertheless, there are still some areas where the issues of measurement and Steven’s typology do crop up. For instance, when scaling area based on a continuous variable, a common recommendation is to start the scale at zero to ensure accurate representations of ratios (see e.g. Wickham and Navarro 2024), aligning with Steven’s definition of a ratio scale. Likewise, the long-standing debate around whether the base of a barplot should always start at zero (see e.g. Cleveland 1985; Wilkinson 2012) also carries echoes of the measurement debate. Ultimately, it may yet require long time to settle the issues around measurement, however, there are definitely some ideas within the literature that data visualization can benefit from. References Abbate, J. 1999. “Getting small: a short history of the personal computer.” Proc. IEEE 87 (9): 1695–98. https://doi.org/10.1109/5.784256. Abukhodair, Felwa A, Bernhard E Riecke, Halil I Erhan, and Chris D Shaw. 2013. “Does Interactive Animation Control Improve Exploratory Data Analysis of Animated Trend Visualization?” In Visualization and Data Analysis 2013, 8654:211–23. SPIE. Backus, John. 1978. “The History of Fortran i, II, and III.” ACM Sigplan Notices 13 (8): 165–80. Batch, Andrea, and Niklas Elmqvist. 2017. “The Interactive Visualization Gap in Initial Exploratory Data Analysis.” IEEE Transactions on Visualization and Computer Graphics 24 (1): 278–87. Becker, Richard A, and William S Cleveland. 1987. “Brushing Scatterplots.” Technometrics 29 (2): 127–42. Beniger, James R, and Dorothy L Robyn. 1978. “Quantitative Graphics in Statistics: A Brief History.” The American Statistician 32 (1): 1–11. Bertin, Jacques. 1967. Sémiologie Graphique: Les diagrammes, les réseaux, les cartes. Gauthier-Villars. Bishop, Christopher M, and Nasser M Nasrabadi. 2006. Pattern Recognition and Machine Learning. Vol. 4. 4. Springer. Blokt. 2020. “Flare \\(\\vert\\) Data Visualization for the Web.” Blokt - Privacy, Tech, Bitcoin, Blockchain &amp; Cryptocurrency. https://blokt.com/tool/prefuse-flare. Bostock, Mike. 2022. “D3.js - Data-Driven Documents.” https://d3js.org. Braşoveanu, Adrian MP, Marta Sabou, Arno Scharl, Alexander Hubmann-Haidvogel, and Daniel Fischl. 2017. “Visualizing Statistical Linked Knowledge for Decision Support.” Semantic Web 8 (1): 113–37. Brasseur, Lee. 2005. “Florence Nightingale’s Visual Rhetoric in the Rose Diagrams.” Technical Communication Quarterly 14 (2): 161–82. Brehmer, Matthew, and Tamara Munzner. 2013. “A Multi-Level Typology of Abstract Visualization Tasks.” IEEE Transactions on Visualization and Computer Graphics 19 (12): 2376–85. Brodbeck, Dominique, Riccardo Mazza, and Denis Lalanne. 2009. “Interactive Visualization - A Survey.” In Human Machine Interaction, 27–46. Berlin, Germany: Springer. https://doi.org/10.1007/978-3-642-00437-7_2. Buja, Andreas, Dianne Cook, and Deborah F Swayne. 1996. “Interactive High-Dimensional Data Visualization.” Journal of Computational and Graphical Statistics 5 (1): 78–99. Cairo, Alberto. 2014. “Graphics Lies, Misleading Visuals: Reflections on the Challenges and Pitfalls of Evidence-Driven Visual Communication.” In New Challenges for Data Design, 103–16. Springer. ———. 2019. How Charts Lie: Getting Smarter about Visual Information. WW Norton &amp; Company. Chang, Winston, Joe Cheng, JJ Allaire, Carson Sievert, Barret Schloerke, Yihui Xie, Jeff Allen, Jonathan McPherson, Alan Dipert, and Barbara Borges. 2024. Shiny: Web Application Framework for r. https://CRAN.R-project.org/package=shiny. Chen, Chun-houh, Wolfgang Karl Härdle, and Antony Unwin. 2008. Handbook of Data Visualization. Springer Science &amp; Business Media. Clark, Lin. 2017. “A Crash Course in Just-in-Time (JIT) Compilers.” Mozilla Hacks the Web Developer Blog. https://hacks.mozilla.org/2017/02/a-crash-course-in-just-in-time-jit-compilers. Clayton, Aubrey. 2021. Bernoulli’s Fallacy: Statistical Illogic and the Crisis of Modern Science. Columbia University Press. Cleveland, William S. 1985. The Elements of Graphing Data. Wadsworth Publ. Co. ———. 1993. Visualizing Data. Hobart press. Cleveland, William S, and Robert McGill. 1984. “Graphical Perception: Theory, Experimentation, and Application to the Development of Graphical Methods.” Journal of the American Statistical Association 79 (387): 531–54. Cook, Dianne, Andreas Buja, Javier Cabrera, and Catherine Hurley. 1995. “Grand Tour and Projection Pursuit.” Journal of Computational and Graphical Statistics 4 (3): 155–72. Dang, Tuan Nhon, Leland Wilkinson, and Anushka Anand. 2010. “Stacking Graphic Elements to Avoid over-Plotting.” IEEE Transactions on Visualization and Computer Graphics 16 (6): 1044–52. Dao, Chau. 2020. “The Nature and Evolution of JavaScript.” Bachelor's Thesis, Oulu University of Applied Sciences. Demiralp, Çağatay, Michael S Bernstein, and Jeffrey Heer. 2014. “Learning Perceptual Kernels for Visualization Design.” IEEE Transactions on Visualization and Computer Graphics 20 (12): 1933–42. Dimara, Evanthia, and Charles Perin. 2019. “What Is Interaction for Data Visualization?” IEEE Transactions on Visualization and Computer Graphics 26 (1): 119–29. Dix, Alan, and Geoffrey Ellis. 1998. “Starting simple: adding value to static visualisation through simple interaction.” In AVI ’98: Proceedings of the working conference on Advanced visual interfaces, 124–34. New York, NY, USA: Association for Computing Machinery. https://doi.org/10.1145/948496.948514. Donoho, Andrew W, David L Donoho, and Miriam Gasko. 1988. “MacSpin: Dynamic Graphics on a Desktop Computer.” IEEE Computer Graphics and Applications 8 (4): 51–58. Elmqvist, Niklas, Andrew Vande Moere, Hans-Christian Jetter, Daniel Cernea, Harald Reiterer, and TJ Jankun-Kelly. 2011. “Fluid Interaction for Information Visualization.” Information Visualization 10 (4): 327–40. Evan You and the Vue Core Team. 2024. “Vue.js.” https://vuejs.org. Fienberg, Stephen E. 1992. “A Brief History of Statistics in Three and One-Half Chapters: A Review Essay.” JSTOR. Fisherkeller, Mary Anne, Jerome H Friedman, and John W Tukey. 1974. “An Interactive Multidimensional Data Display and Analysis System.” SLAC National Accelerator Lab., Menlo Park, CA (United States). Foley, James D. 1990. “Scientific Data Visualization Software: Trends and Directions.” The International Journal of Supercomputing Applications 4 (2): 154–57. Fowlkes, EB. 1969. “User’s Manual for a System Fo Active Probability Plotting on Graphic-2.” Tech-Nical Memorandum, AT&amp;T Bell Labs, Murray Hill, NJ. Franconeri, Steven L, Lace M Padilla, Priti Shah, Jeffrey M Zacks, and Jessica Hullman. 2021. “The Science of Visual Data Communication: What Works.” Psychological Science in the Public Interest 22 (3): 110–61. Freedman, David. 1999. “From Association to Causation: Some Remarks on the History of Statistics.” Statistical Science 14 (3): 243–58. Friendly, Michael. 2006. “A Brief History of Data Visualization.” In Handbook of Computational Statistics: Data Visualization, edited by C. Chen, W. Härdle, and A Unwin, III???–. Heidelberg: Springer-Verlag. Friendly, Michael, and Howard Wainer. 2021. A History of Data Visualization and Graphic Communication. Harvard University Press. Gelman, Andrew, and Antony Unwin. 2013. “Infovis and Statistical Graphics: Different Goals, Different Looks.” Journal of Computational and Graphical Statistics 22 (1): 2–28. Hand, David J. 1996. “Statistics and the Theory of Measurement.” Journal of the Royal Statistical Society: Series A (Statistics in Society) 159 (3): 445–73. Hauser, Helwig, Florian Ledermann, and Helmut Doleisch. 2002. “Angular Brushing of Extended Parallel Coordinates.” In IEEE Symposium on Information Visualization, 2002. INFOVIS 2002., 127–30. IEEE. Heer, Jeffrey, and Michael Bostock. 2010. “Crowdsourcing Graphical Perception: Using Mechanical Turk to Assess Visualization Design.” In Proceedings of the SIGCHI Conference on Human Factors in Computing Systems, 203–12. Heer, Jeffrey, Stuart K. Card, and James A. Landay. 2005. “prefuse: a toolkit for interactive information visualization.” In CHI ’05: Proceedings of the SIGCHI Conference on Human Factors in Computing Systems, 421–30. New York, NY, USA: Association for Computing Machinery. https://doi.org/10.1145/1054972.1055031. Heer, Jeffrey, and Ben Shneiderman. 2012. “Interactive Dynamics for Visual Analysis: A Taxonomy of Tools That Support the Fluent and Flexible Use of Visualizations.” Queue 10 (2): 30–55. Henderson, Harold V, and Paul F Velleman. 1981. “Building Multiple Regression Models Interactively.” Biometrics, 391–411. Highsoft. 2022. “Render Millions of Chart Points with the Boost Module Highcharts.” Highcharts. https://www.highcharts.com/blog/tutorials/highcharts-high-performance-boost-module. ———. 2024. “Highcharts - Interactive Charting Library for Developers.” Highcharts Blog \\(\\vert\\) Highcharts. https://www.highcharts.com. Holtz, Yan. 2022a. “Barplot with Variable Width - Ggplot2.” https://r-graph-gallery.com/81-barplot-with-variable-width.html. ———. 2022b. “Basic Scatterplot in D3.js.” https://d3-graph-gallery.com/graph/scatter_basic.html. Howard, David, and Alan M MacEachren. 1995. “Constructing and Evaluating an Interactive Interface for Visualizing Reliability.” In Congresso Da Associação Cartográfica Internacional–ICA, 17:321–29. Humphry, Stephen. 2013. “Understanding Measurement in Light of Its Origins.” Frontiers in Psychology 4: 113. Jankun-Kelly, TJ, Kwan-Liu Ma, and Michael Gertz. 2007. “A Model and Framework for Visualization Exploration.” IEEE Transactions on Visualization and Computer Graphics 13 (2): 357–69. Kandel, Sean, Andreas Paepcke, Joseph M Hellerstein, and Jeffrey Heer. 2012. “Enterprise Data Analysis and Visualization: An Interview Study.” IEEE Transactions on Visualization and Computer Graphics 18 (12): 2917–26. Kehrer, Johannes, Roland N Boubela, Peter Filzmoser, and Harald Piringer. 2012. “A Generic Model for the Integration of Interactive Visualization and Statistical Computing Using r.” In 2012 IEEE Conference on Visual Analytics Science and Technology (VAST), 233–34. IEEE. Keim, Daniel A. 2002. “Information Visualization and Visual Data Mining.” IEEE Transactions on Visualization and Computer Graphics 8 (1): 1–8. Kelleher, Curran, and Haim Levkowitz. 2015. “Reactive Data Visualizations.” In Visualization and Data Analysis 2015, 9397:263–69. SPIE. Keller, Mark S, Trevor Manz, and Nils Gehlenborg. 2024. “Use-Coordination: Model, Grammar, and Library for Implementation of Coordinated Multiple Views.” In 2024 IEEE Visualization and Visual Analytics (VIS), 166–70. IEEE. Kosara, Robert. 2016. “Presentation-Oriented Visualization Techniques.” IEEE Computer Graphics and Applications 36 (1): 80–85. Krantz, David H, Patrick Suppes, Duncan R Luce, and Amos Tversky. 1971. Foundations of Measurement Volume 1: Additive and Polynomial Representations. New York: Academic Press. Kruskal, J. B. 1965. “Multidimensional Scaling.” https://community.amstat.org/jointscsg-section/media/videos. Kunst, Joshua. 2022. Highcharter: A Wrapper for the ’Highcharts’ Library. Kvasz, Ladislav. 2006. “The History of Algebra and the Development of the Form of Its Language.” Philosophia Mathematica 14 (3): 287–317. Lee, Stuart. 2021. Liminal: Multivariate Data Visualization with Tours and Embeddings. https://CRAN.R-project.org/package=liminal. Lee, Stuart, Ursula Laa, and Dianne Cook. 2022. “Casting Multiple Shadows: Interactive Data Visualisation with Tours and Embeddings.” Journal of Data Science, Statistics, and Visualisation 2 (3). Leman, Scotland C, Leanna House, Dipayan Maiti, Alex Endert, and Chris North. 2013. “Visual to Parametric Interaction (V2pi).” PloS One 8 (3): e50474. Lord, Frederic M. 1953. “On the Statistical Treatment of Football Numbers.” Luce, R Duncan. 1959. “On the Possible Psychophysical Laws.” Psychological Review 66 (2): 81. Mackinlay, Jock. 1986. “Automating the Design of Graphical Presentations of Relational Information.” Acm Transactions On Graphics (Tog) 5 (2): 110–41. Mansfield, Daniel F. 2018. Wikimedia Commons. https://commons.wikimedia.org/wiki/File:Si427o.jpg. ———. 2020. “Perpendicular Lines and Diagonal Triples in Old Babylonian Surveying.” Journal of Cuneiform Studies 72 (1): 87–99. MDN. 2024. “EventTarget - Web APIs \\(\\vert\\) MDN.” MDN Web Docs. https://developer.mozilla.org/en-US/docs/Web/API/EventTarget. Meta. 2024. “React.” https://react.dev. Michell, Joel. 1986. “Measurement Scales and Statistics: A Clash of Paradigms.” Psychological Bulletin 100 (3): 398. ———. 2021. “Representational Measurement Theory: Is Its Number Up?” Theory &amp; Psychology 31 (1): 3–23. Online Etymology Dictionary. 2024. “Statistics.” https://www.etymonline.com/word/statistics. Pike, William A, John Stasko, Remco Chang, and Theresa A O’connell. 2009. “The Science of Interaction.” Information Visualization 8 (4): 263–74. Plotly Inc. 2022. “Part 4. Interactive Graphing and Crossfiltering \\(\\vert\\) Dash for Python Documentation \\(\\vert\\) Plotly.” https://dash.plotly.com/interactive-graphing. ———. 2024a. “Webgl.” https://plotly.com/python/webgl-vs-svg. ———. 2024b. “Scatter Plots in JavaScript.” https://plotly.com/javascript/line-and-scatter. Posit (formerly RStudio Inc.). 2025. “Crosstalk.” https://rstudio.github.io/crosstalk/index.html. Quadri, Ghulam Jilani, and Paul Rosen. 2021. “A Survey of Perception-Based Visualization Studies by Task.” IEEE Transactions on Visualization and Computer Graphics. R Core Team. 2024. R: A Language and Environment for Statistical Computing. Vienna, Austria: R Foundation for Statistical Computing. https://www.R-project.org/. Reda, Khairi, Pratik Nalawade, and Kate Ansah-Koi. 2018. “Graphical Perception of Continuous Quantitative Maps: The Effects of Spatial Frequency and Colormap Design.” In Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems, 1–12. Rheingans, Penny. 2002. “Are We There yet? Exploring with Dynamic Visualization.” IEEE Computer Graphics and Applications 22 (1): 6–10. Rich Harris and the Svelte Core Team. 2024. “Svelte.” https://svelte.dev. Ruiz, Jenny, Estefanı́a Serral, and Monique Snoeck. 2021. “Unifying Functional User Interface Design Principles.” International Journal of Human–Computer Interaction 37 (1): 47–67. Saket, Bahador, Arjun Srinivasan, Eric D Ragan, and Alex Endert. 2017. “Evaluating Interactive Graphical Encodings for Data Visualization.” IEEE Transactions on Visualization and Computer Graphics 24 (3): 1316–30. Sarikaya, Alper, Michael Correll, Lyn Bartram, Melanie Tory, and Danyel Fisher. 2018. “What Do We Talk about When We Talk about Dashboards?” IEEE Transactions on Visualization and Computer Graphics 25 (1): 682–92. Satyanarayan, Arvind, Dominik Moritz, Kanit Wongsuphasawat, and Jeffrey Heer. 2016. “Vega-Lite: A Grammar of Interactive Graphics.” IEEE Transactions on Visualization and Computer Graphics 23 (1): 341–50. Satyanarayan, Arvind, Ryan Russell, Jane Hoffswell, and Jeffrey Heer. 2015. “Reactive Vega: A Streaming Dataflow Architecture for Declarative Interactive Visualization.” IEEE Transactions on Visualization and Computer Graphics 22 (1): 659–68. Shneiderman, Ben. 2003. “The Eyes Have It: A Task by Data Type Taxonomy for Information Visualizations.” In The Craft of Information Visualization, 364–71. Elsevier. Splechtna, Rainer, Michael Beham, Denis Gračanin, Marı́a Luján Ganuza, Katja Bühler, Igor Sunday Pandžić, and Krešimir Matković. 2018. “Cross-Table Linking and Brushing: Interactive Visual Analysis of Multiple Tabular Data Sets.” The Visual Computer 34 (6): 1087–98. Stevens, Stanley Smith. 1946. “On the Theory of Scales of Measurement.” Science 103 (2684): 677–80. ———. 1951. “Mathematics, Measurement, and Psychophysics.” Swayne, Deborah F., Dianne Cook, and Andreas Buja. 1998. “XGobi: Interactive Dynamic Data Visualization in the X Window System.” J. Comput. Graph. Stat. 7 (1): 113–30. https://doi.org/10.1080/10618600.1998.10474764. Swayne, Deborah F., Duncan Temple Lang, Andreas Buja, and Dianne Cook. 2003. “GGobi: evolving from XGobi into an extensible framework for interactive data visualization.” Comput. Statist. Data Anal. 43 (4): 423–44. https://doi.org/10.1016/S0167-9473(02)00286-4. Tal, Eran. 2025. “Models and Measurement.” The Routledge Handbook of Philosophy of Scientific Modeling, 256–69. The New York Times Company. 2025. “Graphics.” The New York Times. https://www.nytimes.com/spotlight/graphics. Theus, Martin. 2002. “Interactive Data Visualization using Mondrian.” J. Stat. Soft. 7 (November): 1–9. https://doi.org/10.18637/jss.v007.i11. ———. 2008. “High-Dimensional Data Visualization.” In Handbook of Data Visualization, 152–75. Springer Science &amp; Business Media. Tierney, Luke. 1990. Lisp-Stat: An Object-Oriented Environment for Statistical Computing and Dynamic Graphics. New York: Wiley-Interscience. Tufte, Edward R. 2001. The Visual Display of Quantitative Information. Cheshire, Connecticut: Graphics Press LLC. Tukey, John W. 1962. “The Future of Data Analysis.” The Annals of Mathematical Statistics 33 (1): 1–67. Tukey, John W et al. 1977. Exploratory Data Analysis. Vol. 2. Reading, MA. Tukey, John W. 1986. “Data Analysis and Behavioral Science or Learning to Bear the Quantitative Man’s Burden by Shunning Badmandments.” The Collected Works of John W. Tukey 3: 391–484. ———. 1993. “Graphic Comparisons of Several Linked Aspects: Alternatives and Suggested Principles.” Journal of Computational and Graphical Statistics 2 (1): 1–33. Unwin, Antony. 1999. “Requirements for interactive graphics software for exploratory data analysis.” Comput. Statist. 14 (1): 7–22. https://doi.org/10.1007/PL00022706. ———. 2000. “Visualisation for Data Mining.” In International Conference on Data Mining, Visualization and Statistical System, séoul, Korea. Citeseer. ———. 2018. Graphical Data Analysis with r. Chapman; Hall/CRC. Unwin, Antony, George Hawkins, Heike Hofmann, and Bernd Siegl. 1996. “Interactive Graphics for Data Sets with Missing Values—MANET.” Journal of Computational and Graphical Statistics 5 (2): 113–22. Unwin, Antony, Martin Theus, Heike Hofmann, and Antony Unwin. 2006. “Interacting with Graphics.” Graphics of Large Datasets: Visualizing a Million, 73–101. Urbanek, Simon. 2002. “Different Ways to See a Tree-KLIMT.” In Compstat: Proceedings in Computational Statistics, 303–8. Springer. ———. 2011. “iPlots eXtreme: Next-Generation Interactive Graphics Design and Implementation of Modern Interactive Graphics.” Computational Statistics 26 (3): 381–93. Urbanek, Simon, and Martin Theus. 2003. “iPlots: High Interaction Graphics for r.” In Proceedings of the 3rd International Workshop on Distributed Statistical Computing. Citeseer. Urbanek, Simon, and Antony R Unwin. 2001. “Making Trees Interactive-KLIMT.” In Proc. Of the 33th Symposium of the Interface of Computing Science and Statistics. Citeseer. Vaidyanathan, Ramnath, Yihui Xie, JJ Allaire, Joe Cheng, Carson Sievert, and Kenton Russell. 2021. Htmlwidgets: HTML Widgets for r. https://CRAN.R-project.org/package=htmlwidgets. Vega Project. 2022. “Example Gallery: Interactive.” https://vega.github.io/vega-lite/examples/#interactive. ———. 2024a. “Binding a Parameter.” https://vega.github.io/vega-lite/docs/bind.html. ———. 2024b. “Brushing Scatter Plots Example.” Vega. https://vega.github.io/vega/examples/brushing-scatter-plots. ———. 2024c. “Dynamic Behaviors with Parameters.” https://vega.github.io/vega-lite/docs/parameter.html. ———. 2024d. “Vega and D3.” Vega. https://vega.github.io/vega/about/vega-and-d3. Velleman, Paul F, and Pratt Paul. 1989. “A Graphical Interface for Data Analysis.” Journal of Statistical Computation and Simulation 32 (4): 223–28. Velleman, Paul F, and Leland Wilkinson. 1993. “Nominal, Ordinal, Interval, and Ratio Typologies Are Misleading.” The American Statistician 47 (1): 65–72. Waddell, Adrian, and R. Wayne Oldford. 2023. Loon: Interactive Statistical Data Visualization. https://CRAN.R-project.org/package=loon. Ward, Matthew O, Georges Grinstein, and Daniel Keim. 2015. Interactive Data Visualization: Foundations, Techniques, and Applications. CRC Press. Ware, Colin. 2019. Information Visualization: Perception for Design. Morgan Kaufmann. Wickham, Hadley. 2011. “The Split-Apply-Combine Strategy for Data Analysis.” Journal of Statistical Software 40: 1–29. ———. 2016. Ggplot2: Elegant Graphics for Data Analysis (2e). Springer-Verlag New York. https://ggplot2.tidyverse.org. Wickham, Hadley, and Danielle Navarro. 2024. Ggplot2: Elegant Graphics for Data Analysis (3e). https://ggplot2-book.org. Wikipedia. 2022. “Duck test - Wikipedia.” https://en.wikipedia.org/w/index.php?title=Duck_test&amp;oldid=1110781513. Wilhelm, Adalbert. 2003. “User interaction at various levels of data displays.” Comput. Statist. Data Anal. 43 (4): 471–94. https://doi.org/10.1016/S0167-9473(02)00288-8. ———. 2008. “Linked Views for Visual Exploration.” In Handbook of Data Visualization, 200–214. Springer Science &amp; Business Media. Wilkinson, Leland. 2012. The Grammar of Graphics. Springer. Wills, Graham. 2008. “Linked Data Views.” In Handbook of Data Visualization, 217–41. ch. II. 9. Springer Berlin/Heidelberg, Germany. Wills, Graham J. 2000. “Natural Selection: Interactive Subset Creation.” Journal of Computational and Graphical Statistics 9 (3): 544–57. Wirfs-Brock, Allen, and Brendan Eich. 2020. “JavaScript: the first 20 years.” Proc. ACM Program. Lang. 4 (HOPL): 1–189. https://doi.org/10.1145/3386327. Yi, Ji Soo, Youn ah Kang, John Stasko, and Julie A Jacko. 2007. “Toward a Deeper Understanding of the Role of Interaction in Information Visualization.” IEEE Transactions on Visualization and Computer Graphics 13 (6): 1224–31. Young, Forrest W, Pedro M Valero-Mora, and Michael Friendly. 2011. Visual Statistics: Seeing Data with Dynamic Interactive Graphics. John Wiley &amp; Sons. Technically, if there are any values \\(x_i &lt; a\\), we will have negative indices (\\(j &lt; 0\\)), and if all values are significantly larger than the anchor, such that \\(x_i &gt; a + w\\), the indices will not start at 1. So, to implement the histogram properly, we should shift all indices by subtracting the minimum index. Finally, if the histogram binwidth is not fixed, the function becomes more complicated as well.↩︎ "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
