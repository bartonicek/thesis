[["problem-set.html", "3 Problem Set 3.1 Data representation 3.2 Data transformation 3.3 Scaling", " 3 Problem Set Designing an interactive data visualization system presents a unique set of challenges which need to be addressed. Some of these have been already mentioned in the Introduction. This section discusses these inherent challenges in greater depth, and begins exploring avenues for possible solutions. 3.1 Data representation There is no data visualization without data. However, all data is not equal. Data can come to use in various shapes and sizes, and this can affect various aspects of the system, including design, memory, and performance. In most data analytic languages, the default data model is that of two-dimensional table or dataframe. Examples include the S3 data.frame class in base R (R Core Team 2024), the tbl_df S3 class in the tibble package (Müller and Wickham 2023), the DataFrame class in the Python pandas package (Pandas Core Team 2024), the DataFrame class in the polars library (Team 2024), or the DataFrame type in the Julia DataFrame.jl package (Bouchet-Valat and Kamiński 2023). In this model, data is organized in columns, which are homogeneous arrays each storing values of the same type. Unlike in a matrix, the columns can be of different types (such as floats, integers, or strings). The dataframe object is then just a dictionary of columns, with some optional metadata, such as row names, column labels, or grouping structure (R Core Team 2024; Bouchet-Valat and Kamiński 2023). However, this column-based organization of data is not universal. For example, in the popular JavaScript data visualization and transformation library D3 (Bostock 2022) ascribes to a row-based data model, such that data is organized as an array of rows, with each row being its own separate dictionary. In a more general programming context, the column-based and row-based data layouts are also known as the struct of arrays (SoA) and array of structs (AoS) data structures, respectively. These data layouts have generally different performance characteristics, and hence why they are also studied in database design (see e.g. Abadi et al. 2013). The SoA layout has (typically) smaller memory footprint and better performance in tight loops that operate on individual columns, thanks to cache locality (Abadi et al. 2013; Acton 2014; Kelley 2023). The AoS layout can have arguably better developer ergonomics and can perform better when retrieving individual records/rows (hence why it is more common in traditional Online Transaction Processing databases, Abadi et al. 2013). 3.2 Data transformation When visualizing data, it is rarely the case that we can just draw the raw data as is. Often, the quantities underlying a specific plot type are instead summaries or aggregates of some kind. Take for example a typical barplot. To draw a barplot, we first need to divide the data into disjoint parts, each corresponding to one bar, and then summarize each part by some metric, usually either the number of cases (count) or the sum of some continuous variable. Similarly, in a histogram, we first need to divide the data into bins and then summarize them (typically by count). Thus, there are two fundamental operations involved in every visualization: splitting the data into parts and computing the summaries on these parts. 3.2.1 Partitioning the data 3.2.1.1 Leave no data out A common-sense guideline that many data visualization experts provide is that faithful visualizations should show the full data and leave nothing out. For instance, Cleveland (1985) argues that axis limits should generally be expanded so that data points at or near these limits are not arbitrarily obscured. Take, for example, the following two scatterplots: Figure 3.1: Without expanding axes, data points near the limits can become obscured. Left: axis limits match the data limits exactly, and so points at or near the axis limits (top-left and bottom-right corner of the plot) are represented by smaller area and become less salient. Right: by expanding axis limits, we can ensure that all data is represented faithfully. In the left plot, the axis limits match the data limits exactly, whereas in the right plot, they are expanded by a small fraction (5%, ggplot2 default, Wickham 2016). The problem with the left plot is that the data points near the axis limits (top-left and bottom-right corner) are represented only by a fraction of the area: for example, the point in the bottom-right corner lies simultaneously at the limits of the x- and y-axis, and is thus represented only by 1/4 of the area of the points in the center of the plot. The example above shows how data can be obscured visually, even after all of the data points have been included in the plot (rendering all rows of the data set). Clearly then, when complete data is available, leaving information out by arbitrarily dropping rows is even less acceptable. This issue becomes more complicated in the presence of missing or incomplete data, however, there exist ways of dealing with that as well, see e.g. Unwin et al. (1996), Tierney and Cook (2023). Thus, ideally, the visualization should represent a surjective mapping from the space of the geometric objects to the underlying data set, such that, by default, there are no cases (rows of the data) which are marginalized or left out of the figure entirely (Ziemkiewicz and Kosara 2009). 3.2.1.2 Distinctness, disjointness, and comparison “To be truthful and revealing, data graphics must bear on the question at the heart of quantitative thinking: ‘compared to what’?” (Tufte 2001, 74). “Graphics are for comparison - comparison of one kind or another - not for access to individual amounts.” (Tukey 1993) In data visualization, a practice so ubiquitous that it is often overlooked is that, in most types of plots, each geometric object represents one disjoint part of the data. That is, each point, bar, line, or polygon typically represents a unique set of cases (rows of the data), with no overlap with the cases represented by the other objects. Why is this the case? This unconscious “law” might be rooted in the fundamental purpose of data visualization: comparison (Tufte 2001; Tukey 1993). When we visualize, we draw our graphics with the ultimate goal of being able to compare our data along a set of visual channels, such as position, length, size, or colour (Bertin 1983; Wilkinson 2012; Franconeri et al. 2021; Wilke 2019). This mirrors the comparisons we make in the real world, where we compare physical objects along their respective dimensions or attributes. With disjoint parts, there is a natural correspondence or bijection between the subsets of the data and their visual representation, see figure 3.2. Specifically, if we imagine the act of taking an object and picking the corresponding set of cases as a function, then, with disjoint parts, this function is invertible: we can pick an object, identify the corresponding set of cases, and then use that set to get back the original object. In plots where the objects do not represent disjoint subsets of the data, this correspondence is broken: if we identify cases corresponding to a single object, there is no way to go back from these cases to the original object. Figure 3.2: Disjoint subsets provide a one-to-one correspondence (bijection) between geometric objects and the data. Suppose we mark out the cases corresponding to one object (the left most bar). Top row: if each geometric object (bar) represents unique set of cases, we can easily go back and forth between the object and its underlying data (middle panel). Thus, the function of picking a set of cases corresponding to an object is bijective. Bottom row: when there is an overlap between the cases represented by each object, once we pick the set of cases corresponding to that object, there is no simple way to use that set to get the corresponding object back. To illustrate this idea on concrete data, take the following barplot representing vote share among the top three parties in the 2023 New Zealand general election (Electoral Commission New Zealand 2023): Figure 3.3: Geometric objects typically represent disjoint subsets of the data. The plot shows the vote share of the top three parties in the 2023 New Zealand general election, with each bar representing a unique subset of voters. Each bar represents a unique set of voters and thus the subsets of the data represented by the bars are disjoint. Technically, there is no hard and fast rule about this. For example, we could transform the first bar by taking a union of the votes of National and Labour parties, and represent the same underlying data the following way: Figure 3.4: Hypothetically, there is nothing preventing us from encoding the same information in multiple objects, and showing non-disjoint parts of our data. The plot shows the same underlying data as 3.2, with the leftmost bar representing a union of National and Labour voters. The two leftmost bars thus do not represent disjoint subsets of the data. For a more realistic example, see Figure 3.6. However, this way of representing the data has several problems. First, there is the issue of its suitability towards the main goal of the visualization. Specifically, when visualizing election data such as this one, we are typically interested in judging the relative number of votes each party received. The second barplot makes this comparison difficult. Specifically, in the second barplot, since the National bar represents a subset of the National OR Labour bar, we have to perform additional mental calculation if we want to find out how many votes Labour received and compare the absolute counts directly (Cleveland 1985). Second, we have metadata knowledge (see e.g. Wilkinson 2012; Velleman and Wilkinson 1993) about the data being disjoint - we know that, in the New Zealand parliament electoral system, each voter can only cast one vote for a single party. Finally, there is the issue of duplicating information: in the second barplot, the number of votes the National party received is counted twice, once in the leftmost bar and again in the second-left bar. This goes against the general principle of representing our data in the most parsimonious way (Tufte 2001). Even when our goal is not to compare absolute counts, there are usually better disjoint data visualization techniques available. For example, if we were interested in visualizing the proportion of votes that each party received, we could draw the following plot: Figure 3.5: Even when proportions are of interest, there are usually disjoint data visualization techniques available. The plot shows proportion of vote share of the top three parties in the 2023 New Zealand general election, with each bar segment again representing a unique subset of voters. By stacking the bar segments on top of each other, we can easily compare proportion of the total number of votes while retaining a parsimonious representation of our data. Each bar segments now again represents a unique subset of voters. The example above was fairly clear case of where a non-disjoint representation of the data would be the wrong choice, however, there are also more ambiguous situations. One such situation is when there are multiple attributes of the data which can be simultaneously present or absent for each case. For example, in 2020, a joint referendum was held in New Zealand on the question of legalization of euthanasia and cannabis. The two issues were simultaneously included on the same ballot. The legalization of euthanasia was accepted by the voters, with 65.1% of votes supporting the decision, whereas the legalization of cannabis was rejected, with 50.7% of voters rejecting the decision (Electoral Commission New Zealand 2020). The referendum data can be visualized in the following way: Figure 3.6: Realistic example of a non-disjoint data representation. The plot shows the vote share in the combined 2020 New Zealand referendum on euthanasia and cannabis, where the two issues were simultaneousy presented on the same ballot. The two bars each show (mostly) the same subset of ballot, with each ballot contributing to the height of one segment in each bar. By definition, both bars include votes which were cast by the same voter (ignoring the votes where no preference was given for either issue, Electoral Commission New Zealand 2020). Thus, the sets of voters that the two bars and the four bar segments represent overlap. In general, there is nothing inherently wrong with the plot above. Non-disjoint representations of the data can work well for certain data types such as set-typed data (see e.g. Alsallakh et al. 2014). In the context of static data visualization, plots like these can serve useful roles. However, even here, there is a simple way of representing the same data in a disjoint way - draw two separate plots: Figure 3.7: Non-disjoint data representations can often be recast into disjoint ones. The figure again shows the vote share in the combined 2020 New Zealand referendum on euthanasia and cannabis, however, now each issue is plotted in a separate plot, and thus each geometric object in each plot represents a unique subset of ballots/voters. Why should we care about whether our representations of the data are disjoint or not? I argue that, for many types of plots, disjointness presents a better mental model: one geometric object for one unique set of observational units or “things”. Conversely, if the objects in our plots do not represent disjoint subsets, then we need to keep track of how these objects are related. This issue may be particularly true for interactive visualization. The natural correspondence between geometric objects and disjoint subsets of the data makes certain interactions more intuitive. Conversely, overlapping subsets introduce complications. For instance, when a user clicks on a bar in a linked barplot, they might be surprised if parts of the other bars within the same plot get highlighted as well: they intended to highlight that bar, not the others. Likewise, when querying, if our objects do not represent disjoint subsets of the data, we have to think about what querying means: are we querying the objects or the cases corresponding to the objects? Disjoint partitions simplify our mental model, and this may be the reason why some authors discuss interactive features in the context of partitions (see e.g. Buja, Cook, and Swayne 1996; Keim 2002). SQL aggregation queries (GROUP BY) are based on partitions (Hellerstein et al. 1999). 3.2.1.3 Plots as partitions In the two preceding sections, I have argued that our interactive data visualization system should have fulfill have two fundamental properties: Plots should show the full data (surjective mapping) Geometric objects within these plots should represent distinct subsets (disjoint parts) These two properties suggest a fundamental model for plots: that of a partitions. While I have not been able to find explicit references linking geometric objects to partitions, some authors have used the language of partitions. For example, Wilkinson (2012, pp 210) and Keim (2002) have linked stacked plots to (hierarchical) partitions. 3.2.1.4 Partitions and products In a typical interactive plot, the data will be partitioned across multiple dimensions. To give a concrete example, suppose we want to draw the following barplot: We start with the following data, which includes a categorical variable (group) that we will plot along the x-axis, a variable representing selection status (selection) that we will color the bar segments with, and a continuous variable that we want to summarize (value): group selection value 1 A 1 12 2 A 1 21 3 A 2 10 4 B 1 9 5 B 2 15 6 C 1 15 7 C 2 12 8 C 2 13 To draw the individual bar segments, we need to sum the value variable across the cases corresponding to each segment. To do this, we first need to split our data into multiple small disjoint subsets according to the product of group and selection variables: # Using paste0() here to simulate a product of two factors product_factor &lt;- paste0(df$group, df$selection) split_dfs &lt;- split(df, product_factor) render_tables(split_dfs) group selection value A 1 12 A 1 21 group selection value 3 A 2 10 group selection value 4 B 1 9 group selection value 5 B 2 15 group selection value 6 C 1 15 group selection value 7 C 2 12 8 C 2 13 We could then summarize each small data set by summing value: summarized_dfs &lt;- lapply(split_dfs, function(x) { aggregate(value ~ ., data = x, sum) }) render_tables(summarized_dfs) group selection value A 1 33 group selection value A 2 10 group selection value B 1 9 group selection value B 2 15 group selection value C 1 15 group selection value C 2 25 Finally, to “stack” the segments on top of each other, we need to combine the summaries back together, according to the levels of group variable, and take the cumulative sum: grouped_dfs &lt;- split(summarized_dfs, sapply(summarized_dfs, function(x) x$group)) stacked_dfs &lt;- lapply(grouped_dfs, function(x) { x &lt;- do.call(rbind, x) x$value &lt;- cumsum(x$value) rownames(x) &lt;- NULL x }) render_tables(stacked_dfs) group selection value A 1 33 A 2 43 group selection value B 1 9 B 2 24 group selection value C 1 15 C 2 40 Now, we can combine the tables into one data set and render: combined_df &lt;- do.call(rbind, stacked_dfs) combined_df$selection &lt;- factor(combined_df$selection, levels = c(2, 1)) # Need to reverse data order for ggplot2 to layer segments appropriately combined_df &lt;- combined_df[6:1, ] ggplot(combined_df, aes(x = group, y = value, fill = selection)) + geom_col(position = position_identity(), col = &quot;white&quot;) Now, we have shown how we can compute summary statistics for a stacked barplot using a simple split-apply-combine pipeline (Wickham 2011). This is in fact what happens implicitly in most ggplot2 plots: ggplot(data, aes(x, y, fill = fill)) + geom_bar() In the call above, we partition the data set by the Cartesian product of the x, y, and fill variables. That is, we break the data into parts based on the unique combinations of these variables, and then compute whatever statistical transformation we need. See the following comment from the ggplot2 documentation (Wickham 2016): # If the `group` variable is not present, then a new group # variable is generated from the interaction of all discrete (factor or # character) vectors, excluding `label`. 3.2.1.5 Limits of simple product partitions For many types of plots, the simple strategy of taking products of factors to form a single “flat” partition of the data works reasonably well. However, for other types of plots, this flat model is not enough. To give a concrete example, let’s turn back to the barplot from the section 3.2.1.3. To draw the barplot, we first split our data into smaller tables, summarized each table by summing up the values, stacked the summaries by taking their cumulative sum, and finally used these to draw the bar segments. This gave us a good visualization for comparing absolute counts across the categories. However, what if we wanted to compare proportions? It turns out there is another type of visualization, called spineplot, which can be used to represent the same underlying data that barplot can, however, is much more useful for comparing proportions: Figure 3.8: The same underlying data represented as a barplot (left) and a spineplot (right). A spineplot represents the same underlying statistic as a barplot (usually sums of counts). However, unlike in barplot, where the underlying statistic gets mapped to the y-axis position/bar height, in spineplot, the underlying summary statistic gets mapped to two aesthetics: the y-axis position and the bar width. Further, the y-axis position gets normalized, such that the heights of the different segments add up to one. The result is a visualization that makes it easy to compare relative proportions across the categories. The fact that the spineplot makes it easy to see relative proportions makes it a very useful visualization. Notice how, in Figure 3.8, the spineplot makes it much easier to see that the proportions of the red cases are same across the B and C groups. Thus, spineplot is a definitely desirable type of representation for categorical data, especially if we can easily switch between it and the barplot. However, despite the fact that both the barplot and the spineplot represent the same underlying summaries, turning one into the other is not a always trivial exercise. For example, in ggplot2, while it is easy to create a barplot using the simple declarative syntax, there is no such simple recipe for spineplots. To create the spineplot in Figure 3.8 took over 10 lines of external data wrangling code (using standard dplyr syntax). Both aesthetics are stacked: width horizontally, across bars, y-axis position vertically, across bar segments. The important thing to notice that, The reason for this is because we have ignored or side-stepped certain issues. For example, how do we know if we are stacking the summaries in the right order? What if we need to transform the bar segments in some way, such as divide by the height of the parent bar, to show proportions rather than absolute counts? Once we start dealing with plots like spineplots or spinograms, it becomes clear that the flat partition structure is not enough. 3.2.1.6 Partitions and hierarchy Keim (2002) stacked plots are suited for hierarchically-partitioned data. 3.2.1.7 Partition data structures 3.2.2 Computing summaries After we have partitioned our data, we need a way to summarize each part by a set of summary statistics. Moreover, since the partitions of our data (may) form a hierarchy, we also need a way of referring to parts across the levels of the hierarchy. 3.2.2.1 Reducers Suppose we are summarizing a part consisting of \\(n\\) data points. 3.3 Scaling Information needs to be encoded in visual attributes (Cleveland 1985) Transformation is a critical tool for visualization or for any other mode of data analysis because it can substantially simplify the structure of a set of data (Cleveland 1993, 48) References Abadi, Daniel, Peter Boncz, Stavros Harizopoulos, Stratos Idreos, Samuel Madden, et al. 2013. “The Design and Implementation of Modern Column-Oriented Database Systems.” Foundations and Trends in Databases 5 (3): 197–280. Acton, Mike. 2014. “Data-Oriented Design and c++.” Luento. CppCon. https://www.youtube.com/watch?v=rX0ItVEVjHc. Alsallakh, Bilal, Luana Micallef, Wolfgang Aigner, Helwig Hauser, Silvia Miksch, and Peter Rodgers. 2014. “Visualizing Sets and Set-Typed Data: State-of-the-Art and Future Challenges.” Eurographics Conference on Visualization (EuroVis). Bertin, Jacques. 1983. Semiology of Graphics. University of Wisconsin press. Bostock, Mike. 2022. “D3.js - Data-Driven Documents.” https://d3js.org. Bouchet-Valat, Milan, and Bogumił Kamiński. 2023. “DataFrames.jl: Flexible and Fast Tabular Data in Julia.” Journal of Statistical Software 107 (September): 1–32. https://doi.org/10.18637/jss.v107.i04. Buja, Andreas, Dianne Cook, and Deborah F Swayne. 1996. “Interactive High-Dimensional Data Visualization.” Journal of Computational and Graphical Statistics 5 (1): 78–99. Cleveland, William S. 1985. The Elements of Graphing Data. Wadsworth Publ. Co. ———. 1993. Visualizing Data. Hobart press. Electoral Commission New Zealand. 2020. “Official Referendum Results Released.” https://elections.nz/media-and-news/2020/official-referendum-results-released. ———. 2023. “E9 Statistics - Overall Results.” https://www.electionresults.govt.nz/electionresults_2023/index.html. Franconeri, Steven L, Lace M Padilla, Priti Shah, Jeffrey M Zacks, and Jessica Hullman. 2021. “The Science of Visual Data Communication: What Works.” Psychological Science in the Public Interest 22 (3): 110–61. Hellerstein, J. M., R. Avnur, A. Chou, C. Hidber, C. Olston, and V. Raman. 1999. “Interactive data analysis: the Control project.” Computer 32 (8): 51–59. https://doi.org/10.1109/2.781635. Keim, Daniel A. 2002. “Information Visualization and Visual Data Mining.” IEEE Transactions on Visualization and Computer Graphics 8 (1): 1–8. Kelley, Andew. 2023. “A Practical Guide to Applying Data Oriented Design (DoD).” Handmade Seattle. https://www.youtube.com/watch?v=IroPQ150F6c. Müller, Kirill, and Hadley Wickham. 2023. Tibble: Simple Data Frames. https://CRAN.R-project.org/package=tibble. Pandas Core Team. 2024. “DataFrame — Pandas 2.2.3 Documentation.” https://pandas.pydata.org/docs/reference/frame.html. R Core Team. 2024. R: A Language and Environment for Statistical Computing. Vienna, Austria: R Foundation for Statistical Computing. https://www.R-project.org/. Team, Polars Core. 2024. “Index - Polars User Guide.” https://docs.pola.rs. Tierney, Nicholas, and Dianne Cook. 2023. “Expanding Tidy Data Principles to Facilitate Missing Data Exploration, Visualization and Assessment of Imputations.” J. Stat. Soft. 105 (February): 1–31. https://doi.org/10.18637/jss.v105.i07. Tufte, Edward R. 2001. The Visual Display of Quantitative Information. Cheshire, Connecticut: Graphics Press LLC. Tukey, John W. 1993. “Graphic Comparisons of Several Linked Aspects: Alternatives and Suggested Principles.” Journal of Computational and Graphical Statistics 2 (1): 1–33. Unwin, Antony, George Hawkins, Heike Hofmann, and Bernd Siegl. 1996. “Interactive Graphics for Data Sets with Missing Values—MANET.” J. Comput. Graph. Stat., June. https://www.tandfonline.com/doi/abs/10.1080/10618600.1996.10474700. Velleman, Paul F, and Leland Wilkinson. 1993. “Nominal, Ordinal, Interval, and Ratio Typologies Are Misleading.” The American Statistician 47 (1): 65–72. Wickham, Hadley. 2011. “The Split-Apply-Combine Strategy for Data Analysis.” Journal of Statistical Software 40: 1–29. ———. 2016. Ggplot2: Elegant Graphics for Data Analysis. Springer-Verlag New York. https://ggplot2.tidyverse.org. Wilke, Claus O. 2019. Fundamentals of Data Visualization: A Primer on Making Informative and Compelling Figures. O’Reilly Media. Wilkinson, Leland. 2012. The Grammar of Graphics. Springer. Ziemkiewicz, Caroline, and Robert Kosara. 2009. “Embedding Information Visualization Within Visual Representation.” In Advances in Information and Intelligent Systems, 307–26. Springer. "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
