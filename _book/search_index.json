[["discussion.html", "9 Discussion 9.1 Limitations of the theoretical model 9.2 Limitations of the software", " 9 Discussion This thesis explored the role of interaction in data visualization pipelines. More specifically, I investigated how interaction affects the four stages of data visualization pipelines - partitioning, aggregation, scaling, and rendering - and explored the inherent problems and challenges. The main thrust of the argument was that the popular model implied by the Grammar of Graphics (Wilkinson 2012), which treats statistics and geometric objects as independent entities, is inadequate for describing the complex relationships between the components of interactive figures (see also Wu and Chang 2024). As an alternative, I proposed a simple category-theoretic model, conceptualizing the data visualization pipeline as a functor. The essence of the proposed model is as follows. Ultimately, when we visualize, we want to represent our data with a set of geometric objects. To do this, we need to partition our data into a collection of subsets. However, often, particularly with features like linked selection, we want to further partition these subsets, to be able to display highlighted parts of objects. This leads to a hierarchical structure: a tree (preorder) of data subsets ordered by set union. To maintain consistency during interactions like linked selection, the subsequent steps of the data visualization pipeline should preserve this structure. Put simply, the geometric objects in our plots and the underlying summary statistics should behave like set union. We can describe this property in category theoretic terms, by conceptualizing the mapping from data subsets to summary statistics as a functor (and, likewise, the mapping from statistics to geometric objects). Further, using the properties of set union, this functor definition allows us identify specific algebraic structures that our statistics and objects should conform to: groups and monoids. Specifically, to behave consistently, the operations underlying our plots should be associative and unital, and potentially also invertible, monotonic, and commutative. When these algebraic constraints are satisfied, the geometric objects in our plots will compose well, meaning that their parts will add up to a meaningful whole, and this ensures that features like linked selection remain consistent. To test the proposed model, I developed plotscaper, an R package for interactive data exploration (along with plotscape, its TypeScript-based backend). Together, the theoretical model and the software formed a crucial feedback loop, allowing me to refine important concepts. Specifically, many of the model’s key concepts emerged from practical challenges I encoutered during the packages’ development, and, by translating theory into code, I was able to empirically test and refine assumptions about the structure and behavior of interactive data visualizations. However, plotscaper was also developed to provide a practical tool for data exploration, not just theory testing. As outlined in Section 3, within the R ecosystem, there is currently no shortage of interactive data visualization packages and frameworks; however, many offer only fairly basic interactive features out of the box. Implementing complex features such as linked selection, representation switching, or parametric interaction (see section 3.2.5) often requires substantial programming expertise and time-investment, creating a barrier to entry for casual users (see e.g. Batch and Elmqvist 2017). Thus, a secondary goal of this project was to try to address this perceived gap, and this goal seems to have been met with moderate success. Despite its experimental status and the fact that it is competing with a number of far larger and better-established interactive data visualization frameworks, plotscaper has been downloaded over 1980 times1, in the 159 days since its initial release. Despite all of these relative successes, both the theoretical model and its practical implementation in plotscaper have, of course, their limitations. These will be the subject of the next few sections. 9.1 Limitations of the theoretical model First, it is important discuss the limitations of the theoretical model presented in this thesis. This model, described in Section 4, conceptualizes the data visualization pipeline as a structure-preserving mapping, also known as a functor. Specifically, a key initial assumption is that, when visualizing data, we start with a hierarchy of data subsets. These subsets are disjoint (share no overlapping data) and are ordered by set inclusion/union. To produce meaningful graphics, the subsequent steps of the data visualization pipeline should preserve this inherent structure and behave like set union. In category theoretic terms, this means that the aggregation and rendering steps of the data visualization pipeline have to be functors. Based on the properties of set union, this naturally identifies algebraic structures as groups and monoids. This proposed model of the data visualization pipeline naturally raises several questions and potential criticisms. Some of these have been already pre-emptyed in Section 4, however, they will be further discussed and expanded upon in the following subsections. My objective is to clearly articulate the model’s advantages, while also acknowledging its limitations and suggesting opportunities for future work. 9.1.1 Why the model is necessary First, let’s briefly restate the main argument presented throughout Section 4. As discussed in Section 4.2, ultimately, when visualizing data, we want to represent our data with geometric objects. These objects need to map onto some underlying data subsets. We create these subsets by partitioning based on some variable, such as a categorical variable in a barplot or a binned continuous variable in a histogram. Often, we also want to further partition the subsets by conditioning on another variable or variables. In particular, in interactive data visualization, features such as linked selection naturally impose this hierarchical partitioning on our data, by partitioning on selection status (and in the presence of aggregated views like barplots, see e.g. Wills 2008). After partitioning our data into subsets, we compute summary statistics on these subsets, map these summaries to aesthetic encodings, and finally render these encodings as geometric objects. Importantly, when the partitioning is hierarchical, the geometric objects we use to represent our data need to reflect this. To do this, data visualizations practitioners employ techniques like stacking, dodging, or layering. While dodging and layering are popular in static data visualization, in interactive visualization, stacking offers some unique advantages (see Section 4.3.1.4). Specifically, since objects formed with stacking better map onto the part-whole relationships in the underlying data, they have more consistent behavior under interaction, and also simplify certain computations. However, an important issue related to stacking is that the way we visually represent data is not independent of the way we summarize it. As discussed in Section 4.3.1.3, past data visualization researchers have noted the fact that while some summary statistics such as sums or counts can be effectively stacked, others like averages or quantiles cannot (see e.g. Wilke 2019; Wills 2011; Wu 2022). For instance, while the sum of sums or maximum of maximums represent valid overall statistics, the average of averages is different from grand mean. Further, the issue clearly extends to other types of plots than just barplots: some statistics allow us to represent objects composed of parts, while others do not. Early in the project, I was lucky to come across some ideas from functional programming, which in turn lead me to the key insight that these part-whole relationships underlying geometric objects and summary statistics can be described algebraically, by using some fundamental concepts from category theory. This lead me to develop a simple algebraic model of graphics, relying on functors, monoids, and groups. By grounding our reasoning in this algebraic model, we can quickly identify which combinations of statistics and geometric objects will compose into part-whole relationships, and thus behave well under features like linked selection. For instance, since the average operator is not a monoid, it will not compose into part-whole relations, and thus we know that it will present certain challenges if we try to combine it with linked selection. Further, the model also allows us to identify what kinds of linked selection will work. For instance, because the maximum and convex hull operators are monoids, they will work well when comparing nested subsets (e.g. single selection group vs. all cases). However, because they lack an inverse, they will be inappropriate for comparing disjoint subsets (multiple distinct selection groups, see Section 4.3.2.8). 9.1.2 Disjointness As discussed above, the models fundamentally rests on a hierarchy of data subsets organized into partitions, such that all subsets within a partition are disjoint. This is a core assumption of the model. While this assumption holds true for most common plot types, certain visualizations deviate from this model. Specifically, visualizations where geometric objects within the same graphical layer represent overlapping data subsets do not adhere to this assumption. Examples include specific visualizations of set-typed data (see e.g. Alsallakh et al. 2014) or two-dimensional kernel density plots (see Section 4.2.2). However, these non-disjoint visualizations represent only a small fraction of all available plot types. In the vast majority of “standard” plots - including barplots, histograms, scatterplots, density plots, heatmaps, violin plots, boxplots, lineplots, and parallel coordinate plots - each geometric object represents a distinct subset of cases2. In Section 4.2.2, I argued that this tendency towards disjoint data representations is not a mere convention or accident, but instead stems from a fundamental naturality of disjointness. Disjointness underlies many fundamental concepts in statistics, programming, and mathematics, and, in general, seems to align better with our cognitive processes (see Section 4.2.2). Put simply, it is far easier to reason about and manipulate objects which are distinct rather than ones which are entangled (see also Hickey 2011). Therefore, I contend that disjointness is particularly well-suited to interactive data visualization. Conversely, with non-disjoint data representations, certain interactive features may become difficult or even impossible to implement. For example, how would one implement meaningful linked selection with a two-dimensional kernel density plots, without referencing the underlying (disjoint) data points? To summarize, while not the only option, I contend that disjointness provides a good default model for interactive graphics. 9.1.3 Associativity and unitality The core idea of the model is preservation of the properties of set union. Among these, the two most important ones are associativity and unitality. Associativity ensures that we can perform the summary operations in any order, while unitality guarantees that empty data subsets can be handled properly. Further, as discussed in Section 4.3.2.6, together, these two properties identify a central class of algebraic structures: monoids. This connection between set union and monoids is not novel. For instance, monoids have long been known to have desirable properties for parallel computing (see e.g. Parent 2018; Fegaras 2017; Lin 2013). As a side note, the challenges we face when visualizing data are in some ways remarkably similar to those in parallel computing: often, we want to break the data into parts, compute some summaries, and the combine these back together to yield some meaningful aggregate. More broadly, monoids are also popular functional programming (see e.g. Milewski 2018), and form the basis of certain algorithms in generic programming (Stepanov and McJones 2009; Stepanov 2013). Finally, monoids and other concepts from category theory have also been used in certain areas of relational database theory (see e.g. Fong and Spivak 2019; Gibbons et al. 2018) However, to my knowledge, I am the first to make the connection between monoids and many popular visualization types. As discussed in Section 4.3.2.1, while there has been some limited number of applications of category theory to data visualization, the way I have used category-theoretic concepts differs significantly from all of these. On one hand, it is significantly more applied than some other past applications (see e.g. Beckmann 1995; Hutchins 1999; Vickers, Faith, and Rossiter 2012), due to the fact that it relates to concrete statistics, geometric objects, and interactive features, rather than broad ideas about the nature of the visualization process. On the other hand, it is also more theoretical than other applications, since it does not require any specific implementation; the work presented in this thesis is not a functional programming library. During my survey of the data visualization literature, I did not find any references explicitly linking common plot types such as barplots or histograms to groups and monoids. The only hints of similar ideas I have been able to find has been in the documentation of Crossfilter, a JavaScript library for exploring large multi-dimensional data sets Gordon Woodhull (2025). However, this documentation only discusses properties like associativity and commutativity, without connecting them to algebraic structures. Associativity and unitality have some interesting implications for data visualization systems. Firstly, due to the previously mentioned connections to parallel computing, associativity suggests that a data visualization system built around monoids can be easily parallelized. This enables improved performance and make it suitable for distributed computing. Secondly, unitality also has interesting consequences. Specifically, it ensures that empty data subsets have unambiguous representations, and, conversely, lack of unitality may cause ambiguities. For example, the average operator is not unital, since the average of an empty set is not defined. This can create issues when visualizing data, such as drawing a bar plot where some categories are empty. While we might choose to omit bars for empty categories, this leads to an ambiguous representation, such that absence of a bar can indicate one of two things: either there were no cases in the category and their average is undefined, or there were cases and their average was equal to the y-axis intercept. In contrast, since the sum is unital, the representation is always clear: a missing bar unambiguously indicates a sum of zero, regardless of whether there were cases in the category or not. This also provides a potential new perspective on the perennial debate in data visualization: should the base of the barplot always start at zero or not (see e.g. Cleveland 1985; Wilkinson 2012)? Since the monoidal unit represents the default state of “no data”, it could serve as the default choice for the barplot’s base, such that, for example, the base of a barplot of products would be one. 9.1.4 Model constraints and utility A potential point of contention is that the constraints which the model provides are too rigid. Specifically, requiring all plots to be groups or monoids excludes a significant fraction of popular visualizations. Further, many non-monoidal plot types, such as boxplots, have been successfully implemented alongside linked selection in the past (see e.g. Theus 2002; Urbanek 2011). Thus, a valid question one might have is whether the limitations imposed by the model are justified by its practical utility. However, I believe this is not an issue, since the model is not meant to be prescriptive. Instead, it simply provides a framework for identifying visualizations which are “naturally” compatible with features like linked selection, and we are free to violate this naturality whenever we see fit. However, we should be aware of the fact that reconciling non-monoidal visualizations with linked selection may require some ad hoc design decisions. For instance, since a boxplot box is not a monoid, there is no such thing as highlighting a “part of a boxplot box”. We may solve this issue by e.g. plotting the highlighted cases as a second box next to the original one, however, then we lose the nice interactive properties of part-whole relations provided by monoidal plots (see Section 4.3.1.4). Thus, the model helps us to identify inherent trade-offs in the design and implementation of interactive graphics. 9.2 Limitations of the software During this project, I had time to think through and test out different implementations of the various features of the interactive data visualization system. While I succeeded in some areas, there were also areas which could still use further improvement. 9.2.1 Scope and features Currently, plotscaper offers a number of features for creating and manipulating interactive figures, many of which have been discussed either in Section 7 or in Section 8. While these features can be used to create a fairly substantial range of useful interactive figures, there are of course many limitations and gaps when compared to other, better-established established data visualization packages. These will be discussed in this section. First, plotscaper currently offers six plot types: scatterplots, barplots, histograms, fluctuation diagrams, histograms, two-dimensional histograms, and parallel coordinate plots. Additionally, normalized representations, such as spineplots and spinograms, are available for all aggregate plots. While these six plot types can already be used to create a wide range of useful interactive figures, there are numerous other plots which could be highly desirable in applied data analysis. Density plots, radar plots, mosaic plots, and maps, for example, may be compatible with the plotscaper model and could be potential additions in future versions of the package. Furthermore, a relatively simple addition which could be useful would be horizontal barplots. Finally, all plots are specified in a nominal way, meaning that, for example, to add a scatterplot, we call the add_scatterplot function. While a system for specifying plots declaratively would be appealing, implementing such a system has presented challenges, and the issue will be discussed in more depth in Section 9.2.2. Second, as described in Section 7, plotscaper currently uses a simple transient-persistent product model for linked selection. Users can transiently select cases or assign them to permanent groups via click or click-and-drag interactions. The combination of transient and persistent selection results in \\(2 \\times 4 = 8\\) possible selection states per case. This model facilitates simple conditional queries, such as “how many cases assigned to group X are also transiently selected?” For example, users can assign a bar in a barplot to a permanent group and transiently select a point cluster in a scatterplot to easily identify cases belonging to both. However, this model is, of course, fairly limited: it does not allow to combine selections with logical operators such as negation or exclusive difference. Implementing more comprehensive selection operators (see e.g. Urbanek and Theus 2003; Urbanek 2011; Theus 2002; Wilhelm 2008) would enable more sophisticated analytical workflows. Finally, selection geometry is currently restricted to point-clicks or rectangular regions defined by clicking-and-dragging. While these are fairly simple and intuitive, alternative selection strategies, such as a movable selection brush, a circular region expanding around a point, or arbitrary lasso/polygon, could prove beneficial in specific contexts (see e.g. Wills 2008). Third, there are several other interactive features which could also be further polished, particularly. For instance, while it is currently possible to sort barplot bars by height, expanding sorting capabilities to other plot types and implementing alternative sorting schemes, such as sorting by the heights of highlighted segments, could be beneficial. Similarly, manual axis reordering in parallel coordinate plots could prove valuable. For continuous scales, the ability to interactively switch to alternative transformations, such as a logarithmic scale, would also be useful. Regarding querying, while the system currently supports querying of custom statistics aggregated via Reducers, expanding the scope to non-monoidal statistics warrants consideration, as the requirements for statistics displayed in the query table are less stringent than those mapped to visual aesthetics. More generic model for parametric interaction (which will be touched on in Section 9.2.2) would also be useful. Finally, there is wide a range of other, more ambitious features such as animation (time aesthetic) or semantic zooming, which could provide great utility in certain use-cases but which also present a substantial implementation overhead. Third, plot and figure customization in plotscaper is currently fairly limited. While users can adjust attributes such as the figure layout and plot scales, surface-level graphical attributes like colors, margins, and axis styling are not yet exposed. Although the support for adding these customization options does exist, their implementation was not prioritized. They may be added in future package versions, when the API stabilizes more. Fourth, as will be discussed in more depth in Section 6.3.0.2, while plotscaper provides decent performance even on moderately sized data sets (thousands or tens of thousands of data points), a particularly valuable feature for performance-sensitive applications would be the ability to register custom rendering backends. For example, GPU-based rendering could enable visualization of much larger datasets (to get some ideas of the scope, see e.g. Highsoft 2022; Lekschas and Manz 2024; Unwin et al. 2006). Conversely, having the ability to switch to an SVG-based rendering backend could also be beneficial in certain scenarios. Currently, the rendering logic in plotscaper is fairly tightly integrated with the rest of the system, however, decoupling this logic would definitely be a priority for a potential major rewrite. Fifth and finally, there are also many opportunities for additional features in the client-server communication. For instance, the ability to render arbitrary graphical elements (e.g. computed regression lines) within existing plotscaper plots or figures would be highly beneficial. Similarly, features such as dynamically switching Reducers or sending the underlying summary statistics to the server (similar to querying) warrant consideration. Furthermore, more fine-grained selection controls could also prove useful. mportantly, many of these features may be implementable relatively quickly, as the underlying infrastructure is already in place. 9.2.2 Declarative schemas As discussed in Section 7, one limitation of the delivered system is the absence of a simple declarative schema-based approach for specifying plots. While declarative schemas, popularized by the Grammar of Graphics (GoG, Wilkinson 2012), have become a highly popular in modern data visualization libraries (see e.g. Wickham 2016; Satyanarayan et al. 2016; Plotly Inc. 2023), my system deviates from this paradigm. Although certain core components within plotscape are modeled declaratively (as shown in Section 7.3.2.6.3), the overall plot definitions remain largely procedural, and the user-facing API (plotscaper) relies on nominal plot types3. However, as I argued in Section 7.2.2.3, this lack of a full declarative plot specification is not unique to my system. Instead, I contend that many currently available declarative data visualization libraries provide partial or incomplete solutions, and frequently conceal or obscure key implementation details (see also Wu and Chang 2024). For instance, operations such as grouping, binning, stacking, and normalization are often passed implicitly. Put simply, there are gaps in the GoG-based model. To quote Wu and Chang (2024): Despite these broad-ranging benefits, we observe that this [GoG-based] semantic delineation obscures the process of visual mapping in a way that makes it difficult to reason about visualizations and their relationships to user tasks. We observe that the core reason for this dissonance between visualization specifications and functions is that the Visual Mapping step represents two distinct substeps. The first involves additional transformations over the data tables in order to compute, e.g., desired statistics and spatially place marks that are specific to the visualization design. We term these Design-specific Transformations. The second is the visual encoding that maps each row in the transformed table to a mark and data attributes to mark attributes using simple scaling functions. During the course of my project, I have independently reached several conclusions which similar to those of Wu and Chang (2024)4. I did try to come up with a way of specifying declarative schemas for interactive graphics, however, despite some partial successes (see Section 7.3.2.6), ultimately, I was not able to come up with a comprehensive model. I chose to make this implementation gap explicit in plotscaper. However, I believe I have also been able to identify three key factors which contribute to the difficulty of developing declarative schemas for interactive data visualization, and these are detailed below. The first factor which complicates declarative schemas in interactive graphics is the weak correspondence between data variables and visual encodings. Specifically, as discussed in Section 7.2.2.3, often, what we plot are not variables found in the original data, but instead variables which have been computed or derived in some way. This is exists even in static graphics; however, it is further amplified in interactive graphics, where dynamic remapping of variables to aesthetics is often desirable (such as when transforming a barplot to a spineplot). Thus, directly mapping data variables to aesthetics seems to be an inadequate approach. However, to map derived variables to aesthetics, we have to explicitly specify what we compute and how. For example, to fully specify a histogram, we have to describe the fact that we want to bin cases based on some continuous variable, compute the counts within bins, stack these counts, also within bins, and finally map the bin borders to the x-axis variable and the counts to the y-axis variable. While I have been able to get reasonably far with providing a mechanism for specifying declarative schema for this process (see Section 7.2.2.3), ultimately, I was not able to integrate it with the rest of the system without some amount of procedural code. The second factor which presents a challenge to declarative schemas in interactive data visualization is the hierarchical nature of graphics itself (see Section 4.2.4). Specifically, while in static graphics, we can often act as if the data underlying our plots is “flat”, interactivity necessitates hierarchical data structures. Interactive features like linked selection and parametric manipulation trigger updates to summary statistics, requiring hierarchical organization for efficient updates, especially with features like stacking and normalization (see Sections 4.3.2.10 and 7.3.2.6). Furthermore, hierarchical data can also be leveraged to provide more efficient scale and axis updates (see Section 7.3.2.12.2), and display more information during querying (e.g., by displaying summary statistics for both objects and segments). However, specifying declarative schemas with hierarchical data is inherently more complex than with flat data, due to both increased surface area (multiple data sets) and hierarchical dependencies. In plotscape, these hierarchical dependencies are represented by aggregated variables with references to parent variables (and factors/reducers), which can be leveraged by specialized operators such as Reduced.stack and Reduced.normalize, see Section 7.3.2.6. An alternative, unexplored approach could be to partially “flatten” the hierarchical structure via SQL-like table joins (i.e. adding parent data as new columns with repeated values). However, with multiple levels of partitioning, this approach may become unwieldy5, and there are other considerations, such as the necessity for variables to “remember” how they have been aggregated (see Sections 4.3 and 7.3.2.6), and the reactive propagation of updates, which make completely flat data tables inadequate. The third and final factor which makes declarative schemas challenging is reactivity. Interactive visualizations need to, by definition, respond to user input. However, this input can impact various stages of the data visualization pipeline differently. For instance, while shrinking or growing the size of points in a scatterplot is a purely graphical computation, shrinking or growing the width of histogram bins requires recomputation of the underlying data. Consequently, the declarative schema should be able to handle reactive parameters which may have hierarchical dependencies. Signals (see Section 7.3.1.4) may offer a hypothetical general solution; however, as discussed in Section 7.3.1.5, my experience with developing plotscape revealed that reactivity typically tends to enter the visualization process at discrete points, corresponding to the four stages of the data visualization pipeline. While I did not manage to develop a general declarative mechanism for this, the following list outlines the identified hypothetical points of reactivity: Pre-partitioning: Data streaming, partitioning parameter updates (e.g. histogram bin width, selection) Pre-aggregation: Aggregation parameter updates (e.g. regression line regularization) Pre-scaling: Scale parameter updates (e.g. sorting, size/alpha adjustments) Pre-rendering: Surface-level changes (e.g. layout modifications, DOM resize events) To summarize, modeling interactive data visualizations declaratively presents significant challenges. Specifically, the weak correspondence between data variables and aesthetics, the inherent hierarchical nature of graphics, and the necessity for reactive updates make the seemingly appealing model of “assign variable \\(x\\) to aesthetic \\(y\\)” inadequate for capturing a wide range of popular interactive graphics. These issues are not unique to plotscaper 9.2.3 Performance A key aspect to discuss is the performance of the delivered software. As discussed in Section 3, responsiveness is crucial for interactive data visualization. Slow systems frustrate users, negating any potential benefits of sophisticated features. Given today’s expectation of highly responsive GUIs and the growing size of data sets, performance is an important concern. Despite not being the sole focus, I am happy to report that plotscaper achieves solid performance even on moderately sized data sets. Specifically, I was able to achieve highly responsive point-wise linked selection on data sets with tens of thousands of data points (such as the diamonds data set; see the Performance vignette on plotscaper’s package website). This performance is, of course, largely attributable to the highly optimized nature of JavaScript engines such as V8 rather than any targeted optimization. Nevertheless, I did try to be generally mindful of performance while developing the package, by adhering to data oriented practices such as relying on the Structure of Arrays (SoA) data layout. Profiling of the package revealed that the primary performance bottleneck was rendering. This manifests quite clearly even on the macro level: figures composed entirely of aggregate plots tend remain responsive even with fairly large data sets, whereas figures with multiple bijective plots (such as scatterplots or parallel coordinate plots) can start to become sluggish even with moderately-sized data sets (thousands or tens-of-thousands of data points). Therefore, alternative rendering strategies may offer significant performance gains. Currently, plotscaper relies on the default HTML5 canvas rendering context, which provides a simple interface for rendering 2D graphics. GPU-based rendering, particularly WebGL (“WebGL: 2D and 3D graphics for the web - Web APIs \\(\\vert\\) MDN” 2025), could lead to significant performance improvements. Beyond rendering, there are other parts of the system that may provide opportunities for easy performance wins. For instance, currently, as mentioned in Section 7.3.2.13.3, querying and selection both rely on a naive collision-detection loop, such that all objects are looped through until matches are found. An approach using spatial data structures, for example quadtrees (Samet 1988), could significantly accelerate these searches. Another area which may be open to performance improvements is reactivity. While reactivity is implemented using the - fairly performant - observer pattern, and event callbacks throttled on hot paths (such as mousemove events), further optimization of the reactive system may be possible. Finally, though less performance critical, client-server communication could also be made more performant. Currently, it is implemented with WebSockets (Cheng et al. 2024; MDN 2025) and JSON-based payloads, which incurs serialization/deserialization overhead on each message. An alternative protocol like TCP could mitigate this. References Alsallakh, Bilal, Luana Micallef, Wolfgang Aigner, Helwig Hauser, Silvia Miksch, and Peter Rodgers. 2014. “Visualizing Sets and Set-Typed Data: State-of-the-Art and Future Challenges.” Eurographics Conference on Visualization (EuroVis). Bartonicek, Adam, Simon Urbanek, and Paul Murrell. 2024. “No More, No Less Than Sum of Its Parts: Groups, Monoids, and the Algebra of Graphics, Statistics, and Interaction.” Journal of Computational and Graphical Statistics, 1–12. Batch, Andrea, and Niklas Elmqvist. 2017. “The Interactive Visualization Gap in Initial Exploratory Data Analysis.” IEEE Transactions on Visualization and Computer Graphics 24 (1): 278–87. Beckmann, Peter E. 1995. “On the Problem of Visualizing Point Distributions in High Dimensional Spaces.” Computers &amp; Graphics 19 (4): 617–29. Cheng, Joe, Winston Chang, Steve Reid, James Brown, Bob Trower, and Alexander Peslyak. 2024. Httpuv: HTTP and WebSocket Server Library. https://CRAN.R-project.org/package=httpuv. Cleveland, William S. 1985. The Elements of Graphing Data. Wadsworth Publ. Co. Fegaras, Leonidas. 2017. “An Algebra for Distributed Big Data Analytics.” Journal of Functional Programming 27: e27. Fong, Brendan, and David I Spivak. 2019. An Invitation to Applied Category Theory: Seven Sketches in Compositionality. Cambridge University Press. Gibbons, Jeremy, Fritz Henglein, Ralf Hinze, and Nicolas Wu. 2018. “Relational Algebra by Way of Adjunctions.” Proceedings of the ACM on Programming Languages 2 (ICFP): 1–28. Gordon Woodhull. 2025. “Crossfilter Gotchas \\(\\cdot\\) crossfilter/crossfilter Wiki.” https://github.com/crossfilter/crossfilter/wiki/Crossfilter-Gotchas. Hickey, Rich. 2011. “Simple Made Easy.” Strange Loop. https://www.youtube.com/watch?v=LKtk3HCgTa8. Highsoft. 2022. “Render Millions of Chart Points with the Boost Module Highcharts.” Highcharts. https://www.highcharts.com/blog/tutorials/highcharts-high-performance-boost-module. Hutchins, Matthew A. 1999. Modelling Visualisation Using Formal Algebra. Australian National University. Lekschas, Fritz, and Trevor Manz. 2024. “Jupyter Scatter: Interactive Exploration of Large-Scale Datasets.” arXiv Preprint arXiv:2406.14397. Lin, Jimmy. 2013. “Monoidify! Monoids as a Design Principle for Efficient Mapreduce Algorithms.” arXiv Preprint arXiv:1304.7544. MDN. 2025. “WebSocket - Web APIs \\(\\vert\\) MDN.” MDN Web Docs. https://developer.mozilla.org/en-US/docs/Web/API/WebSocket. Milewski, Bartosz. 2018. Category Theory for Programmers. Blurb. Parent, Sean. 2018. “Generic Programming.” Pacific++. https://www.youtube.com/watch?v=iwJpxWHuZQY&amp;t=4183s. Plotly Inc. 2023. “Plotly: Low-Code Data App Development.” https://plotly.com. Samet, Hanan. 1988. “An Overview of Quadtrees, Octrees, and Related Hierarchical Data Structures.” Theoretical Foundations of Computer Graphics and CAD, 51–68. Satyanarayan, Arvind, Dominik Moritz, Kanit Wongsuphasawat, and Jeffrey Heer. 2016. “Vega-Lite: A Grammar of Interactive Graphics.” IEEE Transactions on Visualization and Computer Graphics 23 (1): 341–50. Stepanov, Alexander A. 2013. “Efficient Programming with Components.” A9. Youtube. https://www.youtube.com/playlist?list=PLHxtyCq_WDLXryyw91lahwdtpZsmo4BGD. Stepanov, Alexander A, and Paul McJones. 2009. Elements of Programming. Addison-Wesley Professional. Theus, Martin. 2002. “Interactive Data Visualization using Mondrian.” J. Stat. Soft. 7 (November): 1–9. https://doi.org/10.18637/jss.v007.i11. Unwin, Antony, Martin Theus, Heike Hofmann, and Antony Unwin. 2006. “Interacting with Graphics.” Graphics of Large Datasets: Visualizing a Million, 73–101. Urbanek, Simon. 2011. “iPlots eXtreme: Next-Generation Interactive Graphics Design and Implementation of Modern Interactive Graphics.” Computational Statistics 26 (3): 381–93. Urbanek, Simon, and Martin Theus. 2003. “iPlots: High Interaction Graphics for r.” In Proceedings of the 3rd International Workshop on Distributed Statistical Computing. Citeseer. Vickers, Paul, Joe Faith, and Nick Rossiter. 2012. “Understanding Visualization: A Formal Approach Using Category Theory and Semiotics.” IEEE Transactions on Visualization and Computer Graphics 19 (6): 1048–61. “WebGL: 2D and 3D graphics for the web - Web APIs \\(\\vert\\) MDN.” 2025. MDN Web Docs. https://developer.mozilla.org/en-US/docs/Web/API/WebGL_API. Wickham, Hadley. 2016. Ggplot2: Elegant Graphics for Data Analysis (2e). Springer-Verlag New York. https://ggplot2.tidyverse.org. Wilhelm, Adalbert. 2008. “Linked Views for Visual Exploration.” In Handbook of Data Visualization, 200–214. Springer Science &amp; Business Media. Wilke, Claus O. 2019. Fundamentals of Data Visualization: A Primer on Making Informative and Compelling Figures. O’Reilly Media. Wilkinson, Leland. 2012. The Grammar of Graphics. Springer. Wills, Graham. 2008. “Linked Data Views.” In Handbook of Data Visualization, 217–41. ch. II. 9. Springer Berlin/Heidelberg, Germany. ———. 2011. Visualizing Time: Designing Graphical Representations for Statistical Data. Springer Science &amp; Business Media. Wu, Eugene. 2022. “View Composition Algebra for Ad Hoc Comparison.” IEEE Transactions on Visualization and Computer Graphics 28 (6): 2470–85. Wu, Eugene, and Remco Chang. 2024. “Design-Specific Transformations in Visualization.” arXiv Preprint arXiv:2407.06404. The number only includes downloads from the RStudio CRAN mirror.↩︎ As a short exercise, I tried going through ggplot2’s list of geoms and identifying all non-disjoint data representations. The only examples I have been able to find have been find were geoms based on two-dimensional kernel density estimates, i.e. geom_density_2d and geom_density_2d_filled (each line or polygon represents densities computed across all datapoints).↩︎ Currently there are six different types of plots implemented.↩︎ I became aware of Eugene Wu’s work only after he contacted me concerning the publication of a paper I co-authored during this project’s development: Bartonicek, Urbanek, and Murrell (2024)↩︎ I.e., the data would have to contain columns such value, parent_value, parent_parent_value, etc…↩︎ "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
