[["introduction.html", "2 Introduction 2.1 Brief history of interactive data visualization 2.2 What even is interactive data visualization? 2.3 The highlighting problem 2.4 Theory of data visualization systems", " 2 Introduction 2.1 Brief history of interactive data visualization Data visualization has a rich and intricate history, and a comprehensive treatment is beyond the scope of the present thesis. Nevertheless, in this section, I will provide a brief overview, with a particular focus on the later developments related to interactive visualization. For a more detailed historical account, readers should refer to Beniger and Robyn (1978), Dix and Ellis (1998), Friendly (2006), Friendly and Wainer (2021), or Young, Valero-Mora, and Friendly (2011). 2.1.1 Static data visualization: From ancient times to the space age The idea of graphically representing abstract information is very old. As one concrete example, a clay tablet recording a land survey during the Old Babylonian period (approximately 1900-1600 BCE) has recently been identified as the earliest visual depiction of the Pythagorean theorem (Mansfield 2020). Other examples of early abstract visualizations include maps of geographic regions and the night sky, and these were also the first to introduce the idea of coordinate systems (Beniger and Robyn 1978; Friendly and Wainer 2021). Figure 2.1: Photos of the tablet Si. 427 which has recently been identified as the earliest depiction of the Pythagorean theorem (Mansfield 2020). Left: the obverse of the tablet depicts a diagram of a field, inscribed with areas. Right: the reverse of the tablet contains a table of numbers, corresponding to the calculation of the areas. Source: Wikimedia Commons (Mansfield 2018). For a long time, coordinate systems remained tied to geography and maps. However, with the arrival of the early modern age, this was about to change. In the 16-17th century, the works of the 9th century algebraist Al-Khwarizmi percolated into Europe, and with them the idea of representing unknown quantities by variables (Kvasz 2006). This idea culminated with Descartes, who introduced the concept of visualizing algebraic relationships as objects in a 2D plane, forging a powerful link between Euclidean geometry and algebra (Friendly and Wainer 2021). Coordinate systems were thus freed of their connection to geography, and the x- and y-axes could now be used to represent an arbitrary “space” spanned by two variables. Descartes’ invention of drawing abstract relationships as objects in a 2D plane was initially only used to plot mathematical functions. However, it would not be long until people realized that observations of the real world could be visualized as well. A true pioneer in this arena was William Playfair, who popularized visualization as a way of presenting socioeconomic data and invented many types of plots still in use today, such as the barplot, lineplot, and pie chart (Friendly and Wainer 2021). Further, with the emergence of modern nation states in the 19th century, the collection of data and statistics (“things of the state,” Online Etymology Dictionary 2024) became widespread, leading to a “golden age” of statistical graphics (Beniger and Robyn 1978; Friendly and Wainer 2021; Young, Valero-Mora, and Friendly 2011). This period saw the emergence of other graphical lumnaries, such as Étienne-Jules Marey and Charles Joseph Minard (Friendly and Wainer 2021), as well as some ingenious examples of the use of statistical graphics to solve real-world problems, including John Snow’s investigation into the London cholera outbreak (Freedman 1999; Friendly and Wainer 2021) and Florence Nightingale’s reporting on the unsanitary treatment of wounded British soldiers during the Crimean War (Brasseur 2005), both of which lead to a great reduction of preventable deaths. Simultaneously, the field of mathematical statistics was also experiencing significant developments. Building upon the foundation laid by mathematical prodigies such as Jakob Bernoulli, Abraham de Moivre, Pierre Simon Laplace, and Carl Friedrich Gauss, early 19th century pioneers such as Adolph Quetelet and Francis Galton began developing statistical techniques for uncovering hidden trends in the newly unearthed treasure trove of socioeconomic data (Fienberg 1992; Freedman 1999). In the late 19th and early 20th century, these initial efforts were greatly advanced by the theoretical work of figures such as Karl Pearson, Ronald A. Fisher, Jerzy Neyman, and Harold Jeffreys, who established statistics as a discipline in its own right and facilitated its dissemination throughout many scientific fields (Fienberg 1992). As mathematical statistics gained prominence in the early 20th century, data visualization declined. Perceived as less rigorous than “serious” statistical analysis, it got relegated to an auxiliary position, ushering in “dark age” of statistical graphics (Friendly 2006; Young, Valero-Mora, and Friendly 2011). This development may have been partly driven by the early frequentist statisticians’ aspiration to establish statistics as a foundation for determining objective truths about the world and society, motivated by personal socio-political goals (see Clayton 2021). Be it as it may, while statistical graphics also did get popularized and entered the mainstream during this time, only a few interesting developments took place (Friendly and Wainer 2021). However, beginning in the late 1950’s, a series of developments took place which would restore the prominence of data visualization and make it more accessible than ever. Firstly, on the theoretical front, the work of certain academic heavy-weights greatly elevated data visualization and its prestige. Particularly, John Tukey (1962; 1977) fervently championed exploratory data analysis and placed data visualization in its centre. Around the same time, Jacques Bertin published his famous Sémiologie graphique (1967), which was one of the first works to attempt to lay out a comprehensive system of visual encodings and scales. Secondly, at the more applied level, the development of personal computers (see e.g. Abbate 1999) and high-level programming languages such as FORTRAN in 1954 (Backus 1978), made the process of rendering production-grade figures easier and more accessible than ever before. Combined, these developments fueled a surge in the use and dissemination of data visualizations. As the millennium drew to a close, several other important developments solidified the foundation of static data visualization. First, William Cleveland made significant contributions to the field, laying out many important principles for scientific data visualization (Cleveland 1985, 1993). Of note, his seminal study on the impact of the choice of visual encodings on statistical judgements remains widely cited today (Cleveland and McGill 1984). Similarly, Edward Tufte introduced essential principles for designing effective graphics, coining terms such as chartjunk and data-to-ink ratio (Tufte 2001). Finally, Leland Wilkinson’s groundbreaking Grammar of Graphics (2012) introduced a comprehensive system for designing charts based on simple algebraic rules, influencing nearly every subsequent software package and research endeavor in the field of visualization. 2.1.2 Early interactive data visualization: By statisticians for statisticians With the boom of static data visualization in the 1950’s, interactive data visualization would not be left far behind. It started with tools designed for niche, specialized tasks. For example, Fowlkes (1969) designed a system which allowed the users to view probability plots under different configurations of parameters and transformations, whereas Kruskal (1965) created a tool for visualizing multidimensional scaling. However, soon, researchers soon recognized the potential of interactive data visualization as a general-purpose tool for exploring data. The first such general-purpose system was PRIM-9 (Fisherkeller, Friedman, and Tukey 1974). PRIM-9 allowed for exploration of multivariate data via interactive features such as projection, rotation, masking, and filtering. Following PRIM-9, the late 1980’s saw the emergence of a new generation of systems which provided an even wider range of capabilities. Tools like MacSpin (Donoho, Donoho, and Gasko 1988), Data Desk (Velleman and Paul 1989), LISP-Stat (Tierney 1990), and XGobi (Swayne, Cook, and Buja 1998) introduced features such as interactive scaling, rotation, linked views, and grand tours (for a glimpse into these systems, excellent video-documentaries are available at ASA Statistical Graphics Video Library). The proliferation of open-source, general-purpose statistical computing software such as S and R further democratized the access to interactive data visualization tools. Building on XGobi’s foundation, GGobi (Swayne et al. 2003), expanded upon on XGobi and provided an integration layer for R. Other tools like Mondrian (Theus 2002) introduced sophisticated linked interaction between many different types of plots including scatteplots, histograms, barplots, scatterplot, mosaic plots, parallel coordinates plots, and maps. Additionally, iPlots (Urbanek and Theus 2003) implemented a general framework for interactive plotting in R, allowing not only for one-shot rendering interactive figures from R but also for direct programmatic manipulation. This package was later expanded expanded for big data capabilities in iPlots eXtreme (Urbanek 2011). A common thread among these interactive data visualization systems is that they were designed by statisticians with primary focus on data exploration. High-level analytic features such as linked views, rotation/projection, and interactive manipulation of model parameters made frequent appearance. While these features were powerful, they also contributed to a steeper learning curve, potentially limiting adoption by users without a strong data analytic background. Additionally, these tools often had fairly limited options for customization, making them less well suited for data presentation. 2.1.3 Interactive data visualization and the web: World-wide interactivity The end of the millennium marked the arrival of a new class of technologies which impacted interactive data visualization just as much as almost every other field of human endeavor. The rise of the internet in the mid 1990’s made it possible to create interactive applications that could be accessed by anyone, from anywhere. This was aided by the dissemination of robust and standardized web browsers, as well as the development of JavaScript as a high-level programming language for the web (for a tour of the history, see Wirfs-Brock and Eich 2020). Soon, interactive visualizations became just one of many emerging technologies within the burgeoning web ecosystem. Early web-based interactive data visualization systems tended to rely on external plugins. Examples of these include Prefuse (Heer, Card, and Landay 2005) and Flare (developed around 2008, Blokt 2020), which leveraged the Java runtime and Adobe Flash Player, respectively. However, as browser technologies advanced, particularly as JavaScript’s performance improved thanks to advances in just-in-time compilation (JIT, see e.g. Clark 2017; Dao 2020), it became possible to create complex interactive experiences directly in the browser. This led to the emergence of several popular web-native interactive data visualization systems in the early 2010s, many of which remain widely used today. D3.js (Bostock 2022) is one of the oldest and most influential web-based visualization systems still in use today. As a general, low-level framework for visualizing data, D3 provides of a suite of specialized JavaScript modules for various aspects of the data visualization workflow, including data parsing, transformation, scaling, and DOM interaction. While D3 does provide methods for handling interactive events, it does not itself provide a system for dispatching and coordinating these events - it instead delegates this responsibility to the user and encourages the use of reactive Web frameworks such as React (Meta 2024), Vue (Evan You and the Vue Core Team 2024), or Svelte (Rich Harris and the Svelte Core Team 2024). Finally, D3.js visualizations are rendered as Scalable Vector Graphics (SVG) by default, ensuring lossless scaling but impacting performance at high data volumes. While various unofficial alternative rendering engines, based on the HTML 5 Canvas element or WebGL, do exist, as of this date, no such official libraries exist as of this date. Building upon the low-level infrastructure that D3 provides, many packages such as plotly.js (Plotly Inc. 2022) and Highcharts (Highsoft 2024) provide high-level abstractions which make the process of building complex interactive figures more streamlined for the average user. The difference between these systems and D3 is that, while D3 provides low-level utilities such as data transformations, scales, and geometric objects, these packages provide functions for rendering complete plots and registering reactive events, which are under the hood automatically handled via systems based on the native DOM Event Target interface (MDN 2024). Like D3, both plotly.js and Highcharts also render the graphics in SVG by default, however, unlike D3, they both also provide alternative rendering engines based on WebGL (Highsoft 2022; Plotly Inc. 2024). Vega (Satyanarayan et al. 2015; Vega Project 2024b) is another popular package, which, despite also being built partially upon the foundation of D3, takes a different approach. It provides a declarative framework for defining (interactive) data visualizations using a static JSON schema. Compared to plotly.js and Highcharts, Vega offers significantly more granular customization of graphics and interactive behavior, making it significantly more expressive but also more verbose. For example, specifying a scatterplot matrix with linked selection in Vega requires over 300 lines of JSON, not including the data and using default formatting (Vega Project 2024a). In general, these contemporary web-based interactive data visualization systems offer a great deal of flexibility and customizability, making the well suited for modern data presentation. However, all of this expressiveness does come at a cost. Compared to the earlier statistical graphics systems, described in Section 2.1.2, many of the more advanced features that used to be common are now either missing or require so much effort to implement that they are only accessible to power-users, as evidenced by their absence in the documentation and gallery pages of the corresponding packages. For instance, the R Graph Gallery entry on Interactive Charts (Holtz 2022) features multiple interactive figures implemented in the above-mentioned JavaScript libraries, however, they all feature only surface-level single-plot interactive features such zooming, panning, hovering, 3D rotation, and node repositioning. The Plotly Dash documentation page on Interactive Visualizations (Plotly Inc. 2022) does feature two examples of simple linked cross-filtering, however, the vast majority of visualizations in the Plotly R Open Source Graphing Library documentation page (Plotly Inc. 2022) show examples only surface-level interactivity. Similarly, VegaLite Gallery pages on Interactive Charts and Interactive Multiview Displays (Vega Project 2022) feature many examples, however, there are only few, limited examples of linked or parametric interactivity. Finally, the Highcharter Showcase Page (Kunst 2022) does not feature any examples of linking. Of course, it is still possible to implement advanced features such as complex linked views and parametric interaction in these web-based visualization frameworks, however, it often requires a) writing a lot of code, or b) stepping outside of the visualization library to make use of the more general features provided by the reactive framework or JavaScript. This creates a barrier to entry for taking advantage of these more interesting types of interactivity. This may not be an issue for large organizations which can afford to hire specialists to work on visualizations full-time. However, to the average scientist or data analyst, the upfront cost of producing interactive visualizations may be too high, especially if one is only interested in exploratory data analysis. This may be the reason why interactive visualizations are nowadays mainly used for data communication, not data exploration (Batch and Elmqvist 2017). 2.2 What even is interactive data visualization? If it looks like a duck, swims like a duck, and quacks like a duck, then it probably is a duck. […] The irony is that while the phrase is often cited as proof of abductive reasoning, it is not proof, as the mechanical duck is still not a living duck Duck Test entry, (Wikipedia 2022) While giving a brief overview of the history and the present state of interactive data visualization in the previous section, I skirted around one important: what even is interactive data visualization? Surprisingly, despite the widespread popularity of interactive visualizations, there is no clear consensus for what makes a figure interactive. Within the data visualization literature, the terms “interactive” and “interaction” are used inconsistently, with researchers providing incongruent and at times even contradictory definitions (see e.g. Dimara and Perin 2019; Elmqvist et al. 2011; Pike et al. 2009). The lack of a clear consensus complicates discussion of interactive data visualization. Ignoring the issue could risk leaving the reader confused, while a comprehensive exploration of the terminology could become overly complex, as evidenced by the dearth of research papers dedicated to the topic (see e.g. Dimara and Perin 2019; Elmqvist et al. 2011). To address this issue, this section aims to provide a concise yet informative account of how interactivity has been conceptualized in the literature. The goal is to establish a clear framework for understanding the terms “interactive” and “interaction” within the context of this thesis. 2.2.1 Interactive vs. interacting with First, the word “visualization” in the term “interactive data visualization” can be interpreted in two different ways: Noun, as in interactive data visualization is a concrete chart or figure Verb, as in interactive data visualization is the process of interacting with a figure Data visualization literature frequently features both uses of the term, leading to significant overloading (Dimara and Perin 2019; Pike et al. 2009; see also Yi et al. 2007). Further, this dual interpretation has lead to a kind of a split in the literature. Some researchers focus on the mathematical and computational aspects of interactive data visualization, discussing specific systems and implementations (see e.g. Buja, Cook, and Swayne 1996; Kelleher and Levkowitz 2015; Leman et al. 2013; Wills 2008). Others prioritize the more cognitive or human-computer interaction (HCI) aspects of interactive data visualization, exploring what impact different kinds of visualization and interaction styles have on the user’s ability to derive insights from the data (see e.g. Dimara and Perin 2019; Dix and Ellis 1998; Pike et al. 2009; Quadri and Rosen 2021; Yi et al. 2007). There is of course a significant overlap - most papers discuss both concrete implementations of interactive data visualization systems and the user’s intentions and experiences while using those systems. However, the dual intepretation of “interactive data visualization” does complicate literature search. It also highlights the interdisciplinary nature of the field, showing its connections to statistics, computer science, applied mathematics, business analytics, HCI, and cognitive psychology(Dimara and Perin 2019). While this interdisciplinary nature of interactive data visualization is certainly a strength, it can also lead to confusion, and as such I think it is necessary to clearly define key terms. To ensure clarity throughout thesis, the term “interactive data visualization” will primarily refer to concrete charts or figures. When referring to the practice of interactive data visualization, I will attempt to use more active phrasing such as “interacting with a visualization” or “user’s interaction with a visualization”, to indicate that what is being referred to is the activity or process of visualization, rather than any concrete object or implementation. 2.2.2 What is “interactive enough”? Even when we use the term “interactive data visualization” to refer to concrete charts or figures, the meaning still remains fairly ambiguous. What is the bar for calling a figure “interactive”? What features should interactive figures have? These criteria vary a lot between data visualization researchers, such that the same figure may be considered interactive by some but not by others. This is important, since the criteria may impact the requirements and implementation details of interactive data visualization systems. Some researchers adopt a broad definition of interactive data visualization, considering almost any figure combined with graphical user interface (GUI) as interactive, as long as it allows for some level of user manipulation (Brodbeck, Mazza, and Lalanne 2009). For others, the speed of the computer’s responses to user input is important, with faster updates translating to greater interactivity (Becker and Cleveland 1987; Buja, Cook, and Swayne 1996). Some also differentiate between “interactive” and “dynamic” manipulation, such that interactive manipulation involves discrete actions such as pressing a button or selecting an item from a drop-down menu, whereas dynamic manipulation involves continuous actions, like moving a slider or clicking-and-dragging to highlight a rectangular area (Rheingans 2002; Jankun-Kelly, Ma, and Gertz 2007; see also Dimara and Perin 2019). However, many other researchers ascribe to a much narrower view of interactive data visualizations, which hinges on high-level analytic features that allow efficient exploration of the data. These features include the ability to generate different views of the data (by e.g. zooming, panning, sorting, and filtering), and the reactive propagation of changes between connected or “linked” parts of a figure (Kehrer et al. 2012; Buja, Cook, and Swayne 1996; Keim 2002; Unwin 1999; Chen, Härdle, and Unwin 2008). An often cited guideline is the visual information seeking mantra: overview first, zoom and filter, then details-on-demand (Shneiderman 2003). Similarly, in visual analytics research, a distinction is made between “surface-level” (or “low-level”) and “parametric” (or “high-level”) interactions, where surface-level interactions manipulate attributes of the visual domain only (e.g. zooming and panning), whereas parametric interactions manipulate attributes of mathematical models or algorithms underlying the visualization (Leman et al. 2013; Pike et al. 2009). Table 2.1: Table 2.2: Summary of the perspectives on interactivity Name Details Selected references User interaction The user can interactively manipulate the figure in some way Brodbeck, Mazza, and Lalanne (2009) Real-time updates The user’s interactions propagate into the visualization with little to no lag Becker and Cleveland (1987), Buja, Cook, and Swayne (1996), Jankun-Kelly, Ma, and Gertz (2007), and Rheingans (2002) Plot- and data-space manipulation The user can interactively explore different parts of the data set by doing actions which effectively amount to “subsetting” rows of the data (e.g. zooming, panning, and filtering) Buja, Cook, and Swayne (1996), Keim (2002), Shneiderman (2003), and Unwin (1999) Linked views The visualization consists of connected or “linked” parts and the user’s interactions with one part propagate to the other parts (e.g. linked highlighting) Buja, Cook, and Swayne (1996), Keim (2002), Kehrer et al. (2012), Unwin (1999), Theus (2008), Wilhelm (2008), Wills (2008) Parametric updates The user can manipulate the parameters of some underlying mathematical model or algorithm (e.g. histogram bins, grand tour projections, etc…) Leman et al. (2013), Pike et al. (2009) Table 2.1 provides a concise summary of the several perspectives on interactivity discussed above. It meant to serve as a reference point for future discussions within the text, though it is important to note that this is not an exhaustive list. For a more comprehensive taxonomy of interactive visualization systems and features, see e.g. Dimara and Perin (2019), Yi et al. (2007). 2.2.3 Complexity of interactive features The way we define interactivity has an impact on implementation requirements. To start with a perhaps slightly over-exaggerated example, many programming languages come equipped with a read-evaluate-print loop (REPL) which can be used to interactively execute code from the command line. The user writes code, presses ENTER, and the language interpreter evaluates the code, returns any output, and waits for more input from the user. Now, if the language in question supports plotting, then, under the permissive “user interaction” definition, it could be argued that even the act of running code from a command line to produce new plots could be considered an “interactive data visualization system”, since the user’s interaction with the REPL produces changes to the visual output. And, hypothetically, if the user could type fast enough, they would see the updates appear almost instantly, satisfying the “real-time update” definition. Does this mean that every programming language which has a REPL and supports plotting automatically ships with an interactive data visualization system? I would argue that no: most people nowadays probably do not consider the command line to be an interactive data visualization system. But perhaps it has not always been this way. Several decades ago, the command used to be considered a prime example of an interactive user interface (see e.g. Foley 1990; Howard and MacEachren 1995). Compared to waiting seconds or minutes for code to compile, a REPL is indeed a much more interactive experience. However, with the rise in processor speed and the proliferation of highly interactive graphical user interfaces (GUIs), users have come to expect visualizations that can be interacted with directly (Dimara and Perin 2019). As such, our perceptions of what is “interactive” are not constant but change over time; as technologies improve, we come to expect more direct and responsive user interfaces. Now, let’s set the somewhat exaggerated example of the REPL aside, and focus on what today would be considered more “typical” examples interactive data visualization systems. That is, systems in which the user can interact with the visualizations directly, by pressing keys or mouse buttons. Then, there still are considerable differences in what different features imply for implementation requirements. There are features which manipulate visual attributes of the plot only, independent of the data. These include, for example, changing the size, color, or opacity of points in a scatterplot. Features like this are usually fairly simple to implement because they do not affect the underlying data representation: a point displays the same data (as indicated by its xy-coordinates) no matter whether it is green or orange. Also, these graphical-only features typically do not require specialized data structures, and have low time- and space-complexity: for example, when interactively changing the opacity of points in a scatterplot, we only need to update one scalar value - the points’ opacity - and as such most of the user-experienced time will be spent re-rendering, rather than on any computation. In contrast, some interactive features require specialized data structures and complex algorithms, above and beyond those that are required for static plots. For instance, each time the user engages in interactive features such as filtering, linked highlighting, or parametric interaction, new summaries of the underlying data may need to be computed. When a user selects several points in a linked scatterplot, we first have to find the ids of all the corresponding cases, recompute the statistics underlying all other linked plots (such as counts/sums in barplots or histograms), train all of the relevant scales, and only then can we re-render the plot. Likewise, if we interactively manipulate a histogram’s binwidth, we need to recompute the number of cases in each bin each time the binwidth changes. To maintain the illusion of smooth, “continuous” interaction (Dimara and Perin 2019), these computations need to happen fast, and as such, computational efficiency becomes imperative. 2.2.4 Working definition As was discussed in previous sections, the definition “interactive data visualization” varies across fields and researchers. Moreover, when building an interactive data visualization system, this distinction matters, since different interactive features inherently come with different levels of complexity. Thus, how should we go about deciding what to consider “interactive” for our purposes? Data visualization can be broadly categorized into two primary modes: presentation and exploration. While both modes share a bulk of common techniques, each comes with a different set of goals and challenges (Kosara 2016). Data presentation starts from the assumption that we have derived most of the important insights from our data already, and the goal is now to communicate these insights clearly and make an impactful and lasting impression (Kosara 2016). In contrast, data exploration begins from a position of incomplete knowledge - we accept that there are facts about our data we might not be aware of yet. Thus, when we explore data with visualizations, the goal is to help us see what we might otherwise miss or might not even think to look for (Tukey et al. 1977; Unwin 2018). However, it is not always the case that more complex visuals necessarily translate to better statistical insights. In static visualization, it is a well-established fact that plots can include sophisticated-looking and seemingly appealing features which do not promote the acquisition of statistical insights in any way (Cairo 2014, 2019; Gelman and Unwin 2013; Tufte 2001). Similarly, adding interactivity to a visualization does not always improve its statistical legibility (see e.g. Abukhodair et al. 2013; Franconeri et al. 2021). I propose to approach interactive features the same way we treat visual features in static visualization. Specifically, I propose the following working definition: To justify being called an “interactive data visualization”, the interactive features in a visualization should promote statistical understanding. If we accept this proposition, then there are several important consequences that follow. First, we must favour high-level, data-dependent, parametric interactions over the purely graphical ones. That is not to say that purely graphical interactive features are not useful. For example, in the presence of overplotting, manipulating size or alpha of objects can help us features (areas of high density) that would otherwise remain hidden. Likewise, zooming and panning, while often being counted among the more high-level features, require manipulation of existing axis limits only and can be done without reference to the original data. Still, I argue that the ability to see new summaries of the data is what makes some interactive data visualizations systems ultimately more powerful (and also more challenging to implement). The interactive features that enable this, such as filtering, linked highlighting, and parameter manipulation, go beyond aesthetics, and empower the users to explore the data dynamically, uncovering hidden patterns and relationships that may otherwise remain hidden. 2.2.5 Common interactive features This section describes several common types of interactive features that tend to make frequent appearance across interactive data visualization systems. It is only meant as an overview (for comprehensive taxonomies of interactive features, see Dimara and Perin 2019; Yi et al. 2007). For each feature, I highlight its properties, common uses, and implementation requirements. 2.2.5.1 Zooming and panning Zooming and panning are two fundamental interactive features, often used in tandem. Because of their association, and the fact that they both involve interactive manipulation of scale limits, I discuss them here simultaneously, in a single subsection. Zooming, depicted in Figure 2.2, allows the user to magnify a specific region of a single plot. Typically, this is done creating a rectangular selection and the plot scales are then automatically adjusted to match this region. Zooming allows the user to get a better sense of the trend within the magnified region, and discover patterns that may be otherwise obscured due to overplotting or improper aspect ratio (see e.g. Buja, Cook, and Swayne 1996; Unwin 1999; Theus 2008). Figure 2.2: Zooming involves shrinking the axis limits to obtain a more detailed view of the data. Typically, the user selects a rectangular region of the plot (left) and the plot scales are then adjusted so that the region fills up the entire plot area (right). Notice the change in the axis limits. However, after zooming into a region, it is often helpful retain the ability to traverse the wider plot area, while maintaining the same level of zoom and aspect ratio. This is what panning is for. By performing an action like right-clicking and dragging, the user can shift the focus of the zoomed in region around the plot. Figure 2.3: Panning involves moving the axis limits while retaining the same zoom level and axis ratio. In the figure above, we pan by moving the coordinates to the bottom right (increasing the weight limits and decreasing the mileage limits, respectively) to move to a different region of the plot. Since these features can be implemented with scales only, implementing zooming and panning might seem relatively straightforward, however, even here, there are few interesting problems to consider. First, whereas continuous axes can be zoomed and/or panned by modifying the axis limits directly, discrete axes require a bit more thought. Second, with nested zooming, maintaining a reversible history of previous states is essential (Unwin 1999). Third, at times, it can be useful to link scale updates across multiple plots, such that, for example, zooming or panning a plot in a scatterplot matrix produces the same updates in other plots with the same variables on one of the axes. Finally, an advanced feature that can be also quite useful when combined with hierarchical data such as geographic information is logical or semantic zooming (Keim 2002; Unwin 1999; Yi et al. 2007). In logical zooming, magnification does not only increase the size of the zoomed-in objects, but also the level of detail. Clearly, this makes it a more complex feature than general zooming involving scales. 2.2.5.2 Querying Querying is another popular interactive feature that is usually fairly simple to implement. As shown in Figure [REFERENCE], the way querying is typically implemented is that when a user mouses over a particular geometric object, a tooltip or a small table is displayed, showing values corresponding to the underlying data point(s) (Urbanek and Theus 2003). This makes it possible to look up precise values that would otherwise be available only approximately via the visual representation. Querying is useful because it allows us to combine the best features of graphics and tables. Specifically, it allows us to move past Tukey’s dichotomy: “graphics are for the qualitative/descriptive […] never for the carefully quantitative (tables do that better)” and “graphics are for comparison […] not for access to individual amounts” (Tukey 1993). Additionally, querying can also allow us to display more information than would be otherwise available through visual encodings alone, particularly when values corresponding to individual data points are of interest (such as when identifying outliers). 2.3 The highlighting problem As was discussed in the previous section, linked selection is one of the most highly ranked interactive features in interactive data visualization. It allows us to mark specific cases in one plot, and see the corresponding summary statistics in all the other plots. In this way, it allows us to quickly explore different dynamically-generated subsets of our data, within the context of the whole data set. 2.3.1 Linked selection and stacking When we engage in linked selection, we want to highlight parts of objects corresponding to the selected cases. Thus, fundamentally, we need to break each object into parts. We then need some way of representing those parts, in a way that visually preserves the hierarchical nature of the relationship (it needs to be clear that the parts are still parts of the whole object). In data visualization, there are three common methods for dealing with objects that have been split into parts: stacking, dodging, and layering. Let’s briefly illustrate these on the example of the barplot. We start with the whole bars and then break each bar into multiple segments based on the levels of another variable (such as selection status). Now, what we do with these segments will differ based on the technique we use. When stacking, we plot the bar segments vertically on top of each other. When dodging, we plot the bars side-by-side, as “clusters”. Finally, when layering, we plot bar segments in separate graphical layers and use partial transparency to mitigate overplotting. Figure 2.4: Examples of the three methods for dealing with objects that have been split into parts: stacking, dodging, and layering. Much has been written about the relative merits of stacking, dodging, and layering. For example, layering is only useful with few categories, as blending many colors can make it difficult to tell the categories apart (Franconeri et al. 2021; Wilke 2019). Further, in a landmark study, Cleveland and McGill (1984) showed that people tend to be less accurate when reading information from stacked bar charts as opposed to dodged bar charts. Specifically, since the lower y-axis coordinate of a stacked segment is pushed up by the cumulative height of the segments below, it becomes difficult to accurately compare segments’ length, both within and across bars (Cleveland and McGill 1984). Subsequent research has independently validated these findings and expanded upon them (see e.g. Heer and Bostock 2010; Thudt et al. 2016; Quadri and Rosen 2021). Due to this suboptimal statistical legibility, many data visualization researchers have urged caution about stacking (see e.g. Byron and Wattenberg 2008; Cairo 2014; Franconeri et al. 2021), and some have even discouraged its use altogether (Kosara 2016; Wilke 2019). However, much of this research has been done with on static visualizations. I argue that, in interactive data visualization, there are additional constraints that affect the calculus of which method is the best. First, if we want to support the ability to interactively manipulate the alpha channel and do linked selection with multiple (3+) selection groups, we can effectively eliminate layering as an option. Having two different sources of alpha channel (layering and user input) would make the interaction confusing and limit its range (e.g. if we use 75% alpha to do layering, then the effective range of values the user can manipulate is 0-75%). Further, with multiple selection groups, it would become hard to tell the selection status apart. It is much better to keep the two interactive features (selection and alpha manipulation) orthogonal and use a separate visual attribute (color and transparency) for each. Thus, the choice is between stacking and dodging. While, as was discussed above, dodging is the preferred choice in static data visualization, I propose that First, I propose that stacking is the superior method for displaying selection. Thanks to the four Gestalt principles of proximity, similarity, closure, and common region, in a stacked barplot, each bar presents itself as a single visual entity. In other words, since the stacked segments are placed right on top of each other, and share width and a closed border, they are perceived as part of a unified whole (the bar). This remains true throughout selection - no matter how the heights of the highlighted segments change, the height of the whole stacked bar remains constant, and so does the overall outline of the plot. To address the highlighting problem, we need to first discuss some key mathematical concepts. 2.4 Theory of data visualization systems 2.4.1 Scales Every data visualization system needs some way of translating abstract data values into concrete graphical attributes such as position, size, or colour. Given the ubiquitous need for scales, one might expect them to be a “solved issue”, within the relevant literature. However, this is far from the truth. Specifically, the issues of scales and measurement are still being grappled with in the areas of mathematics and philosophy of science to this day (for a gentle yet thorough introduction, see Tal 2015). Scales are another area of data visualization in which there has been considerable debate, with many terms being overloaded and relating to concepts from different fields. This is due to the fact that the issue of how to compare, rank, and translate values has a long and complicated history. In particular, the issue of measurement has been hotly debated in the field of psychometrics and mathematical psychology, leading to the development of the theory of measurement (which has some overlap with, but is not the same as, measurement theory in mathematics). One paper that has been key to the debate around scales and measurement has been the seminal work of Stevens (1946). In this paper, Stevens defined a scale as a method of assigning numbers to values, allowing for various kinds of comparisons. Further, by considering transformations which preserve the comparisons, Stevens identified 4 types of scales: nominal, ordinal, interval, and ratio (see also Michell 1986; Velleman and Wilkinson 1993). Table 2.3: Types of scales identified by Stevens (1946) Scale Structure Comparison Valid transformations Nominal Equivalence relation Are \\(x\\) and \\(y\\) the same? \\(x&#39; = f(x)\\), where \\(f\\) is a bijection Ordinal Total order Is \\(x\\) is greater than \\(y\\)? \\(x&#39; = f(x)\\), where \\(f\\) is a monotonic bijection Interval Lebesque measure How far is \\(x\\) from \\(y\\)? \\(x&#39; = ax + b\\), for \\(a, b\\) real Ratio How many times is \\(x\\) greater than \\(y\\)? \\(x&#39; = ax\\), for \\(a\\) real Table 2.3 shows a loose reproduction of Table 1 from Stevens (1946). Note that the family of valid transformations gets smaller in each row, meaning that the scales carry more information (Velleman and Wilkinson 1993). Let’s discuss the scales individually. 2.4.1.0.1 Nominal scales Nominal scales correspond to equivalence relations. An equivalence relation is a binary relation \\(\\sim\\) on some set \\(X\\) which, for all \\(x, y, z \\in X\\), has the following properties: Reflexivity: \\(x \\sim x\\) Symmetry: \\(x \\sim y \\text{ if and only if } y \\sim x\\) Transitivity: \\(x \\sim y \\text{ and } y \\sim z \\text{ then } x \\sim z\\) Intuitively, we can think of the numbers on a nominal scale as “labels”. Thus, the only question which we can ask a nominal scale is whether two labels are the same or different. Examples of variables with nominal scale include variables of which we typically think of as categorical, such as color, species, or political party. It does not make sense to say “blue is more than green” or “cat is more than dog” without specifying some other axis of comparison. It does make sense, however, to say “Daisy and Molly are the same species of animal (cat)” or “these two glasses are of different colors”. For nominal scales, any permutation is a valid transformation (Stevens 1946). For example, if we use the numbers \\(\\{ 1, 2, 3 \\}\\) to represent the species \\(S = \\{ \\text{cat}, \\text{dog}, \\text{hamster} \\}\\), respectively, we can re-assign the numbers in any order we want and the properties of the scale are preserved. It is arguable whether any nominal quantities exist in and of themselves or whether they only ever exists as abstract social constructions over underlying continuous reality. Color is a discretization of the visible light spectrum (frequency of electromagnetic radiation), and the pre-Darwinian concept of a species is likewise an abstraction over continuously varying distribution of genes (although there have been some attempts to ground the definition of a discrete species in the theory of genetics, e.g. as a population of individuals which can produce viable offsprings, see Mayr 1999). Further, even many subjective concepts which are typically described as discrete such as emotions may be abstractions over underlying continuous phenomena (Barrett 2013). However, even if nominal quantities are entirely socially constructed, this does not mean they are arbitrary or useless. SEARLE 2.4.1.0.2 Ordinal scales Ordinal scales correspond to total orders. A total order is a relation \\(\\leq\\) on \\(X\\) which, for all \\(x, y, z \\in X\\), has the following properties: Reflexivity: \\(x \\leq x\\) Antisymmetry: \\(\\text{if } x \\leq y \\leq x \\text{ then } x = y\\) Transitivity: \\(x \\leq y \\text{ and } y \\leq z \\text{ then } x \\leq z\\) Totality or comparability or strong connectedness: \\(\\text{for all } x, y, \\text{ either } x \\leq y \\text{ or } y \\leq x\\) Examples of total orders include the usual ordering \\(\\leq\\) on natural numbers \\(\\mathbb{N}\\): \\(1 \\leq 2 \\leq 3 \\leq \\ldots\\) or the alphabetical order on letters: \\(A \\leq B \\leq C \\ldots \\leq Z\\). As total orders, ordinal scales allow us to rank quantities. A good example of an ordinal variable is placement in a race or competition. If Emma and Charlotte ran a marathon, and Emma placed 2nd and Charlotte 3rd, we can say that Charlotte ran finished the race earlier than Emma. However, we do not know whether she crossed the finish line 15 minutes or 2 hours earlier, or whether or not her average pace was less than half of that of Emma. Some authors have related ordinal scales to weak orders (see Michell 1986). Weak orders (also known as total preorders, see nLab 2024a) generalize total orders by allowing for ties (properties 2. and 4. above do not need hold). While this seems like a useful property, I opted to relate ordinal scales to total orders here instead, since there is currently ambuiguity in the way the term weak order is used in the literature (see e.g. nLab 2024b, 2024c; Abrams 2024), and, for practical data analysis, the distinction is fairly inconsequential. For instance, in the marathon example above, if Emma and Charlotte both placed second, after Lucy and before Lily, we could frame the outcome of the race as the following weak order on the set \\(M\\) of marathoners: \\(\\text{Lucy} \\leq \\text{Emma, Charlotte} \\leq \\text{Lily} \\leq ...\\). However, the underlying set of ranks \\(R \\subset \\mathbb{N}\\) still retains a total ordering: \\(1 \\leq 2 \\leq 3 \\leq \\ldots\\) and we can specify a surjective monotonically increasing function \\(r: M \\to R\\) which maps each marathoner to her rank. Clearly, we can map any weak order to a total order by applying a functor which enforces anti-symmetry in this way (Fong and Spivak 2019; nLab 2024a). The only transformations which are permissible for ordinal scales are those which preserve order, that is, monotonic increasing transformations (Stevens 1946; Michell 1986). For example, transforming our set of ranks \\(R\\) by taking the log or square root of each rank leaves the order relations between them unchanged. 2.4.1.0.3 Interval scales Interval scales. Interval scales allow us to calculate a distance between two points. However, they do not have a natural “zero point” or intercept. As such we cannot use them to determine the ratio between two quantities. Examples of interval scales include the calendar date and geographical position. It does not make sense to say that the year 1000 CE is “twice as much” as 500 CE, since the birth of Jesus Christ is (religious beliefs aside) an arbitrary zero point: we could set 0 CE at any other point in time, such as the founding of Athens or the release of Taylor Swift’s first album, and all of the properties we care about when tracking historical time would be preserved. Likewise, it does not make sense to say that 90° longitude is “three times” that of 30° longitude: the location of the prime meridian is also the product of arbitrary historical cirumstances. 2.4.1.0.3.1 Ratio scales Unlike interval scales, ratio scale have a well-defined natural zero point. For example, 2.4.1.0.4 Criticism of On the Theory of Scales of Measurement In the original paper, Stevens had also made the claim that the type of scale determined which statistical tests and summaries were “permissible” for the data. For example, according to Stevens, while mean is an appropriate summary of an interval scale (since expectation is linear), it would not be a permissible summary of ordinal data. This claim was later disputed by researchers References Abbate, J. 1999. “Getting small: a short history of the personal computer.” Proc. IEEE 87 (9): 1695–98. https://doi.org/10.1109/5.784256. Abrams, Dave. 2024. “Total Weak Order Vs Total Order.” Mathematics Stack Exchange. https://math.stackexchange.com/questions/3793222/total-weak-order-vs-total-order. Abukhodair, Felwa A, Bernhard E Riecke, Halil I Erhan, and Chris D Shaw. 2013. “Does Interactive Animation Control Improve Exploratory Data Analysis of Animated Trend Visualization?” In Visualization and Data Analysis 2013, 8654:211–23. SPIE. Backus, John. 1978. “The History of Fortran i, II, and III.” ACM Sigplan Notices 13 (8): 165–80. Barrett, Lisa Feldman. 2013. “Psychological Construction: The Darwinian Approach to the Science of Emotion.” Emotion Review 5 (4): 379–89. Batch, Andrea, and Niklas Elmqvist. 2017. “The Interactive Visualization Gap in Initial Exploratory Data Analysis.” IEEE Transactions on Visualization and Computer Graphics 24 (1): 278–87. Becker, Richard A, and William S Cleveland. 1987. “Brushing Scatterplots.” Technometrics 29 (2): 127–42. Beniger, James R, and Dorothy L Robyn. 1978. “Quantitative Graphics in Statistics: A Brief History.” The American Statistician 32 (1): 1–11. Bertin, Jacques. 1967. Sémiologie Graphique: Les diagrammes, les réseaux, les cartes. Gauthier-Villars. Blokt. 2020. “Flare \\(\\vert\\) Data Visualization for the Web.” Blokt - Privacy, Tech, Bitcoin, Blockchain &amp; Cryptocurrency. https://blokt.com/tool/prefuse-flare. Bostock, Mike. 2022. “D3.js - Data-Driven Documents.” https://d3js.org. Brasseur, Lee. 2005. “Florence Nightingale’s Visual Rhetoric in the Rose Diagrams.” Technical Communication Quarterly 14 (2): 161–82. Brodbeck, Dominique, Riccardo Mazza, and Denis Lalanne. 2009. “Interactive Visualization - A Survey.” In Human Machine Interaction, 27–46. Berlin, Germany: Springer. https://doi.org/10.1007/978-3-642-00437-7_2. Buja, Andreas, Dianne Cook, and Deborah F Swayne. 1996. “Interactive High-Dimensional Data Visualization.” Journal of Computational and Graphical Statistics 5 (1): 78–99. Byron, Lee, and Martin Wattenberg. 2008. “Stacked Graphs–Geometry &amp; Aesthetics.” IEEE Transactions on Visualization and Computer Graphics 14 (6): 1245–52. Cairo, Alberto. 2014. “Graphics Lies, Misleading Visuals: Reflections on the Challenges and Pitfalls of Evidence-Driven Visual Communication.” In New Challenges for Data Design, 103–16. Springer. ———. 2019. How Charts Lie: Getting Smarter about Visual Information. WW Norton &amp; Company. Chen, Chun-houh, Wolfgang Karl Härdle, and Antony Unwin. 2008. Handbook of Data Visualization. Springer Science &amp; Business Media. Clark, Lin. 2017. “A Crash Course in Just-in-Time (JIT) Compilers.” Mozilla Hacks the Web Developer Blog. https://hacks.mozilla.org/2017/02/a-crash-course-in-just-in-time-jit-compilers. Clayton, Aubrey. 2021. Bernoulli’s Fallacy: Statistical Illogic and the Crisis of Modern Science. Columbia University Press. Cleveland, William S. 1985. The Elements of Graphing Data. Wadsworth Publ. Co. ———. 1993. Visualizing Data. Hobart press. Cleveland, William S, and Robert McGill. 1984. “Graphical Perception: Theory, Experimentation, and Application to the Development of Graphical Methods.” Journal of the American Statistical Association 79 (387): 531–54. Dao, Chau. 2020. “The Nature and Evolution of JavaScript.” Bachelor's Thesis, Oulu University of Applied Sciences. Dimara, Evanthia, and Charles Perin. 2019. “What Is Interaction for Data Visualization?” IEEE Transactions on Visualization and Computer Graphics 26 (1): 119–29. Dix, Alan, and Geoffrey Ellis. 1998. “Starting simple: adding value to static visualisation through simple interaction.” In AVI ’98: Proceedings of the working conference on Advanced visual interfaces, 124–34. New York, NY, USA: Association for Computing Machinery. https://doi.org/10.1145/948496.948514. Donoho, Andrew W, David L Donoho, and Miriam Gasko. 1988. “MacSpin: Dynamic Graphics on a Desktop Computer.” IEEE Computer Graphics and Applications 8 (4): 51–58. Elmqvist, Niklas, Andrew Vande Moere, Hans-Christian Jetter, Daniel Cernea, Harald Reiterer, and TJ Jankun-Kelly. 2011. “Fluid Interaction for Information Visualization.” Information Visualization 10 (4): 327–40. Evan You and the Vue Core Team. 2024. “Vue.js.” https://vuejs.org. Fienberg, Stephen E. 1992. “A Brief History of Statistics in Three and One-Half Chapters: A Review Essay.” JSTOR. Fisherkeller, Mary Anne, Jerome H Friedman, and John W Tukey. 1974. “An Interactive Multidimensional Data Display and Analysis System.” SLAC National Accelerator Lab., Menlo Park, CA (United States). Foley, James D. 1990. “Scientific Data Visualization Software: Trends and Directions.” The International Journal of Supercomputing Applications 4 (2): 154–57. Fong, Brendan, and David I Spivak. 2019. An Invitation to Applied Category Theory: Seven Sketches in Compositionality. Cambridge University Press. Fowlkes, EB. 1969. “User’s Manual for a System Fo Active Probability Plotting on Graphic-2.” Tech-Nical Memorandum, AT&amp;T Bell Labs, Murray Hill, NJ. Franconeri, Steven L, Lace M Padilla, Priti Shah, Jeffrey M Zacks, and Jessica Hullman. 2021. “The Science of Visual Data Communication: What Works.” Psychological Science in the Public Interest 22 (3): 110–61. Freedman, David. 1999. “From Association to Causation: Some Remarks on the History of Statistics.” Statistical Science 14 (3): 243–58. Friendly, Michael. 2006. “A Brief History of Data Visualization.” In Handbook of Computational Statistics: Data Visualization, edited by C. Chen, W. Härdle, and A Unwin, III???–. Heidelberg: Springer-Verlag. Friendly, Michael, and Howard Wainer. 2021. A History of Data Visualization and Graphic Communication. Harvard University Press. Gelman, Andrew, and Antony Unwin. 2013. “Infovis and Statistical Graphics: Different Goals, Different Looks.” Journal of Computational and Graphical Statistics 22 (1): 2–28. Heer, Jeffrey, and Michael Bostock. 2010. “Crowdsourcing Graphical Perception: Using Mechanical Turk to Assess Visualization Design.” In Proceedings of the SIGCHI Conference on Human Factors in Computing Systems, 203–12. Heer, Jeffrey, Stuart K. Card, and James A. Landay. 2005. “prefuse: a toolkit for interactive information visualization.” In CHI ’05: Proceedings of the SIGCHI Conference on Human Factors in Computing Systems, 421–30. New York, NY, USA: Association for Computing Machinery. https://doi.org/10.1145/1054972.1055031. Highsoft. 2022. “Render Millions of Chart Points with the Boost Module Highcharts.” Highcharts. https://www.highcharts.com/blog/tutorials/highcharts-high-performance-boost-module. ———. 2024. “Highcharts - Interactive Charting Library for Developers.” Highcharts Blog \\(\\vert\\) Highcharts. https://www.highcharts.com. Holtz, Yan. 2022. “Barplot with Variable Width - Ggplot2.” https://r-graph-gallery.com/81-barplot-with-variable-width.html. Howard, David, and Alan M MacEachren. 1995. “Constructing and Evaluating an Interactive Interface for Visualizing Reliability.” In Congresso Da Associação Cartográfica Internacional–ICA, 17:321–29. Jankun-Kelly, TJ, Kwan-Liu Ma, and Michael Gertz. 2007. “A Model and Framework for Visualization Exploration.” IEEE Transactions on Visualization and Computer Graphics 13 (2): 357–69. Kehrer, Johannes, Roland N Boubela, Peter Filzmoser, and Harald Piringer. 2012. “A Generic Model for the Integration of Interactive Visualization and Statistical Computing Using r.” In 2012 IEEE Conference on Visual Analytics Science and Technology (VAST), 233–34. IEEE. Keim, Daniel A. 2002. “Information Visualization and Visual Data Mining.” IEEE Transactions on Visualization and Computer Graphics 8 (1): 1–8. Kelleher, Curran, and Haim Levkowitz. 2015. “Reactive Data Visualizations.” In Visualization and Data Analysis 2015, 9397:263–69. SPIE. Kosara, Robert. 2016. “Presentation-Oriented Visualization Techniques.” IEEE Computer Graphics and Applications 36 (1): 80–85. Kruskal, J. B. 1965. “Multidimensional Scaling.” https://community.amstat.org/jointscsg-section/media/videos. Kunst, Joshua. 2022. Highcharter: A Wrapper for the ’Highcharts’ Library. Kvasz, Ladislav. 2006. “The History of Algebra and the Development of the Form of Its Language.” Philosophia Mathematica 14 (3): 287–317. Leman, Scotland C, Leanna House, Dipayan Maiti, Alex Endert, and Chris North. 2013. “Visual to Parametric Interaction (V2pi).” PloS One 8 (3): e50474. Mansfield, Daniel F. 2018. Wikimedia Commons. https://commons.wikimedia.org/wiki/File:Si427o.jpg. ———. 2020. “Perpendicular Lines and Diagonal Triples in Old Babylonian Surveying.” Journal of Cuneiform Studies 72 (1): 87–99. Mayr, Ernst. 1999. Systematics and the Origin of Species, from the Viewpoint of a Zoologist. Harvard University Press. MDN. 2024. “EventTarget - Web APIs \\(\\vert\\) MDN.” MDN Web Docs. https://developer.mozilla.org/en-US/docs/Web/API/EventTarget. Meta. 2024. “React.” https://react.dev. Michell, Joel. 1986. “Measurement Scales and Statistics: A Clash of Paradigms.” Psychological Bulletin 100 (3): 398. nLab. 2024a. “Posetal Reflection in nLab.” https://ncatlab.org/nlab/show/posetal+reflection. ———. 2024b. “Strict Weak Order in nLab.” https://ncatlab.org/nlab/show/strict+weak+order. ———. 2024c. “Weak Order in nLab.” https://ncatlab.org/nlab/show/weak+order. Online Etymology Dictionary. 2024. “Statistics.” https://www.etymonline.com/word/statistics. Pike, William A, John Stasko, Remco Chang, and Theresa A O’connell. 2009. “The Science of Interaction.” Information Visualization 8 (4): 263–74. Plotly Inc. 2022. “Part 4. Interactive Graphing and Crossfiltering \\(\\vert\\) Dash for Python Documentation \\(\\vert\\) Plotly.” https://dash.plotly.com/interactive-graphing. ———. 2024. “Webgl.” https://plotly.com/python/webgl-vs-svg. Quadri, Ghulam Jilani, and Paul Rosen. 2021. “A Survey of Perception-Based Visualization Studies by Task.” IEEE Transactions on Visualization and Computer Graphics. Rheingans, Penny. 2002. “Are We There yet? Exploring with Dynamic Visualization.” IEEE Computer Graphics and Applications 22 (1): 6–10. Rich Harris and the Svelte Core Team. 2024. “Svelte.” https://svelte.dev. Satyanarayan, Arvind, Ryan Russell, Jane Hoffswell, and Jeffrey Heer. 2015. “Reactive Vega: A Streaming Dataflow Architecture for Declarative Interactive Visualization.” IEEE Transactions on Visualization and Computer Graphics 22 (1): 659–68. Shneiderman, Ben. 2003. “The Eyes Have It: A Task by Data Type Taxonomy for Information Visualizations.” In The Craft of Information Visualization, 364–71. Elsevier. Stevens, Stanley Smith. 1946. “On the Theory of Scales of Measurement.” Science 103 (2684): 677–80. Swayne, Deborah F., Dianne Cook, and Andreas Buja. 1998. “XGobi: Interactive Dynamic Data Visualization in the X Window System.” J. Comput. Graph. Stat. 7 (1): 113–30. https://doi.org/10.1080/10618600.1998.10474764. Swayne, Deborah F., Duncan Temple Lang, Andreas Buja, and Dianne Cook. 2003. “GGobi: evolving from XGobi into an extensible framework for interactive data visualization.” Comput. Statist. Data Anal. 43 (4): 423–44. https://doi.org/10.1016/S0167-9473(02)00286-4. Tal, Eran. 2015. “Measurement in Science.” Theus, Martin. 2002. “Interactive Data Visualization using Mondrian.” J. Stat. Soft. 7 (November): 1–9. https://doi.org/10.18637/jss.v007.i11. ———. 2008. “High-Dimensional Data Visualization.” In Handbook of Data Visualization, 152–75. Springer Science &amp; Business Media. Thudt, Alice, Jagoda Walny, Charles Perin, Fateme Rajabiyazdi, Lindsay MacDonald, Diane Vardeleon, Saul Greenberg, and Sheelagh Carpendale. 2016. “Assessing the Readability of Stacked Graphs.” In Proceedings of Graphics Interface Conference (GI). Tierney, Luke. 1990. Lisp-Stat: An Object-Oriented Environment for Statistical Computing and Dynamic Graphics. New York: Wiley-Interscience. Tufte, Edward R. 2001. The Visual Display of Quantitative Information. Cheshire, Connecticut: Graphics Press LLC. Tukey, John W. 1962. “The Future of Data Analysis.” The Annals of Mathematical Statistics 33 (1): 1–67. Tukey, John W et al. 1977. Exploratory Data Analysis. Vol. 2. Reading, MA. Tukey, John W. 1993. “Graphic Comparisons of Several Linked Aspects: Alternatives and Suggested Principles.” Journal of Computational and Graphical Statistics 2 (1): 1–33. Unwin, Antony. 1999. “Requirements for interactive graphics software for exploratory data analysis.” Comput. Statist. 14 (1): 7–22. https://doi.org/10.1007/PL00022706. ———. 2018. Graphical Data Analysis with r. Chapman; Hall/CRC. Urbanek, Simon. 2011. “iPlots eXtreme: Next-Generation Interactive Graphics Design and Implementation of Modern Interactive Graphics.” Computational Statistics 26 (3): 381–93. Urbanek, Simon, and Martin Theus. 2003. “iPlots: High Interaction Graphics for r.” In Proceedings of the 3rd International Workshop on Distributed Statistical Computing. Citeseer. Vega Project. 2022. “Example Gallery: Interactive.” https://vega.github.io/vega-lite/examples/#interactive. ———. 2024a. “Brushing Scatter Plots Example.” Vega. https://vega.github.io/vega/examples/brushing-scatter-plots. ———. 2024b. “Vega and D3.” Vega. https://vega.github.io/vega/about/vega-and-d3. Velleman, Paul F, and Pratt Paul. 1989. “A Graphical Interface for Data Analysis.” Journal of Statistical Computation and Simulation 32 (4): 223–28. Velleman, Paul F, and Leland Wilkinson. 1993. “Nominal, Ordinal, Interval, and Ratio Typologies Are Misleading.” The American Statistician 47 (1): 65–72. Wikipedia. 2022. “Duck test - Wikipedia.” https://en.wikipedia.org/w/index.php?title=Duck_test&amp;oldid=1110781513. Wilhelm, Adalbert. 2008. “Linked Views for Visual Exploration.” In Handbook of Data Visualization, 200–214. Springer Science &amp; Business Media. Wilke, Claus O. 2019. Fundamentals of Data Visualization: A Primer on Making Informative and Compelling Figures. O’Reilly Media. Wilkinson, Leland. 2012. The Grammar of Graphics. Springer. Wills, Graham. 2008. “Linked Data Views.” In Handbook of Data Visualization, 217–41. ch. II. 9. Springer Berlin/Heidelberg, Germany. Wirfs-Brock, Allen, and Brendan Eich. 2020. “JavaScript: the first 20 years.” Proc. ACM Program. Lang. 4 (HOPL): 1–189. https://doi.org/10.1145/3386327. Yi, Ji Soo, Youn ah Kang, John Stasko, and Julie A Jacko. 2007. “Toward a Deeper Understanding of the Role of Interaction in Information Visualization.” IEEE Transactions on Visualization and Computer Graphics 13 (6): 1224–31. Young, Forrest W, Pedro M Valero-Mora, and Michael Friendly. 2011. Visual Statistics: Seeing Data with Dynamic Interactive Graphics. John Wiley &amp; Sons. "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
